# sec03/rag_exaone3.py

import streamlit as st
from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# import retriever -> retriever.py ì•ˆì— retrieverê°ì²´ê°€ ìˆì–´ì„œ í—·ê°ˆë¦´ ìˆ˜ ìˆìŒ. retriever.retrieverë¡œ í˜¸ì¶œì€ ê°€ëŠ¥í•¨
from retriever import query_augmentation_chain, retriever, document_chain

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOllama(model="exaone3.5:7.8b")

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
def get_ai_response(messages, docs):
    response = document_chain.stream({
        "messages": messages,
        "context": docs,
    })

    for chunk in response:
        yield chunk

# Streamlit ì•±
st.title("ğŸ’¬ exaone3.5 LangChain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ë¬¸ì„œì— ê¸°ë°˜í•´ ë‹µë³€í•˜ëŠ” ë„ì‹œ ì •ì±… ì „ë¬¸ê°€ì•¼.")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    print("user\t:", prompt) # , ì ì„ ê²½ìš° ìë™ìœ¼ë¡œ ê³µë°± 1ì¹¸ ì„¤ì •

    augmented_query = query_augmentation_chain.invoke({
        "messages": st.session_state["messages"],
        "query": prompt
    })
    print("augmented_query\t", augmented_query)

    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    print("ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰")
    # gptëŠ” augmented_queryë§Œ ë„£ëŠ” ê²ƒì„ ì¶”ì²œ
    docs = retriever.invoke(f"{prompt}\n{augmented_query}")

    for doc in docs:
        print('----------')
        print(doc)

        # ë¬¸ì„œ ì¶œì²˜ í‘œê¸°í•˜ê¸°
        with st.expander(f"**ë¬¸ì„œ:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}"): # sourceê°€ ì—†ìœ¼ë©´ 'ì•Œ ìˆ˜ ì—†ìŒ'ì´ ê¸°ë³¸ê°’
            # íŒŒì¼ëª…ê³¼ í˜ì´ì§€ ì •ë³´ í‘œì‹œ
            st.write(f"**page:**{doc.metadata.get('page', '')}") # pageë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ '' ì´ ê¸°ë³¸ê°’
            st.write(doc.page_content)

    print("===============")

    with st.spinner(f"AIê°€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤... '{augmented_query}'"):
        response = get_ai_response(st.session_state["messages"], docs)
        result = st.chat_message("assistant").write_stream(response)
    st.session_state["messages"].append(AIMessage(result))
