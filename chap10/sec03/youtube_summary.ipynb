{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30df5a99",
   "metadata": {},
   "source": [
    "## YoutubeSearch 패키지로 유튜브 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2024e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-search in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: requests in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from youtube-search) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube-search) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube-search) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube-search) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube-search) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 랭체인에서 youtube search tool 이라는 패키지를 제공하지만 기능이 제한적이라 파이썬 패키지 사용할 예정\n",
    "%pip install youtube-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fe86ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'PzeQ-H9q3Y8',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAS3g7BBhHj50lH81nWFkPFL5dCFA',\n",
       "   'https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLDGG2TJ0b_qeStZ6URpvlbqXe6TlQ'],\n",
       "  'title': '랭체인 + RAG 5분만에 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '나도코딩',\n",
       "  'duration': '5:34',\n",
       "  'views': '조회수 7,929회',\n",
       "  'publish_time': '2개월 전',\n",
       "  'url_suffix': '/watch?v=PzeQ-H9q3Y8&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv'},\n",
       " {'id': 'm8tIOcMcwno',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLD6ACjB-c0R9H3HEfaeu323mLS9MQ',\n",
       "   'https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCHenGlwslkGWHJ48R06LOGC-wZgQ'],\n",
       "  'title': '랭체인 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '다비드스튜디오 dabidstudio ',\n",
       "  'duration': '9:16',\n",
       "  'views': '조회수 14,231회',\n",
       "  'publish_time': '8개월 전',\n",
       "  'url_suffix': '/watch?v=m8tIOcMcwno&pp=ygUJbGFuZ2NoYWlu'},\n",
       " {'id': '1scMJH93v0M',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC8Bbvnyigui44yjlyGJQCfFV7MqA',\n",
       "   'https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBIUwbKKCmlPJKcw2nTifu92hXaZg'],\n",
       "  'title': '#langchain 의 #RAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작',\n",
       "  'long_desc': None,\n",
       "  'channel': '테디노트 TeddyNote',\n",
       "  'duration': '21:47',\n",
       "  'views': '조회수 41,428회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=1scMJH93v0M&pp=ygUJbGFuZ2NoYWlu'},\n",
       " {'id': '84paXmEsjjg',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLARhrBfQwlUZu-kL78JiAK12VYMjA',\n",
       "   'https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCZHMGJ0GLCy1Fzpxt0GmCqTmCD5w'],\n",
       "  'title': '9장 LangChain + YouTube Transcript API +GPT-4o-mini  으로 유튜브 자막 추출부터 요약, 번역, 요점 정리까지',\n",
       "  'long_desc': None,\n",
       "  'channel': '오늘코드todaycode',\n",
       "  'duration': '12:07',\n",
       "  'views': '조회수 376회',\n",
       "  'publish_time': '3개월 전',\n",
       "  'url_suffix': '/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu'},\n",
       " {'id': 'aDN8hm4pfPE',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLBkzzRK-6gLFE2KFpAQ6KmdBvKE3w',\n",
       "   'https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBLCzdjvCdb-JFdr8K1JAJtcH1Mfw'],\n",
       "  'title': \"아직도 '랭체인'을 모른다고 해서 5분 설명해드림\",\n",
       "  'long_desc': None,\n",
       "  'channel': '노마드 코더 Nomad Coders',\n",
       "  'duration': '6:01',\n",
       "  'views': '조회수 46,383회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=aDN8hm4pfPE&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드 검색하기\n",
    "from youtube_search import YoutubeSearch\n",
    "\n",
    "videos = YoutubeSearch(\"langchain\", max_results=5).to_dict()\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da4e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://youtube.com/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 온전한 경로 만들기\n",
    "video_url = 'https://youtube.com' + videos[3]['url_suffix']\n",
    "video_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786c3f",
   "metadata": {},
   "source": [
    "## YoutubeLoader 패키지로 유튜브 자막 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5844cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from youtube_transcript_api) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube_transcript_api) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube_transcript_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube_transcript_api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\doit-agent\\venv\\lib\\site-packages (from requests->youtube_transcript_api) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 유튜브 자막을 내려받기 위한 youtube_transcript_api\n",
    "%pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31a623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '84paXmEsjjg'}, page_content='안녕하세요. NLP와 LM 실전 가이드 9장에 있는 책 어 312쪽부터 317쪽에 있는 유튜브 영상 요약하기를 실습을 진행을 해 보도록 하겠습니다. 일단이 책은 이제 원서 마스터링 NLP 어 from롬파데이션투 LLM 책의 이제 번역서인데요. 이제 원서의 실습 내용하고 조금 다르게 구성이 되어 있습니다.이 이제 원서 어의 이제 실습어요 그 코랩 링크를 통해서도 이제 바로 이제 들어와서 이렇게 보실 수가 있는데요. 여기에서는 이제 인베드 체인이라는 것을 이제 사용을 해요. 근데 인베드 체인이 어 유료로 어 변경이 되었고요. 그리고 여기 인베드 체인을 사용해서 이제 어떤 실습을 하냐면 원서에서는여이 유튜브 자막을 가지고 와요. 그래서 그 자막을 이제 번역하고 요약해 보는 실습으로 구성이 되어 있는데이 정도의 실습은 굳이요 인베드 체인을 사용하지 않더라도 실습이 가능하기 때문에 인베드 체인을 이제 복잡하게 이제 설정하는 것보다는 어 저희는 그냥 오픈소스 라이브러리들을 이제 사용을 해서 진행을 해 볼 예정입니다. 일단 이제 실습에 들어가기 전에 어 저희가 할 실습에 대해서 요약을 해보고 진행을 해 보도록 할 텐데요. 유튜브 영상 어 자막 추출 및 요약을 진행을 해 볼 예정이고요. 그래서 유튜브 영상의 자막을 API로 이제 추출을 해서 랭체인과 GPT 45니로 이제 요약하고 이제 다구어 번역하는 이제 전체 과정을 소개를 해 보도록 하겠습니다. 그래서이 내용은 NLP와 LM 실전 가이드 9장을 기반으로 이제 한국어 주요를 깔끔하게 이제 정리하는 이제 방법을 익혀보도록 할 예정이에요. 그래서 필요한 라이브러리 랭체인 그다음에 랭체인 오픈 AI 그다음에 유튜브 트랜스크립트 API를 설치를 할 거고이 유튜브 트랜스크립트 API 같은 경우에는 유튜브에서 공식적으로 이제 제공하고 있는 API가 아니라 그냥 오픈 소스로 개발자들이 만들어서 이제 어 공유하고 있는 어 API다라고 보시면은 됩니다. 그래서 이제 필요한 모듈 이제 임포트 할 때 이제 OS나 이제 텍스트 랩도 임포트를 할 텐데 뭐 긴 텍스트들에 대한 줄바금 처리를 할 때 텍스트 랩을 사용할 거예요. 그래서 다국어 번역을 했을 때 뭐 한국어, 뭐 러시아, 뭐 독일어 요런 것들 이제 텍스트 랩을 통해서 조금 보기 좋게 전 처리를 해 볼 예정이고요. 그다음에 유튜브 트랜스크립트 API를 통해서 유튜브 자막을 이제 추출을 해 볼 예정이고 어 랭체인으로 이제 프롬프트 템플릿이라든지 오픈 AI의 채팅 어 기반의 LLM을 이제 사용을 해 볼 예정입니다. 그래서 API 키도 마찬가지로 이제 저희는 콜랩을 통해서 이제 실습을 하기 때문에 그 콜랩 왼쪽에 열쇠 모양 클릭을 하시게 되면은 요런 식으로 오픈 AI API 키 등록하고 이제 사용하실 수가 있고요. 로컬에서 이제 사용하실 때는 어 이런 이제 환경 변수에 설정을 하고 사용을 하실 수도 있습니다. 그래서 유튜브 자막 최출 과정은 일단 영상 URL를 지정을 하고 유튜브 트랜스크립트 API를 통해서 가져오는데 일단요 아이디값 영상의 아이디값만 있으면은 어 유튜브 트랜스크립트 API를 통해서 스크립트 트랜스크립트 하게 되면은 영어 자막을 가져올 수가 있습니다. 그래서 자막 딕셔너리에서 텍스트 항목만 이제 추출을 해서 하나의 문자열로 합쳐서 어 실습을 진행을 해 볼 예정이에요. 그리고 이제 랭체인으로 요약하고 번역 설정을 해 보도록 할 텐데 GPT 45 미니는 어 굉장히 이제 가격도 저렴하고 성능도 그렇게 이제 떨어지진 않아서 GPT 45 미니를 이제 사용을 해 볼 예정이고요. 그다음에 이제 어 비용도 어 저렴하다 이렇게 이제 볼 수 있습니다. 그래서 이제 프롬프트 템플릿을 구성을 해서 뭐 전체 내용을 내문장 길이로 요약한다든지 아니면은 한국어 러시아 독일어로 번역을 해 본다든지 그다음에 언어간 이제 구분을 위해서 특수 문자를 지어 그 지정을 하고 이제 텍스트 랩으로 전 처리하는 어 그런 과정이 있고요. 그다음에 이제 템플릿 프롬프트 템플릿으로 입력 변수를 이제 설정해서 여기에다가 이제 자막을 넣어 준다든지 하는 내용으로 이제 구성이 되어 있습니다. 그다음에 이제 프롬프트 템플릿이 구성했다면 이제 체인을 구성을 해 주는데 어이 체인 구성할 때 이제 파이프 연산자로 이제 런너블 시퀀스 형태로 연결을 해서 사용을 할 거고요. 그다음에 이제 프롬프트에다가 이제 자막 텍스트 입력을 해 주고 그다음 이제 LM 호출해서 인보크 메 그 메서드를 통해서 LLM의 입력을 전달하고 결과를 받을 예정이에요. 그다음에 텍스트 랩으로 이제 가독성 좋게 어 전처리까지 이제 해 보는게 실습 내용입니다. 어, 그리고 이제 뭐 번역을 했다면 다음으로 이제 요약 테스크를 진행을 할 텐데 이제 간결한 한국어 요점을 이제 정리해 달라. 그래서 뭐 세 개에서 다섯 개 분리 어 형태로 머리끌로 이제 정리해 달라 요렇게 이제 어 요청을 할 예정입니다. 그래서 이제 글머리 기호로 시작하는 이제 한국어로 이제 작성을 해 달라라고 할 거예요. 그래서 이제 프롬프트 템플릿 구성하고 체인 구성하고 이전 결과 번역 결과를 새 체인에 전달을 해서 마지막에는 이제 한국어 주요 요점을 이제 표시하는 이제 요약을 해 보는 어 방법으로 이제 번역과 요약 테스크를 진행을 해 보도록 하겠습니다. 그럼 이제 코랩으로 넘어와서 어 직접 이제 실습 진행을 해 보도록 할 텐데요. 일단 PP 인스톨 해서 이제 앞에서 이제 소개했었던 것처럼 이제 랭체인 그다음에 랭체인에서 이제 오픈 AI API 이제 사용할 거기 때문에 랭체인 오픈 A AP AI 그다음에 어 랭체인 커뮤니티 유튜브 트랜스크립트 API 설치를 해 주도록 하고요. 그다음에 이제 OS 뭐 텍스트 랩 그다음에 유튜브 어 API 그다음에 랭체인에서는 이제 프롬프트 템플릿과 채 높은 오픈 AI 불러오도록 하고요. 그다음에 이제 왼쪽 열쇠 버튼 누르게 되면은 이제 미리 어 저장을 해 두었기 때문에 한 번만 입력을 해 두게 되면 내 계정에 저장이 되는 거기 때문에 어 별도로 따로 입력을 해 주시지 않아도 됩니다. 네. 만약에 내가 환경 변수 로컬에서 실습하고 있다 하시게 되면은 환경 변수에서 직접 불러오시거나 아니면 여기에다가 지정하고 사용을 해 주시는 방법도 있습니다. 그래서 이제 오픈 AI API 키 어가 만약에 이제 없다라고 하게 되면은이 코랩에서 오픈 AI API 키를 이제 불러오도록 어 했습니다. 그다음에 유튜브 비디오 URL를 통해서 URL을 지정을 해 주었고요. 그리고 유튜브 트랜스크립트 API를 통해서요 비디오 아이디에서요 언어 같은 경우에는이 유튜브 영상 같은 경우 이제 테드의 강연 영상이에요. 그래서요 테드 강연 영상에 대한 뒤에 있는요 아이디값만 요렇게 이제 가지고 온다. 그래서 영어로 되어 있기 때문에 어 이이라고 지정을 해 주었고 만약에 이제 한국어다라고 하게 되면은 이제 K5 요런 식으로 이제 지정을 해 주시면은 되겠죠. 그럼 이제 GPT 45니 어를 이제 사용을 해서 어 저희가 이제 다구어 번역을 이제 진행을 해 보도록 할 텐데 여기에 이제 서머리 프롬프트 템플릿에다가 이제 전체 내용을 검토하고 한국어 러시아 독일어로 이제 번역을 해 달라라고 프롬프트 템플릿을 작성을 했습니다. 그래서 여기에다가 어 그 문자열을 다른 문자열로 이제 구분을 해서 한국어 러시아 독일어를 구분을 하도록 했고요. 그래서 프롬프트 템플릿에다가 지금 위에 서머리 프롬프트 템플릿 써 놓은 내용 지정을 해 주고 그다음에 인풋 베리어블에다가 이제 컨텐츠 해서 이제 넣어 주도록 했어요. 그다음에이 서머리 그 프롬프트에서요 프롬프트와 llm 모델은 이제 오픈 AI의요 채 어 오픈 AI요 모델을 이제 지정을 해 주도록 했습니다. 그다음에 여기 이제 그 서머리 프롬프트의 포맷 해서 이제 컨텐츠에다가는 어 영어 텍스트를 이제 넣어 주도록 했어요.이 영어 텍스트는 어디에 있냐면 우리가이 유튜브에서 가져온 자막을 잉글시 텍스트라는 어 내용으로 이제 넣어 줬어요. 그래서 그 영어 텍스트 이제 확인을 해 보게 되면은 여기에서 어 요렇게 이제 테드의 어 영상에 대한 그 영어 어 자막을 가지고 왔고이 천자만 이제 일단 보여 주도록 했어요. 이제 너무 어 기니까. 그래서요 내용을 어 지금이 잉글리시 텍스트에다가 넣어 줄 예정입니다. 그래서 여기 컨텐츠라고 지정을 했는데요 인풋 베리어블 해서요 프롬프트 템플릿의요 컨텐츠가 여기에 이제 들어가게 된다라고 이제 보시면은 되고 그리고요 컨텐츠는요 서머리 프롬프트 템플릿의 이제 변수로 여기 컨텐츠로 이제 들어가게 됩니다. 그래서요 컨텐츠 어를 이제 그 영어 자막 텍스트를 넣어 주도록 하고요. 프롬프트 체인 구성해 준 거를 이제 서머리 체인이라는 변수에다가 넣어 주었는데요. 여기에서 인보크 해서 저 런너블 시퀀스로 어 되어 있는이 프롬프트와 모델을요 변수로 이제 넣어 주었습니다. 그다음에 여기에서 내문장 길이에 영어로 요약한 다음 한국어 러시아 독일어로 이제 번역해 달라 아라고 했죠. 그래서 요약하고 이제 번역을 이제 수행 어 한 결과를 이제 출력을 해 보고 여기에서 위에서 이제 구분자 요걸로 이제 넣어 달라라고 했으니까 이제 구분자로 어 번역과 이제 요약이 되는지 확인을 해 보도록 하겠습니다. 그럼 이렇게 번역 결과가 나왔는데요. 일단이 원문 나왔고요. 그다음에 요약하고 이제 번역해 달라라고 했는데 영어로 요약을 먼저 하고 그다음에 이제 번역을 하는데 한국어 러시아 독일어로 이제 번역을 해 달라고 했어요.이 한국어 위에는 요렇게 어 그 대시 어 문자를 넣어 주고 그다음에 여기에는 어 아스트리크 문자를 넣어 주고 그다음에는 요렇게 이제 문자로 이제 구분을 해서 한국어 러시아 독일어를 이제 구분을 했고 그다음에 요약 및 번역 결과 아까지 요렇게 이제 넣어 주었습니다. 그래서 이제 보기 좋게 이제 출력한 거는요 텍스트 랩을 통해서 어 보기 좋게 어 렇게 그 출력까지 이제 해 주도록 했는데 한국어로 이제 번역한 결과를 보게 되면은 이제 좋은 관계는 건강하고 행복한 삶에 필수적이며 그다음에 어 연구한 결과 어 사회적 연결이 중요하고 외로움이 건강과 행복에 부정적을 낀 영향을 미친다고 강 그 강조한다. 요런 이제 어 내용들이 이제 나와 있습니다. 그래서 각 언어별 요청한 언어별로 요약과 번역을 했고요. 그다음에 여기에서 글리로 작성해 달라라고 했어요. 그래서 각 요점은 글리 기호로 시작하는 한국어로만 이제 작성을 해 달라라고 했습니다. 그래서 이제 프롬프트 템플릿에다가요 키포인트 프롬프트 템플릿을 넣어 줬고 그 변수로는 오리지널 엔서라고 요렇게 어 변수를 이제 넣어 주도록 했어요. 이전 질문에 대한 답변을 넣어 주고 그걸 이제 글리 기호로 이제 만들어 주는데요. 여기에서도 이제 체인어요 프롬프트 템플릿과 LLM 모델 오픈 AI에 사용을 하고요. 그다음에이 인보크에다가이 위에서 구성한 이제 체인의 인보크에서 오리지널 엔서 이전에 이제 답변받은 어 내용을 이제 변수로 프롬프트 템플릿에다가 넣어 줄 수 있도록 설정을 해 주었습니다. 그럼 이제 한국어 요점을 글리 기호로 어 정리해 달라라고 했는데요. 어 좋은 관계는 건강하고 행복한 삶의 필수적이다. 그다음에 사회적 연결이 중요하고 외로움과 어 외로움은 건강과 행복에 부정적인 영향을 미친다. 그래서 관계의 질이 양보다 중요하면 만족스러운 관계가 나이 될수록 더 나은 결과를 가져온다. 그래서 관계를 유지하는데 시간과 에너지를 투자하는 것이 충만한 삶의 핵심이다라고 해서 어 테드 어 영상을 이렇게 번역하고 요약하는 테스크를 이제 진행을 해 봤다라고 보시면은 될 거 같아요. 그래서 이번 실습에서는 이제 유튜브 어 그에 트랜스크립트 API와 그다음에 랭체인을 사용을 해서 어 간단한 RH 실습을 해 봤다. 검색 증강 생성 실습을 해 봤다라고 보시면은 될 것 같습니다. 그래서 인베드 체인을 사용을 해도 되지만 여기에서는 이제 어 별도의 개별적인 라이브러리를 사용을 해서 R를 이제 구현을 하고 실습을 해 보았습니다. 감사합니다.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YoutubeLoader로 유튜브 자막 가져오기\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    video_url,\n",
    "    language=['ko', 'en'], # 한국어, 영어 자막 모두 가져오기\n",
    ")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db19ad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'PzeQ-H9q3Y8',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAS3g7BBhHj50lH81nWFkPFL5dCFA',\n",
       "   'https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLDGG2TJ0b_qeStZ6URpvlbqXe6TlQ'],\n",
       "  'title': '랭체인 + RAG 5분만에 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '나도코딩',\n",
       "  'duration': '5:34',\n",
       "  'views': '조회수 7,929회',\n",
       "  'publish_time': '2개월 전',\n",
       "  'url_suffix': '/watch?v=PzeQ-H9q3Y8&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'video_url': 'https://youtube.com/watch?v=PzeQ-H9q3Y8&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'content': [Document(metadata={'source': 'PzeQ-H9q3Y8'}, page_content='여러분 채 GPT 많이 사용하시죠? 네. 최근에는 가족 사진을 다양한 스타일의 이미지로 만들어 보는 재미 덕분에 이용자가 폭주하면서 샘 얼트먼이 이미지 생성을 자세해 달라는 글도 올렸었는데요. 어 G지PT는 재미있는 이미지 생성에도 많이 사용되지만 실제로 여러분들이 사용할 또는 업무에 필요한 용도로도 많이 활용을 하실 것 같습니다. 네. 이렇게 많은 분야에서 사용되는 챗 GPT. 그런데 사실 채 GPT라고 해서 모든 것을 알고 있는 건 아니에요. GPT는 특정 시점까지 데이터를 학습하고이 내용을 바탕으로 답변을 하기 때문에 최신 데이터에 대해서는 답변을 올바로 하지 못하는 문제가 있는데요. 네. 이런 부분을 보완하고자 최신 정보를 즉각적으로 반영할 수 있는 실시간 웹 기능을 제공하고 있지요. 그런데 이것 말고도 여전히 채지가 답변을 올바로 하지 못하는 부분이 있습니다. 바로 비공개 데이터인데요. 예를 들어서 우리 가족이 이렇게 있을 때 우리 집에서 가장 키가 큰 사람은 누구야라고 물어본다면 대체 GPT는 아마도 올바른 답을 하지 못할 겁니다. 또는 가족 여행으로 제주도를 간다고 했을 때 우리 가족 제주도 여행 출발 항공편은이라고 물어봐도네 역시 잘 모른다고 답을 하고 있지요. 우리 가족의 키 또는 우리 가족의 여행 정보는 우리 식구들 또는 매우 가까운 사람들만 알고 있는 정보이지 채 GPT는 당연히 알 수가 없을 겁니다. 그런데 제가 질문을 조금 다르게 해 볼게요. 이번에는 우리 가족의 키 정보를 주면서 물어보는 거예요. 네. 이렇게 키 정보를 주면서 우리 집에서 키가 가장 큰 사람은이라고 했더니 네. 이번에는 아빠가 가장 크다고 답변을 잘 해 줍니다. 다음 질문도 바꿔 볼까요? 자, 지금 보고 계신 네, 우리 가족 여행 계획서 중에서 항공편 정보와 관련된 부분만 채치T에게 전달하면서 다시 한번 물어보도록 할게요. 우리 가족 제주도 여행 출발 항공편은 이렇게 물었더니 네, 역시 정확하게 네, n254라고 답변을 잘하지요. 자, 이렇게 질문과 관련된 참고 자료를 함께 주면 채 G지pt도 제대로 답변을 할 수 있게 됩니다. 그런데 문제가 있어요. 자주 키 정보나 항공편 정도야 간단하지만 만약 책 한 권 전체 내용이라든지 수백 페이지에 달하는 회사 내부 매뉴얼 전체 등네 방대한 정보에 대해서 질문을 하고 싶다고 하면 어떻게 할까요? 어, 질문을 할 때마다 모든 내용을 대화창에 복사 붙여 넣게 하기에는 아마도 쉽지가 않을 것 같습니다. 데이터 양도 너무 많고 그에 따라 비용도 발생할 거고요. 또 참고 자료가 너무 많으면 오히려 책 GPT가 필요한 정보를 찾는데 혼란을 줄 가능성이 큽니다. 결국 올바른 답변을 얻지 못할 수도 있는 거예요. 바로이 문제를 해결하는 기술이 RH입니다. 네. 우리말로는 검색 증강 생성이라고 하는데 어렵게 들리지만 원리는 앞에서 본 것과 같습니다. 채치T에게 정보를 제공하고 그 정보 내에서 답변을 해 달라고 하는 거예요. 앞에서 보셨던 것처럼 우리 가족 여행 계획 데이터가 있으면이 전체 내용 중에서 우리가 궁금한 항공 일정과 관련된 부분만 뽑아서 질문제에 넣은 것. 이게 바로 Rage이 핵심입니다. Rag의 구조는 간략히 설명드리면 이렇습니다. 우리가 질문을 하면 RA 시스템은 먼저 우리가 미리 준비해 둔 외부 문서나 데이터베이스에서 질문과 가장 관련 높은 정보를 검색합니다. 네. 마치 오픈북 시험 볼 때 책에서 관련된 내용을 찾는 것과 같아요. 자, 그리고 이렇게 찾은 핵심 정보와 원래 질문을 함께 AI에게 전달하면서 자, 여기 참고 자료 있으니까 이거를 보고 답을 해 줘 하고 시키는 거죠. 그러면 채pt는이 참고 자료를 바탕으로 훨씬 정확하고 구체적인 답변을 생성합니다. 생각보다 간단해 보이기도 하죠. 그런데이 R 시스템을 직접 만들려면 데이터를 불러오고 검색하기 좋게 나누고 검색도 하고 또 AI 모델하고 연결하고 등등 복잡한 작업들이 필요합니다. 이때 랭체인이라고 하는게 빛을 바라는데요. 어 랭체인은 마치 AI 프로그램 개발을 위한 레고 블록세트와 같습니다. Rag를 만드는데 필요한 여러 기능들 가령 데이터를 불러오거나 나누거나 검색하거나 AI를 연동하는 작업들을 미리 만들어진 형태로 제공합니다. 그래서이 랭체인 블록들을 가져다 쉽고 빠르게 조립해서 R이 기반의네 똑똑한 채복 같은 서비스를 뚝딱 만들 수 있는 거예요. 네.이 이 화면은 랭체인과 레그 기술을 사용해서 만들어 본 PDF 문서 기반 인공지능 Q&A 채포인데요. 이렇게 어떤 내용이 담긴 PDF 파일을 업로드하고 나서 질문을 해 보면 PDF 파일에서 관련 있는 부분을 찾아서 올바로 답변을 해 주는 모습을 보실 수 있습니다. 아주 다양한 환경에서 사용될 수 있는데요. 누군가 어떤 큰 행사를 준비하는데 행사 기간 및 장소는 어떻게 되는지, 입장 비용은 어떻게 되는지 음식물 반입은 가능한지 주차 지원은 되는지 등 행사 관련하여 다양한 질문을 채포을 통해서 해 줄 수도 있고요. 여러분이 사용하고 계신 전자 제품의 어떤 고장이 났을 때 AS를 받기 전에 가정에서 자가 소리를 하기 위한 방법이 어떻게 되는지 물어볼 수도 있겠죠.데 네. 고객센터 입장에서는 어 제품 매뉴얼이나 자주 묻는 질문 등에 대한 데이터가 있다면이 내용을 바탕으로네 채봇을 통해서 빠르고 정확하게 답변이 가능할 겁니다. 네. 자, 온라인에서 어떤 물건을 구매할 때도 Q&A 게시판에 보면 질문이 굉장히 많은데요. 이런 내용들을 어딘가 잘 정리해 두면 지금까지 답변한 내용을 바탕으로 새로운 질문이 왔을 때 자동으로 응답하는 것도 생각해 볼 수 있을 것 같습니다. AI가 단순히 알고 있는 것을 넘어서 여러분이 가진 정보를 활용해서 여러분만의 똑똑한 체포 서비스를 개발할 수 있다는게 네, 흥미롭지 않나요? 자, 이렇게 해서 아주 빠르게 내 한 개를 넘는 R과이를 쉽게 구현하도록 돕는 레인체인에 대해서 알아봤습니다. 네. 혹시라도 보다 더 자세히 공부하고 싶으신 분들이 계시다면 영상 본문 또는 고정 댓글을 참고해 주시면 좋겠습니다. 네, 그러면 이번 영상은 여기에서 마치도록 하겠습니다. 감사합니다.')]},\n",
       " {'id': 'm8tIOcMcwno',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLD6ACjB-c0R9H3HEfaeu323mLS9MQ',\n",
       "   'https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCHenGlwslkGWHJ48R06LOGC-wZgQ'],\n",
       "  'title': '랭체인 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '다비드스튜디오 dabidstudio ',\n",
       "  'duration': '9:16',\n",
       "  'views': '조회수 14,231회',\n",
       "  'publish_time': '8개월 전',\n",
       "  'url_suffix': '/watch?v=m8tIOcMcwno&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=m8tIOcMcwno&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': 'm8tIOcMcwno'}, page_content=\"l&m 서비스 개발에 관심이 많으신 분들은 자주 접하셨을 단어가 있습니다 바로이 랭 체인이라고 하는 것인데요 랭 체인은 l&m 서비스 개발을 굉장히 편리하게 해 주는 툴입니다 그런데 랭 체인을 처음 공부할 때 어려운 부분들이 좀 있습니다 일단 너무 복잡하고 종류가 많습니다 벡터 스토어 리트리버 체인 등등등 다양한 컴포넌트들이 있고 뭐가 뭔지 잘 모르겠습니다이 랭 체인이 어떻게 작동을 하는지 잘 이해가 안 갑니다 그래서 예제 코드를 보거나 코드를 다운받아도 내가 원하는 방식으로 바꾸는 것이 굉장히 어렵습니다 그래서 이번 영상에서는 링 체인의 특징 세 가지를 중심으로 l&m 서비스 개발 관점에서 어떤 문제를 해결해 주는지를 다뤄보려고 합니다 추상화 표준화 그리고 체이닝 이렇게 세 가지입니다 그래서 이런 특징들을 기반으로 우리가 랭 체인을 효과적으로 활용하기 위해서는 어떻게 접근을 하면 될지에 대해서 저희 생각을 공유해드리고자 합니다 랭 체인의 첫 번째 특징은 추상화입니다 랭 체인은 l&m 서비스를 만들 때 필요한 각종 복잡한 작업들을 굉장히 간결하게 표현을 해 주고 간소화해 줍니다 예를 들어 대표적인 l&m 서비스라고 할 수 있는 레그 체포 또는 문서 q&a 체포를 만들려고 할 때 꼭 필요한 작업들이 있습니다 PDF Pro 되어 있는 문서에서 텍스트를 불러와 주고 그 텍스트를 쪼개고 임베딩을 하고 벡터 DB 저장을 해 주는 과정을 거칩니다 그런데이 과정은 랭킹이 있으면 단 세 줄로 간결하게 표현을 하고 구현을 할 수가 있습니다 만약에 랭 체인이 없다고 하면은 우리가 PDF 불러오고 임베딩 모델을 정의하고 사용을 하고 벡터 디비를 활용하는 부분까지 다 직접 코드를 작성을 하고 구현을 해야 됩니다 그런 번 그름을 랭 치는 해소를 해 줍니다 링 체인의 두 번째 특징은 표준화합니다 링 체인은 비슷한 기능들을 가지고 있는 여러 요소들을 똑같은 형식을 갖춘 컴포넌트로 표준화해 줍니다 l&m 서비스를 만들 때 우리가 용을 할 수 있는 AI 모델은 이제는 정말로 종류가 다양합니다 채즈 피티도 있고 제미 아도 있고 정말 다양한데 이런 다양한 AI 모델을 우리는 랭지 인을 이용하면 챗 모델이라고 하는 하나의 표준화된 형식으로 통일을 해 줍니다 챗 모델이라고 하는 표준화된 컴퍼넌트가 없었으면 각 AI 모델마다 갖고 있는 엔드 포인트라는 API든지 활용하는 형태가 다 다르기 때문에 이걸 제대로 구현화 해 주기 위해서는 굉장히 번거로운 과정들이 있을 건데 그런 부분들이 체인이 알아서 간소화해 줘서이 챗 모델이라고 하는 표준화된 형식으로 통일을 해 줍니다 그래서 각각의 AI 모델들은 챗 엔트로픽 챗 오픈 AI 등등의 이름을 가진 클래스로 선언 할 수 있는데이는 모두이 챗 모델이라고 하는 컴퍼넌트의 종류이기 때문에 똑같은 성질을 가지고 있습니다 마찬가지로 정말로 다양한 원본 데이터를 활용해서 l&m 서비스를 만들 수 있습니다 우리가이 서비스에 맥락을 주입하고 데이터를 를 주입할 때 그 데이터는 pdf's 올 수도 있고 워드 문서에서 올 수도 있고 다양한 출처에서 올 수 있습니다 이렇게 다양한 소스에서 오는 데이터를 체인은 도큐먼트 아고 하는 표준화된 컨테이너를 이용해서 관리합니다 어떤 소스는 체인의 컴포넌트를 통해서 다양한 소스의 데이터들은 그 데이터 안에 있는 텍스트를 표현해 주는 페이지 콘텐트 그리고 데이터의 부가 정보를 담고 있는 메타데이터이 두 개로 이루어진 도큐먼트 아고 하는 형태로 표준화를 해서 우리는 도큐먼트를 다루고 도큐먼트를 가공하고 도큐먼트를 쪼개고 등의 작업들을 하게 됩니다 지금 가져온 코드는 링 틴으로 작성된 레그 코드인데요 여기서도 지금 AI 모델 부분은이 한 줄입니다 지금은 채 GPT GPT 4o 미니 모델을 쓰고 있는 컴퍼넌트를 활용하는데 만약에 우리가이 코드에서 AI 모델을 클로드로랭 1을 활용하면 재활용 가능한 코드를 작성할 수 있습니다 자주 쓰이는 주요 컴포넌트는 다음과 같은데 그래서이 주요 컴포넌트들의 성격만 잘 알고 있으면 어차피 표준화된 형태로 관리가 되기 때문에 다른 세부적인 클래스들은 쉽게 습득할 수가 있습니다 랭의 세 번째 특징은 체이닝 있니다 우리가 자주 활용하는 주요 컴포넌트를 쉽게 연결을 해서 우리 l&m 서비스가 어떤 로직으로 데이터를 주고받고 전달을 하는지 선명하게 보여줄 수 있습니다 제가 앞서 말씀 말씀드린 주요 컴포넌트들의 공통점들이 있습니다 100% 아니지만 대부분의 컴포넌트는 인풋이 있으면은 그 인풋에 대해서 아웃풋을 주는 형태로 구성되어 있습니다 예를 들어서 프롬트 템플릿이고 하는 컴포넌트는 이런 딕셔너리 형태의 데이터를 받으면은이를 기반으로 완전한 형태의 메시지 프롬프트를 만들어 줍니다 챗 모델이라고 하는 컴퍼넌트는 프롬트 또는 질문 또는 메시지라고 하는 인풋을 받으면 그 메시지에 대한 응답 결과 그리고 관련 부가 정보를 담고 있는 결과값을 아웃풋으로 줍니다 PDF 주로 다루는 PDF 로더는 컴퍼넌트는 우리가 인풋으로 PDF 파일을 주면은 도큐먼트의 리스트 형태로 아웃풋을 반환을 해 줍니다 텍스트 스플리터고 하는 컴포넌트도 인풋으로이 다큐먼트 리스트를 주면이를 다시 재조합하고 더 잘게 쪼개거나 등의 방식으로 또 도큐먼트 리스트를 반환을 해 줍니다 이렇게 컴포넌트들이 인풋과 아웃풋 형태로 이어져 있기 때문에 여러 개의 컴포넌트를 연쇄적으로 연달아서 연결을 해서 첫 번째 컴포넌트의 아웃풋이 그다음 컴포넌트의 인풋으로 그대로 보내질 수 있도록 할 수 있습니다 예를 들어서 이런 딕셔너리가 있으면이를 우리는 프롬트 템플의 인풋으로 넣어 주면이 프롬트 템플릿은 완성된 프롬프트를 아웃풋으로 줍니다 그 아웃풋은 챗 모델이라고 하는 컴포넌트의 인풋으로 들어가서 응답 결과가 포함된 아웃풋이 나옵니다 그리고 마지막으로이 챗 모델의 아웃풋 중에서 실제로이 챗 모델이 응답한 텍스트 결과만 뽑아내는 내용이 최종 출력 결과로 나오도록 하나의 체인을 구성을 할 수가 있습니다 이런 체인은 실제로 코드상에서 구현을 할 때도이 파이프라고 하는 특수 기호로 쉽게 연결을 할 수 있습니다 그래서 지금 이렇게 시각화에서 보여준 체인도 실제로 코드에서도 프롬트 템플릿이 파이프 챗 오픈 AI 파이프 스트링 아프 파서 형태로 표현할 수가 있습니다 그리고 이런 체인에서 크라는 메소드를 이용하면 실제로이 체인에 들어갈 인풋을 넣어주고 그 체인의 최종 결과 값을 받아볼 수가 있습니다 그래서 우리가 레 체인을 접할 때는 제일 중요한게 인풋과 아웃풋이 있는 주요 컴포넌트들을 완벽하게 이해를 해 주는 것입니다 랭지 홈페이지에서도 이런 주요 컴포넌트를 빌딩 블록이라고 표현을 하고이 주요 컴포넌트는 이렇게 여덟 개 정도로 정리가 되어 있습니다이 컴포넌트들이 구체적으로 어떤 인풋을 받고 어떤 아웃풋을 주는지 이것만 집중적으로 봐도 아 랭 체이 이렇게 인풋과 아웃풋으로 이루어진 컴포넌트들을 조합해서 만드는구나 를 정확히 파악할 수가 있습니다 그 주요 컴포넌트에 대해서 정말로 잘 소개가 된 문서가이 랭 체인 공식 홈페이지에 있는 컨셉츄얼 가이드라고 하는 문서인데 제가 이거 영상 하단에 링크를 첨부해 두겠습니다 여기 컴포넌트를 눌러 보면은이 조요 컴포넌트들이 어떤 인풋과 어떤 아웃풋으로 이루어져 있고 어떤 기능을 하는지 굉장히 자세하게 설명이 되어 있기 때문에 여러 번 읽어 보시는 것을 추천드립니다 두 번째로 말씀드리고 싶은 건 랭 체인에서 분명히 복잡하고 잘 이해가 안 되는 체인들도 많은데 그런 체인들은 일단 넘어가거나 아니면은 내가 이해 가능한 주요 컴포넌트들의 조합으로 이루어져 있는 형태로 풀어서 활용을 하는 것입니다 예를 들어서 레그를 표현하는 예제 코드 중에서도 아이 랭 체인에서 자체적으로 제공하는 크레이트 리트리버 체인이나 크이 st 도큐먼트 체인 같은 체인들이 있는데 사실 이렇게만 보면은 체인이 지금 어떤 주요 컴포넌트들을 가지고 있고 어떻게 인풋과 아웃풋으로 구성이 되어 있는지 잘 이해가 가지 않고 내가 제대로 활용하기가 까다로운 부분 들이 많습니다 그런데 이런 체인들도 실제로는 이렇게 주요 컴포넌트들을 파이프로 연결한 형태로도 똑같이 표현을 할 수가 있습니다 지금 앞에 나와 있는이 레그 체인이 코드는 지금 뒤에 있는이 레그 체인고 완전히 동일한 기능을 가지고 있습니다 그래서 우리는 최대한 주요 컴퍼넌트 둘로 이루어진 형태로 체인 대를 풀어서 쓰거나 너무 추상화가 돼서 너무 구체적인 내용이 안 보여지는 체인들은 가급적이면 지향을 하는 것이 좋은 거 같습니다 마지막으로는 그래서이 랭 체인을 다루 에는 필요한 로직을 위주로 부분적으로 내 서비스나 내 프로그램에 활용하는 것이 제일 좋은 거 같습니다 링치 인은 표준나사 아이 특징 때문에 LM 서비스를 처음 개발하려고 하는 분들이 쉽고 빠르게 MVP 만들고 이미 주어져 있는 예제 코드를 활용해서 빠르게 뭔가를 구현하기에는 굉장히 좋은 툴입니다 그런데 조금만 더 내가 구현을 하고자 하는 대상이 구체적이고 또 내가 데이터 수집부터 프런트까지 단계별로 커스트마이징을 하거나 수정을 하거나 튜닝을 할 부분들이 많아질수록 랭 체인만으로 100% 되는 부분들은 안정적입니다 그래서 코드 전체를 랭 체인으로 무조건 해야 되겠다라는 생각보다는 빨리빨리 구현하고 내가 100% 이해할 수 있는 부분만 부분적으로 랭 체인의 주요 컴포넌트를 활용하면 좋을 것 같습니다\")]},\n",
       " {'id': '1scMJH93v0M',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC8Bbvnyigui44yjlyGJQCfFV7MqA',\n",
       "   'https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBIUwbKKCmlPJKcw2nTifu92hXaZg'],\n",
       "  'title': '#langchain 의 #RAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작',\n",
       "  'long_desc': None,\n",
       "  'channel': '테디노트 TeddyNote',\n",
       "  'duration': '21:47',\n",
       "  'views': '조회수 41,428회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=1scMJH93v0M&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=1scMJH93v0M&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': '1scMJH93v0M'}, page_content='안녕하세요 오늘은 레그에 대해서 알아보겠습니다 레그에 대해서 잘 아시는 분도 계시고 처음 들어보시는 분도 계실 것 같아요 요즘에이 레그라 주제가 굉장히 핫한데라는 것은 뭐의 약자면 retrial augmented generation 요렇게 해가지고라고 부르는데 rri 하면은 추출의 의미를 가지고 있고요 어그멘티드 하면은 뭐 데이터 증가 그다음에 제네레이션 어떤 데이터로부터 우리가 원하는 내용을 추출해서 우리가 원하는 답변으로 lml 활용해서 만들어내는 거 요거에 전반적인 프로세스를 우리가 레그라 부릅니다 자이 레그가 요즘에 굉장히 핫한 이유가 lml 활용할 때 이런 경험이 있으실 거예요 만약에 채치 PT 테 우리가 다양한 질문을 던질 수가 있죠 그러면 채치 ptga 정말 똑똑하니까 잘 답변을 해 줘요 그런데 채지 피티가 이런 걸 할 수 있을까요 우리 회사의 내규 중에서 뭐뭐를 알려 줘 이런 거 모르죠 왜냐면 얘는 우리 회사의 내규 정보를 모르고 있기 때문이에요 그러면 우리가 원하는 건 뭐냐면 채체 피티한달 정보를 먼저 던져 줍니다 근데이 정보가 압축적이다 참 좋을 텐데 어 우리 회사 내규의 정보가 200페이지에 그러면이 중에서 우리가 원하는 내규 정보 정보를 찾으려면 시간이 굉장히 오래 걸리죠 이런 것들을 우리가 레그라는 걸 통해서 서비스로 만들 수가 있는 거죠 200페이지 짜리를 쥐어주고 그다음에 우리가 어떤 질문을 던지면이 200페이지 중에서 우리 질문에 답변할 수 있는 데이터들을 먼저 추출을 하는 거 rri 하는 거죠 그다음에이 추출된 거를 그대로 우리한테 토해내는게 아니죠 그냥 추출된 걸 주면은 그거는 그냥 DB 검색이 DB 검색 DB 검색입니다 근데 그냥 DB 검색이 아니라이 추출된 내용을 우리 질문에 맞게 이러이러 합니다라고 친절하게 답변을 만들어서 는 거죠 그래서이 리그라는 기술이 많이 주목받고 핫해진 이유 자체가 더 이상 채치 PT 일반화해서 학습한 정보를 답변하는 걸 원하는게 아니라 우리 회사 정보 우리가 가지고 있는 정보 우리만의 어떤 법률 정보 우리만의 어떤 마케팅 정보 기반으로 답변해 줘 뭐뭐를 기반으로 답변해죠 요렇게 하려면 레그 기술을 잘 활용해서 어 qa 시스템을 만들어야지 된다라는 거죠 사실이 레그에 대해서 깊게 다뤄 보려면 정말 영상의 길이가 길어질 수밖에 없습니다 그렇지만 여러분들이 찍먹 수 있을 정도 수준의 튜토리얼을 가지고 와 봤고요이 찍먹 mas 알려 드리면 좀 재미가 없어요 왜냐면은 다른 데서도 많이 하는게이 레그의 찍먹 수준이거든요 근데 여기서 더 나아가서 우리가 어떤 점들을 개선할 수 있는지를 같이 한번 보실게요 자 먼저 레그 개발을 위해서는이 전반적인 흐름에 대해서 알고 계셔야 됩니다이 레그 프로세스는 데이터로드 데이터를 불러오는 거 그다음에 불러왔으면 분할하는 거 임베딩 하는 거 벡터 디비에 저장하는 거 그다음에 저장을 했으면 이제 사용자가 질문을 하겠죠 질문을 하면은이 질문을 기반으로 데이터에서 검색해서 원하는 내용을 발제를 하고 발췌된 내용과 프롬프트를 더해 가지고 l&m 넣어서 우리가 원하는 답변으로 이끌어내는 이런 큰 흐름을 머릿속에 가지고 계시는게 좋아요 근데 우리가이 랭 체인을 쓰면은라는 걸 개발할 때 굉장히 편리하죠 왜냐면 지금 여기에 제가 단계를 나눠 놨는데이 나뉘어진 단계 안에서도 세부 태스크들을 굉장히 많아요 예를 들면 데이터로드 할 때 우리가 PDF로드 할 건지 워드 문서를 로드할 건지 아니면 웹페이지를 로드할 건지 이미지를 로드할 건지 그밖에 엄청나게 많은 데이터를로드 할 수가 있어요 근데 우리가 만약에 에 PDF로드 할 거야 워드로드 할 거야 이거를 다 파이썬 코딩으로 구현하려 그러면 머리 빠지죠 그런데이 랭 아인에서 통합된 인터페이스라는 표현을 써요 네가 알고 있어야 되는 거는 한 개에 통합된 함수 하나만 알면 돼 뭐 예를 들면은 로드라는 함수만 알면 돼 그리고 앞단에서 내가 여기다가 워드 문서를 넣으면은 워로드 뭐 웹페이지 넣으면 웹페이지로드 뭐 요런 식으로 해 줄게 네가 앞에 것만 바꿔 주면 돼 뭐 이런 식으로 통합된 페이스로 개발을 해 놨기 때문에 우리는 랭 체인을 사용하면은 굉장히 여러 종류의 문서를 손쉽게 로드할 수 있는 거 그런 것들이 있고요 그래서이 랭 체인을 써서 레그를 사용하면은 개발이 굉장히 쉬워진다고 보시면 돼요 랭 체인을 쓰면은 어떤 레그의 품질이 좋아진다 이런 측면이 아니에요 이런 측면이 아니라 개발이 굉장히 속도가 붙고 그다음에 편리하다 그렇기 때문에 생산성이 좋다 이렇게 설명드릴 수 있습니다 자 그래서 여기 보시면 이제 로더 터 차례대로 저희가 나가 볼 건데요이 프로세스는이 프로세스는 거의 변하지 않습니다 변하지 않기 때문에 여러분들이 이번 영상에서는 어떤 큰 그림을 한 번씩 체험해 보시는 거고요 어 나는 이번 튜토리얼에서는 저희가 웹페이지를 볼 건데 웹페이지가 아니라 다른 걸 로드하고 싶은데 예를 들어서 PDF 로드하고 싶은데 이러면은 다른 모듈을 로드하는 거 그거 응용하시면 거죠 그니까 큰 틀만 잡고 있으면요 사이에서 바꾸는 거는 충분히 쉽다 이렇게 말씀드릴 수 있을 것 같아요 바로 한번 가보시죠 자 먼저 환경 설정하고 자이 환경 안에서는 제가 랭 스미스 API 써 가지고 저희가 실행하는 모든 것들을 다 트레이싱을 할 거고요 그다음에 llm 오픈 AI 앱 API 키 어 설정해 주도록 하겠습니다 레그 튜토리얼 이렇게 설정해 주고 자 그리고 뭐 필요한 모듈도 임포트 해 오고요 첫 번째로는 저희가 네이버 뉴스를 가지고 올 거거든요이 네이버 뉴스를 가져올 때 웹베이스 로더는 걸 쓰면은 어 손쉽게 웹페이지의 내용을 크롤링해서 결과로 가져올 수가 있어요 뉴스 기사가 이렇게 나와 있습니다 굉장히 훈훈한 기사여서 요거를 한번 가지고 와 봤고요 자 여기서 우리가 궁금한 거는 여기 안에 있는 내용들이죠 이걸 가져와야 돼요 우리가 원래는 파이썬으로 뭐 크롤러 써 가지고 뷰티풀 수비나 아니면은 셀레니움 써 가지고 이거 긁어 와야 되죠 랭 체인의 웹베이스 로더 쓰면 는 쉽게 가져옵니다 어떻게 가져오냐 먼저 우클릭해서 요소 검사를 하신 다음에 여기 안에 우리가 가지고 오고자 하는 요소를 클릭해요 요렇게 바디를 클릭합니다 클릭하면 여기 dib 해 가지고 뉴스 CT 언더바 아티클이 되어 있고 클래스 네임도 되어 있죠 만약에요 내용을 가지고 오고 싶어요 그러면 아이디로 가지고 오셔도 되고 아니면 클래스 네임으로 가지고 오셔도 됩니다 요거를 복사를 해요 복사를 하신 다음에 여기 비주얼 스튜디오 코드에서 요거 붙여 넣게 하면 되는 거예요 제가 방금 복사한 내용이거든요 바디 부분 요거는 이제 뉴스 기사의 타이틀도 가지고 오고 싶어서 이렇게 넣었습니다 di 는 태그에 여기에 지금 DI 태그로 붙어 있는 어 클래스 어트리뷰트 클래스 속성값이 그니까 요거 있 놈과 요거 있 놈을 가지고 와라라고 한 거예요 이걸 한번 실행해 볼게요 실행하면 뉴스 기사의 본문을 기가 막히게 쉽게 잘 가져오는 것을 볼 수가 있어요 자 만약에 여러분들이 웹사이트에서 크롤링해서 가지고 와야 된다라고 했을 때는 여기에 들어가는 유아를 바꿔 주시고 방금 요소 검사해 가지고 그 클래스의 이름 바꿔 주시면 가지고 오실 수가 있거든요 근데 나는 웹페이지를 가지고 올게 아니라 PDF 문서를 로드하고 싶은데요 하시면은 로더를 PDF Pro 가지고 오시면 돼요 제가 작성하고 있는 다큐먼트 로더는 문서에 보시면은 PDF 로더가 있거든요 요거를 가지고 오는 거죠 여기 보면은 다큐먼트 로더스 아는 모듈 안에서 PI PDF 로더로 가지고 오죠 요게 이제 PDF 문서의 제목이 아아 그 요거를 복사해서 뭐 대신 쓰면 될까요 로더 대신 요거 대신 요거를 주석 치고 이렇게 가져오면 되는 그럼 어때요 얘는 웹문서에서 가져오는 거고 어 내가 이번에 PDF에서 가져올 거야 요거 가져오는 거죠 자 이거 로드해 보죠 문제없이 동작을 한다거 이게 정말 랭 이인이 잘만 거죠 그러니까 랭 체인이 어 너 왼 문서 가져오고 싶어 그럼 이거 써 그리고 너 PDF 가지고 오고 싶어 이거 써 대신 이거 함수는 네가 안 건드려도 돼요 앞단 네가 바꿔 주면 돼 PDF 할 때는 PDF 로더 쓰면 되고 웹베이스 로더 쓰면은 웹베이스 로더 쓰면 돼 예제로 작성해 놓은 파일들을 보면은 여러 가지 형태의 파일들을 이렇게 가지고 올 수 있습니다 아래쪽에 보면은 폴더를 지정하면 폴더 안에 있는 내용들 전부 다 가져오는 것도 가능하고요 그리고 csb 가져오는 거 html 문서도 가져오실 수가 있고 그리고 뭐 제이슨 형태나 그밖에 파이 파일 등등 다양한 문서들을 이렇게 가지고 오실 수가 있어요 다 보면은 로더 점 로드는 똑같죠이 앞에 있는 부분만 바꿔 주시면 되는 거예요 나중에 여러분들이 PDF 가지고 하고 싶다면 요것만 바꿔 주시면 되겠죠 다시 뉴스 기사 내용 볼게요 이렇게 해서 뉴스 기사의 본문을 잘 가지고 왔습니다 메타데이터에 보면은 어느 소스에서 가져온 건지 URL이 잘 들어가 있는 것을 볼 수가 있고요 다음으로 보시 내용이 이제 스플리터 있니다 자 우리가 로드를 했으면 그다음으로 해 주셔야 되는게 스플릿이 그럼 스플릿은 언제 쓰는 거냐 스플릿은 청크를 만들 때 씁니다 데이터 청크를 만들 때 데이터 청크는 거는 뭘까요 우리 l&m 보면은 대표적으로 GPT 모델 볼게요 GPT 3.5 4등 무한정으로 텍스트를 받아들일 수 있는 건 아니잖아요 그런데 우리 문서의 길이는 얘가 받아들일 수 있는 양보다 클 수 있어요 더 쉬운 예를 들어 볼게요 만약에 PDF 문서를 로드를 했는데 PDF 100장짜리 LM이 받아들일 수 있는 거는 한 번에 열 장까지 밖에 못 받아들여요 그럼 100장짜리 얘한테 넘기면 어떻게 될까요 그러면 에러가 떨어지죠 어 얘가 허용할 수 있는 거는 10장까지만 받아들일 수 있는데 당신 100장 넘겨주면 어떡합니까라고 해서 에러가 떨어집니다 그럼 우리 어떻게 해야 될까요 열 장보다 작은 단위를 넣어 줘야 되는 거예요 그래서 우리는 뭐 어떤 걸 하냐면 분할이라는 단계를 수행하는 거죠 분할을 해 가지고 100장짜리 문서를 잘게 쪼개 놓는 거예요 뭐 사실 열 장으로 곱하기 개 이렇게 쪼개도 되죠 근데 보통 이렇게 쪼개는 경우는 잘 없어요 더 잘게 쪼개다 글자수 단위로 쪼갤 수도 있고 뭐 토큰 단위 뭐 여러 가지 단위 기준으로 쪼갤 수 있어요 여기서 중요한 거는 뭐 어떻게 쪼개냐 이것도 중요한 포인트가 될 수 있어요 하지만 여기서 중요한 거는 쪼갠다는 거 근데 여기서 쪼갤 때도요 여러분들이 신경 써 주셔야 되는 포인트가 있어요 100장짜리 문서에서 하나의 주제를 다룰 때 보통 한 장 정도 분량을 하나의 주제로 다르고 그 하나의 소 주제라고 보시면 되겠죠 이게 한 100개 정도 있는 거예요 그래서 100장짜리 됐어요 그러면 여러분들이 만약에 10장씩 쪼이면 어떻게 될까요 한 장에 하나의 소주제가 맵핑이 되어 있는데 열 장씩 끊으면이 열 장 안에는 열 개의 소주제가 난립해 있겠죠 우리가 어떤 질문을 할 거예요 질문했을 때 쪼개진 단위에서 하나의 대표적인 단락을 가지고 올 거거든요데 단락을 가졌는데 봤더니 열개의 주제가 짬뽕 돼 있어 그러면은이 짬뽕 되어 있는 주제가 나중에 l&m 쪽으로 흘러 들어갈 텐데 아무래도 품질이 떨어질 거잖아요 그러니까 제가 드리고 싶은 말씀은 쪼갤 때도 이왕이면 내가 어떤 질문을 하면은 그 질문을 포함하는 범위만 깔끔하게 쪼개지면 가장 베스트 겠죠 그 단위가 얼마나 되는지는 저도 모르죠 문서마다 너무 달라집니다 문서마다 이런 것들을 최적화는게 중요하고요 사실 문서마다 다 다르기 때문에 우리가 이거를 아 최적 하기는 사실 거의 불가능해요 이거는 여러 가지를 테스트해 보면서 어느 정도로 쪼개는게 어 우리 상황이 맞는지 그런 것들을 확인해 보시는게 중요합니다 자 그러면 여기 리커시브 캐릭터 텍스트 스플리터는 걸 써서 쪼개 쪼개는데 청크 사이즈라는 거는 쪼개는 단위 뭐 글자수 정도라고 생각하시면 되고요 청크 오버랩을 뭐냐면 우리가 쪼갤 때 문단을 자를 때 이렇게 자르고 이렇게 자르나요 그러면 어떻게 되죠 만약에 어떤 내용이 여기 끝부분에 나오고 여기 끝부분에 나올 수가 있어요 이렇게 걸쳐 있을 수도 있잖아요 그렇기 때문에 오버랩이란 걸 줍니다 그래서 우리가 이렇게 가운데 부분을 뚝 자르는게 아니라 문서 하나가 있고 이렇게 겹쳐져서 가져올 수 있도록 쪼개진 단위에서 시작이 어색하지 않도록 앞에 있는 내용을 좀 포함할 수 있도록 그게 보통은 오버랩을 주는 편이에요 그래서 이거를 해석을 하자면 최대 1 글자 단위로 쪼갤 건데 중간에 50 글자 정도는 겹치게 가져와라 요런 의미로 보시면 될 거 같아요 자 그래서 스플릿 도큐먼트 씁니다 쓰면은 요거는 굉장히 짧은 문서아 자 짧은 문서인데 몇 개로 쪼개져 있는지 한번 볼게요 자 렌에 스플릿을 찍어 보면 세 개의 문서로 쪼개진 거를 볼 수가 있어요 기사가 길지 않다 보 까 세 개의 문서로 쪼개진 거죠 자 다음으로는 이제 임베딩 하고 벡터 스토에 저장하는 거예요 우리가 나중에 검색을 할 거예요 검색을 해서 가져올 건데 예를 들어서이 신문 기사에 기사의 내용을 바탕으로 우리 질문할 거예요 뭐 가령 출산 직원에게 얼마를 샀습니까 아는 질문을 던져요 그러면 얘는 얼마를 쌓느냐라는 질문과 유사도가 높은 문단을 발라낼 거예요 발라내서 그걸 기반으로 얼마를 쐈는지 유치를 하게 됩니다 자 그러면이 문단이 예를 들면 이렇게 쪼개져 있고 뭐 한 요렇게 쪼개져 있었어요이 1번 문단이 있고 2번 문단이 있고 3번 문단이 있어요 그럼 출산 직원에게 얼마를 샀습니까라는 거를이 각 문단별로 유사도 계산을 해요요 내용이 들어가 있으면은 유사도가 아무래도 높게 나올 가능성이 높겠죠 얘가 유사도가 높게 나오고 얘가 그다음으로 높게 나오고 얘가 마지막으로 높게 나왔어요 그러면 얘는 어떤 액션을 취하면요 문단을 가져와서이 안에서 얼마를 썼는지 그 답변을 생성에서 주게 되는 거예요 자 그런데 그 유사도 계산하려면 우리가 필요한게 임베딩이란게 필요하고요 우리가 그냥 문장으로 들어가 는게 아니라 이거를 어 벡터 표현으로 변환 합니다 오픈 아이의 임베딩은 1536 차원의 어떤 벡터 공간에다가 우리가 질문한 내용들을 임베딩 해서 어떤 좌표계로 만들어 두는 거예요 좌표계로 만들어서이 스라는 벡터 DV 다가 저장을 해 둡니다 그서 요거는 이제 벡터 스토어를 생성하는 그런 로직이 이렇게 생성을 했으면 그다음에 리트리버를 가져오는 자요 코드와요 코드는 어떻게 보시면 되냐면 지금 DB 뉴스 기사를 저장하죠 저장하는 단계가 바로요 코드예요 근데 우리가 저장만 한다 라고 해서 여기서 검색해서 쓸 수 있는 건 아니에요 검색을 하려면 뭐가 필요하냐면 리트리버가 필요하죠 그래서이 DB 리트리버를 가져오는 거예요 자 우리가 저장만 한 거예요 요거는 저장만 한 거고 우리가 나중에 리트리버를 통해서 우리가 원하는 단락을 검색을 할 겁니다 그때 쓸 거예요 자 그래서 리트리버까지 가지고 왔고요 다음으로는 프롬프트 있니다 프롬프트는 레그 프롬프트는 걸 쓸 건데 허브점 풀을 하죠이 허브는 어디냐면 랭 체인의 허브에요 아 이거 정말 저는 추천드립니다 제가 지금 보여 드릴 거는 랭스 이스의 허브라는 건데 여러분들이 프롬프트 엔지니어링을 하려면 굉장히 많은 시간이 들어가잖아요 근데이 랭스 이스의 허브에 오셔서 qa 오벌 도큐먼트 뭐 체보 에이전트 여러 가지 카테고리로 잘 정리가 되어 있거든요 여기 있는 미리 만들어 놓은 좋은 프롬프트 그냥 가져다 쓰시면 돼요 우리 레그를 할 거니까 레그라 입력을 하고이 중에서 어 탑비드 요걸 입력하면요 rlm이라는 거에 슬래시 하고 레그 빼기 프롬트 이렇게 나오죠 자 요거에 프롬프트를 내가 쓰고 싶어요 밑에 내려 보시면은 어떤 식으로 프롬프트 입력됐는지 이거 복사해도 쓰실 수 있거든요 근데 이럴 필요 없이 여기 밑에 코드도 나와 있네요 여기에 있는 이름을 복사를 합니다 복사를 하고 여기 여기 오셔서 붙여 넣기를 하고 그다음에 허브점 프 하면은 여러분들이 업로드되어 있는이 프롬프트를 바로 가져다 쓸 수 있는 거예 근데 여기 인풋 베리에 보면은 퀘는 사용자가 입력하는 질문이 들어갈 거고요 그다음에 컨텍스트에는 우리가 문서를 지금 여러 개 쪼개 아아 그다음에 어떤 질문 하면은이 중에 과장 관련성 높은 문서를 뽑을 거예요 그리고 그 뽑힌 문서가 컨텍스트로 들어가는 거예요 그러면 우리의 답변은이 뽑힌 문서에 대한 답변을 생성해서 얘가 주는 거 이런 식으로 동작합니다 컨텍스트에는 리트리버 여기 이전에 벡터 스토어에서 검색기 가져 왔잖아요 검색 로 검색한 결과 그러니까 퀘에 대해서 가장 연관성이 높은 단락을 가져올 거거든요 그 단락이 여기에 있는 컨텍스트로 들어간다고 보시면 됩니다 다음으로 필요한 거는 이제 l&m이에요 지금 우리 단계는 리트리버가 만들었잖아요 검색 기까지 만들었으면 트도 만들었고요 그다음에 이제 LM LM 브레인에 해당하는 거예요 두 뇌저 두뇌 IQ 100인 사람이 있고 IQ 200인 사람이 있어요 똑같은 문서와 똑같은 프롬프트를 주더라도 200 인상이 더 잘할 가능성이 높잖아요이 IQ 해당하는게 LM이라고 보시면 돼요 여러분들의 상황에 맞게 쓰시면 되는데 아 물론 우리가 제일 좋은 gpt4 모델 쓰면 좋겠죠 근데 이걸 쓰려고 보면은 속도 문제도 있지만 비용적인 측면도 꽤 크잖아요 그럼 나는 비용 좀 저렴하게 가고 싶다 GPT 3.5를 가도 되고 나는 아예 무료로 쓰고 싶다 그럼 허깅 페이스에 오픈 소스 모델 쓰시면 됩니다 이런 것들도 교체도 자유롭고 여러분들이 상황에 맞게 쓰시면 돼요 저는 GPT 3.5 터보 모델을 쓸 거고요 소소한 팁 하나를 드리자면 어 한글 관련된 처리는 GPT 4 모델 있죠 GPT 4의 터보의 프리뷰 모델 훨씬 더 좋습니다 근데 요 영어로 된 처리하는 거는 3,5 터보가 가성비가 좋죠 그거는 알아서 상황에 맞게 쓰시면 되고요 자 그다음에 포맷 도큐먼트 요거는 뭐 해 주는 거냐면 검색한 문서 결과를 하나의 문단으로 합쳐 주는 거죠 자이 검색을 할 적에 얘는 단락을 하나만 뽑는 건 아니에요 우리가 정할 수 있는데 단락을 두 개를 뽑을 수 있고 세 개를 뽑을 수 있어요 만약에 신문기사의 주제는 무엇입니까라고 물어봤어요데 단락이 1번 2번 3번 이렇게 쭉 많아요이 중에서 주제가 한 군데서만 나오는 건 아니잖아요 여러 군데에서 핵심 아이디어가 나올 수 있잖아요 그렇기 때문에 유사도 제일 높은 거 하나만 뽑는 경우는 잘 없고 잘게 쪼개 놓은 데에서 뭐 세 개를 뽑든 다섯 개를 뽑든 열 개를 뽑든 이렇게 n 개를 뽑는 거예요 뽑으면 여러 개의 문서가 될 거잖아요이 여러 개의 문서를 하나로 합쳐 가지고 하나의 문장처럼 만들어서 넣어 주기 위해서 있는 함수가 바로이 포맷 도큐먼트고 보시 자 그래서 마지막으로 완성되는게 바로요 체인이에요 렇게 하면 완성이 되는 건데 다시 한번 복습해 볼게요 자 우리가 질문을 하잖아요 질문을 하면은 그 질문 내용이 여기에 들어가요 패션이라는 키값에 러너블 패스 스루로 들어갑니다 들어가면이 질문 기반으로 얘가 여기에 있는 리트리버 리트리버는 검색을 수행해요 그니까 만약에 출산 정책이 어떻게 됩니까라고 하면은이 출산 정책이라는 키워드와 가장 연관성이 높은 단락을 이렇게 쭉 뽑아 내요 그게 바로 리트리버 하는 역할이고 여러 개의 단락을 뽑아 냈으면 이거에 하나의 문장으로 합쳐준게이 포맷 박스요 그러면 리트리버의 역할은 내 질문의 연관성이 높은 단락을 뽑아 주는 역할을 하는 거고요 그럼 이거 하나로 로 문장을 연결지어서 나오게 되는 거죠 결국에는 여기서는 요게 중요한 거예요 내가 사용자가 질문을 던진다 그 질문을 바탕으로 연관성 높은 도큐먼트를 서칭을 한다 서칭 된 결과를 하나로 합친다 그러면이 하나로 합쳐진이 문장은 질문과 연관성이 높은 단락에 그냥 하나로 이어진 문장이 되는 거예요 그 문장을 프롬프트 테 넘겨 주는 거죠 넘겨 주고한테 생각해서 결과를 달라라고 하는 거예요 그러면 주어진 주어진 정보라고 하면 리트리버를 통해서 검색된 정보를 의미합니다 주어 정보와 그다음에 사용자의 질문 등을 고려를 해서 원하는 답변을 주게 되는 거죠 요렇게 만들어 주는 체인을 생성을 해보고요 자 그러면 한번 질문을 해 볼게요 자 요런 신문 기사입니다 출산 직원에게 1억 원 쏜다 격적 저출생 정책이라는 기사이고 저는 요렇게 한번 질문을 던져 볼게요 부형 그룹의 출산 장려 정책에 대해서 설명해 주세요라고 질문을 하면요 자 요렇게 답변을 줬네요 출산 장려 정책으로 2021년도 이후에 태어난 자녀에게 1억 원씩 지급을 하고 쌍둥이 자녀가 있을 경우에 2억원 지급한다 셋째 의 자녀를 나을 경우에는 주택을 제공하겠다는 계획을 밝혔다 자이 내용이 맞는지 볼까요 자 여기에 그 내용이 있네요 자녀의 1억 원씩 쌍둥이 자녀가 있으면 2억원 받고 그다음에 국민 주택을 제공하겠다는 뜻도 밝혔습니다 잘 나와 있어요 여기에서이 단락이 아마 인풋으로 들어갔을 거예요 이거를 랭 스미스에 가면은 확인해 볼 수가 있거든요 자 여기 보시면 제가 질문이 요렇게 들어갔잖아요 출산 장려 정책에 대해서 설명해 주세요 그러면 아웃풋이 렇게 나왔는데이 리트리버가 어떤 도큐먼트를 뽑았냐 요런 도큐먼트를 뽑았어요 이게 그 오픈 AI GPT 4에 들어간거든요 도큐먼트를 한번 보면은 요게 첫 번째 출생 정책 그다음에 음모한 것도 있다 뭐 요런 식으로 되어 있고 그다음에 마지막으로는 요렇게 들어가 있는 거죠 아마 여기 유용한 정보들이 들어가 있잖아요 요거를 뽑아 가지고 줬을 것 같아요 랭 스미스를 활용하시면 리트리버가 어떤 도큐먼트를 이렇게 검색을 했고 이거를 l&m 테 넘겨 줬는지 볼 수가 있거든요 챗 오픈 AI 들어가 있는 입력을 보시면 지금 컨텍스트에 요렇게 들어가 있잖아요 신문 기사의 내용 자 이거 어떻게 발치를 한 거죠 내가 질문한 거 기반으로 리트리버부터 검색을 해서 그 문단들을 하나로 이어붙여 가지고 주는 거죠 그러면이 주어진 정보를 바탕으로 부형 그룹의 출산 장려 정책에 대해서 설명해 주세요라는 퀘이 들어왔기 때문에 이거를 바탕으로 지금 답변을 주는거다 이렇게 보시면 됩니다이 뉴스 기사는 짧아 가지고 거의 모든 기사의 내용이 다 들어갔을 것 같긴 한데요 PDF 문서의 내용이 굉장히 길 경우에는 레그를 잘 써서 중요한 정보가 여기 안에 포함되는게 반드시 필요하고요 그거에 따라서 성능이 많이 달라지고이 랭 스미스를 활용해서 리트리버가 원하는 단락을 잘 뽑아냈는지 하나하나 보면서 디버깅 하는게 선행이 돼야 돼요 lml 아무리 좋은 걸 쓰면 뭐 합니까 여기서 발라내는 결과가 좋지 못하다면 아무리 좋은 lml 써도 결과가 만족스럽지 못하실 거예요 그래서 랭스 미스의 리트리버의 우리가 쿼리를 날렸을 때 질문을 날렸을 때 답변을 하기 위해서 그 필요한 정보들이 여기 들어가 있는지 반드시 사전에 검출 해 주셔야 됩니다 그다음에 얼마에 지원을 제공하나요 요것도 한번 해 볼게요 이것도 해 봤더니 1억 원 지원한다 요것도 2억 원 지원한다 답변이 이렇게 잘 나오고요 그다음에 저출생 대책을 블랙포인트 형식으로 작성해 달라 내가 원하는 형식으로 출력을 요구할 수도 있는 이거는 l&m이 너무 잘해 주는 일 중에 하나니까 자 이렇게 했더니 블랙포인트 형식으로 깔끔하게 어 잘 정리해서 주는 것을 볼 수가 있고요 아 요거는 제가 재미삼아서 한번 넣어 봤는데 부형 그룹의 임직원 숫자는 몇 명인가요 이런 거는 기사에 없습니다 없는데 얘가 어떤 식으로 답변하지 볼게요 자 답변이 이렇게 나왔어요 임직원 숫자에 대한 정보는 제공된 문맥에서 확인될 수 없다 요거는 출산 장 정책과 관련된 내용을 다루고 있고 임직원 숫자에 대한 구체적인 정보를 얻기 위해서는 추가적인 자료가 필요하다라고 나오죠 얘가 할루시네이션 통해서 막 임직원 숫자는 뭐 80명 이니다 이런 식으로 얘기하는게 아니라 지금 얘는 제공된 문맥에서 확인할 수 없다라고 잘 대답을 하죠 그 비밀은 바로 이제 프롬프트에 들어가 있습니다 자 이게 프롬프트 든요 그러면이 프롬프트를 읽어 보시면 퀘 서링 태스크를 수행하고 있는데 요게 핵심이죠 답변을 모르면 그냥 모른다고 할 것이지 만들어 내지 말아라라는 프롬프트가 들어가 있기 때문에 이렇게 모르는 답변에 대해서 할루시네이션 어느 정도 방지해 주는 것을 볼 수가 있고요 제가 지금 썼던이 레그 프라프라 거는 가장 기본적인 프롬프트에 이거보다 훨씬 더 할루시네이션 스트릭트게 방지해 줄 수 있는 좋은 프도 많이 나와 있거든요 이런 것들을 여러분들이 추가해서 하면은 얘가 막 말을 지어내거나 하는 현상들을 많이 없애실 수가 있습니다 오늘은이 네이버 뉴스를 토대로 레그를 한번 살펴봤습니다데 오늘 제가 공유드릴 내용은 사실 어떻게 보면은 뼈대에 해당하는 내용이거든요 가장 기본적인 요소들을 모아다가 끝까지만 한번 훑어 본 거예요 답변을내는 것까지데 당연히 여기에 PDF 문서가 더 방대한 양의 자료가 들어가거나 문서가 여러 개가 되면은 난이도가 더 올라갈 거예요 그럴 때는 스플릿 하는 방식도 새롭게 고민 해 보셔야 되고 베딩도 바꿔 보셔야 되고 비도 여러 가지를 써 보시면서 테스트를 해 보셔야 됩니다 이거 하나하나마다 경우의 수가 굉장히 많은데요 그래도 다행스러운 점은 랭 체인은 통합된 인터페이스를 제공해 주기 때문에 우리가 쉽게쉽게 다른 방법들을 시도해 볼 수가 있어요 제가 앞으로 텍스트 스플리터 임베딩 벡터 스토어이 내용들을 를 계속 업로드를 할 예정이거든요이 업로드되는 내용들을 보시고 여러분들이 여러 가지 방법들로 한번 해 보시고요이 레그 2 자료는 요거를 모듈별로 좀 더 심도 있게 보는 내용이에요 혹시 관심 있으신 분들은이 레그 2 파일도 한번 보시면서 연구해 보시고요 또 궁금한 점이 있다면 댓글로 남겨 주시기 바랍니다 앞으로 제가 업로드할 파일들은 모두 랭 cein 한국어 튜토리얼이라요 기업 리파지토리에 올려 드릴 예정이고요 주소는 정보를 안에 넣어 놓도록 하겠습니다 관심 있으신 분들은요 안에 있는 튜토리얼 실행해 보면서 연구해 보셔도요 것 같아요 오늘은 외에 대해서 간단히 한번 알아봤고 오늘 영상은 여기까지입니다 [음악] 감사합니다')]},\n",
       " {'id': '84paXmEsjjg',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLARhrBfQwlUZu-kL78JiAK12VYMjA',\n",
       "   'https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCZHMGJ0GLCy1Fzpxt0GmCqTmCD5w'],\n",
       "  'title': '9장 LangChain + YouTube Transcript API +GPT-4o-mini  으로 유튜브 자막 추출부터 요약, 번역, 요점 정리까지',\n",
       "  'long_desc': None,\n",
       "  'channel': '오늘코드todaycode',\n",
       "  'duration': '12:07',\n",
       "  'views': '조회수 376회',\n",
       "  'publish_time': '3개월 전',\n",
       "  'url_suffix': '/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': '84paXmEsjjg'}, page_content='안녕하세요. NLP와 LM 실전 가이드 9장에 있는 책 어 312쪽부터 317쪽에 있는 유튜브 영상 요약하기를 실습을 진행을 해 보도록 하겠습니다. 일단이 책은 이제 원서 마스터링 NLP 어 from롬파데이션투 LLM 책의 이제 번역서인데요. 이제 원서의 실습 내용하고 조금 다르게 구성이 되어 있습니다.이 이제 원서 어의 이제 실습어요 그 코랩 링크를 통해서도 이제 바로 이제 들어와서 이렇게 보실 수가 있는데요. 여기에서는 이제 인베드 체인이라는 것을 이제 사용을 해요. 근데 인베드 체인이 어 유료로 어 변경이 되었고요. 그리고 여기 인베드 체인을 사용해서 이제 어떤 실습을 하냐면 원서에서는여이 유튜브 자막을 가지고 와요. 그래서 그 자막을 이제 번역하고 요약해 보는 실습으로 구성이 되어 있는데이 정도의 실습은 굳이요 인베드 체인을 사용하지 않더라도 실습이 가능하기 때문에 인베드 체인을 이제 복잡하게 이제 설정하는 것보다는 어 저희는 그냥 오픈소스 라이브러리들을 이제 사용을 해서 진행을 해 볼 예정입니다. 일단 이제 실습에 들어가기 전에 어 저희가 할 실습에 대해서 요약을 해보고 진행을 해 보도록 할 텐데요. 유튜브 영상 어 자막 추출 및 요약을 진행을 해 볼 예정이고요. 그래서 유튜브 영상의 자막을 API로 이제 추출을 해서 랭체인과 GPT 45니로 이제 요약하고 이제 다구어 번역하는 이제 전체 과정을 소개를 해 보도록 하겠습니다. 그래서이 내용은 NLP와 LM 실전 가이드 9장을 기반으로 이제 한국어 주요를 깔끔하게 이제 정리하는 이제 방법을 익혀보도록 할 예정이에요. 그래서 필요한 라이브러리 랭체인 그다음에 랭체인 오픈 AI 그다음에 유튜브 트랜스크립트 API를 설치를 할 거고이 유튜브 트랜스크립트 API 같은 경우에는 유튜브에서 공식적으로 이제 제공하고 있는 API가 아니라 그냥 오픈 소스로 개발자들이 만들어서 이제 어 공유하고 있는 어 API다라고 보시면은 됩니다. 그래서 이제 필요한 모듈 이제 임포트 할 때 이제 OS나 이제 텍스트 랩도 임포트를 할 텐데 뭐 긴 텍스트들에 대한 줄바금 처리를 할 때 텍스트 랩을 사용할 거예요. 그래서 다국어 번역을 했을 때 뭐 한국어, 뭐 러시아, 뭐 독일어 요런 것들 이제 텍스트 랩을 통해서 조금 보기 좋게 전 처리를 해 볼 예정이고요. 그다음에 유튜브 트랜스크립트 API를 통해서 유튜브 자막을 이제 추출을 해 볼 예정이고 어 랭체인으로 이제 프롬프트 템플릿이라든지 오픈 AI의 채팅 어 기반의 LLM을 이제 사용을 해 볼 예정입니다. 그래서 API 키도 마찬가지로 이제 저희는 콜랩을 통해서 이제 실습을 하기 때문에 그 콜랩 왼쪽에 열쇠 모양 클릭을 하시게 되면은 요런 식으로 오픈 AI API 키 등록하고 이제 사용하실 수가 있고요. 로컬에서 이제 사용하실 때는 어 이런 이제 환경 변수에 설정을 하고 사용을 하실 수도 있습니다. 그래서 유튜브 자막 최출 과정은 일단 영상 URL를 지정을 하고 유튜브 트랜스크립트 API를 통해서 가져오는데 일단요 아이디값 영상의 아이디값만 있으면은 어 유튜브 트랜스크립트 API를 통해서 스크립트 트랜스크립트 하게 되면은 영어 자막을 가져올 수가 있습니다. 그래서 자막 딕셔너리에서 텍스트 항목만 이제 추출을 해서 하나의 문자열로 합쳐서 어 실습을 진행을 해 볼 예정이에요. 그리고 이제 랭체인으로 요약하고 번역 설정을 해 보도록 할 텐데 GPT 45 미니는 어 굉장히 이제 가격도 저렴하고 성능도 그렇게 이제 떨어지진 않아서 GPT 45 미니를 이제 사용을 해 볼 예정이고요. 그다음에 이제 어 비용도 어 저렴하다 이렇게 이제 볼 수 있습니다. 그래서 이제 프롬프트 템플릿을 구성을 해서 뭐 전체 내용을 내문장 길이로 요약한다든지 아니면은 한국어 러시아 독일어로 번역을 해 본다든지 그다음에 언어간 이제 구분을 위해서 특수 문자를 지어 그 지정을 하고 이제 텍스트 랩으로 전 처리하는 어 그런 과정이 있고요. 그다음에 이제 템플릿 프롬프트 템플릿으로 입력 변수를 이제 설정해서 여기에다가 이제 자막을 넣어 준다든지 하는 내용으로 이제 구성이 되어 있습니다. 그다음에 이제 프롬프트 템플릿이 구성했다면 이제 체인을 구성을 해 주는데 어이 체인 구성할 때 이제 파이프 연산자로 이제 런너블 시퀀스 형태로 연결을 해서 사용을 할 거고요. 그다음에 이제 프롬프트에다가 이제 자막 텍스트 입력을 해 주고 그다음 이제 LM 호출해서 인보크 메 그 메서드를 통해서 LLM의 입력을 전달하고 결과를 받을 예정이에요. 그다음에 텍스트 랩으로 이제 가독성 좋게 어 전처리까지 이제 해 보는게 실습 내용입니다. 어, 그리고 이제 뭐 번역을 했다면 다음으로 이제 요약 테스크를 진행을 할 텐데 이제 간결한 한국어 요점을 이제 정리해 달라. 그래서 뭐 세 개에서 다섯 개 분리 어 형태로 머리끌로 이제 정리해 달라 요렇게 이제 어 요청을 할 예정입니다. 그래서 이제 글머리 기호로 시작하는 이제 한국어로 이제 작성을 해 달라라고 할 거예요. 그래서 이제 프롬프트 템플릿 구성하고 체인 구성하고 이전 결과 번역 결과를 새 체인에 전달을 해서 마지막에는 이제 한국어 주요 요점을 이제 표시하는 이제 요약을 해 보는 어 방법으로 이제 번역과 요약 테스크를 진행을 해 보도록 하겠습니다. 그럼 이제 코랩으로 넘어와서 어 직접 이제 실습 진행을 해 보도록 할 텐데요. 일단 PP 인스톨 해서 이제 앞에서 이제 소개했었던 것처럼 이제 랭체인 그다음에 랭체인에서 이제 오픈 AI API 이제 사용할 거기 때문에 랭체인 오픈 A AP AI 그다음에 어 랭체인 커뮤니티 유튜브 트랜스크립트 API 설치를 해 주도록 하고요. 그다음에 이제 OS 뭐 텍스트 랩 그다음에 유튜브 어 API 그다음에 랭체인에서는 이제 프롬프트 템플릿과 채 높은 오픈 AI 불러오도록 하고요. 그다음에 이제 왼쪽 열쇠 버튼 누르게 되면은 이제 미리 어 저장을 해 두었기 때문에 한 번만 입력을 해 두게 되면 내 계정에 저장이 되는 거기 때문에 어 별도로 따로 입력을 해 주시지 않아도 됩니다. 네. 만약에 내가 환경 변수 로컬에서 실습하고 있다 하시게 되면은 환경 변수에서 직접 불러오시거나 아니면 여기에다가 지정하고 사용을 해 주시는 방법도 있습니다. 그래서 이제 오픈 AI API 키 어가 만약에 이제 없다라고 하게 되면은이 코랩에서 오픈 AI API 키를 이제 불러오도록 어 했습니다. 그다음에 유튜브 비디오 URL를 통해서 URL을 지정을 해 주었고요. 그리고 유튜브 트랜스크립트 API를 통해서요 비디오 아이디에서요 언어 같은 경우에는이 유튜브 영상 같은 경우 이제 테드의 강연 영상이에요. 그래서요 테드 강연 영상에 대한 뒤에 있는요 아이디값만 요렇게 이제 가지고 온다. 그래서 영어로 되어 있기 때문에 어 이이라고 지정을 해 주었고 만약에 이제 한국어다라고 하게 되면은 이제 K5 요런 식으로 이제 지정을 해 주시면은 되겠죠. 그럼 이제 GPT 45니 어를 이제 사용을 해서 어 저희가 이제 다구어 번역을 이제 진행을 해 보도록 할 텐데 여기에 이제 서머리 프롬프트 템플릿에다가 이제 전체 내용을 검토하고 한국어 러시아 독일어로 이제 번역을 해 달라라고 프롬프트 템플릿을 작성을 했습니다. 그래서 여기에다가 어 그 문자열을 다른 문자열로 이제 구분을 해서 한국어 러시아 독일어를 구분을 하도록 했고요. 그래서 프롬프트 템플릿에다가 지금 위에 서머리 프롬프트 템플릿 써 놓은 내용 지정을 해 주고 그다음에 인풋 베리어블에다가 이제 컨텐츠 해서 이제 넣어 주도록 했어요. 그다음에이 서머리 그 프롬프트에서요 프롬프트와 llm 모델은 이제 오픈 AI의요 채 어 오픈 AI요 모델을 이제 지정을 해 주도록 했습니다. 그다음에 여기 이제 그 서머리 프롬프트의 포맷 해서 이제 컨텐츠에다가는 어 영어 텍스트를 이제 넣어 주도록 했어요.이 영어 텍스트는 어디에 있냐면 우리가이 유튜브에서 가져온 자막을 잉글시 텍스트라는 어 내용으로 이제 넣어 줬어요. 그래서 그 영어 텍스트 이제 확인을 해 보게 되면은 여기에서 어 요렇게 이제 테드의 어 영상에 대한 그 영어 어 자막을 가지고 왔고이 천자만 이제 일단 보여 주도록 했어요. 이제 너무 어 기니까. 그래서요 내용을 어 지금이 잉글리시 텍스트에다가 넣어 줄 예정입니다. 그래서 여기 컨텐츠라고 지정을 했는데요 인풋 베리어블 해서요 프롬프트 템플릿의요 컨텐츠가 여기에 이제 들어가게 된다라고 이제 보시면은 되고 그리고요 컨텐츠는요 서머리 프롬프트 템플릿의 이제 변수로 여기 컨텐츠로 이제 들어가게 됩니다. 그래서요 컨텐츠 어를 이제 그 영어 자막 텍스트를 넣어 주도록 하고요. 프롬프트 체인 구성해 준 거를 이제 서머리 체인이라는 변수에다가 넣어 주었는데요. 여기에서 인보크 해서 저 런너블 시퀀스로 어 되어 있는이 프롬프트와 모델을요 변수로 이제 넣어 주었습니다. 그다음에 여기에서 내문장 길이에 영어로 요약한 다음 한국어 러시아 독일어로 이제 번역해 달라 아라고 했죠. 그래서 요약하고 이제 번역을 이제 수행 어 한 결과를 이제 출력을 해 보고 여기에서 위에서 이제 구분자 요걸로 이제 넣어 달라라고 했으니까 이제 구분자로 어 번역과 이제 요약이 되는지 확인을 해 보도록 하겠습니다. 그럼 이렇게 번역 결과가 나왔는데요. 일단이 원문 나왔고요. 그다음에 요약하고 이제 번역해 달라라고 했는데 영어로 요약을 먼저 하고 그다음에 이제 번역을 하는데 한국어 러시아 독일어로 이제 번역을 해 달라고 했어요.이 한국어 위에는 요렇게 어 그 대시 어 문자를 넣어 주고 그다음에 여기에는 어 아스트리크 문자를 넣어 주고 그다음에는 요렇게 이제 문자로 이제 구분을 해서 한국어 러시아 독일어를 이제 구분을 했고 그다음에 요약 및 번역 결과 아까지 요렇게 이제 넣어 주었습니다. 그래서 이제 보기 좋게 이제 출력한 거는요 텍스트 랩을 통해서 어 보기 좋게 어 렇게 그 출력까지 이제 해 주도록 했는데 한국어로 이제 번역한 결과를 보게 되면은 이제 좋은 관계는 건강하고 행복한 삶에 필수적이며 그다음에 어 연구한 결과 어 사회적 연결이 중요하고 외로움이 건강과 행복에 부정적을 낀 영향을 미친다고 강 그 강조한다. 요런 이제 어 내용들이 이제 나와 있습니다. 그래서 각 언어별 요청한 언어별로 요약과 번역을 했고요. 그다음에 여기에서 글리로 작성해 달라라고 했어요. 그래서 각 요점은 글리 기호로 시작하는 한국어로만 이제 작성을 해 달라라고 했습니다. 그래서 이제 프롬프트 템플릿에다가요 키포인트 프롬프트 템플릿을 넣어 줬고 그 변수로는 오리지널 엔서라고 요렇게 어 변수를 이제 넣어 주도록 했어요. 이전 질문에 대한 답변을 넣어 주고 그걸 이제 글리 기호로 이제 만들어 주는데요. 여기에서도 이제 체인어요 프롬프트 템플릿과 LLM 모델 오픈 AI에 사용을 하고요. 그다음에이 인보크에다가이 위에서 구성한 이제 체인의 인보크에서 오리지널 엔서 이전에 이제 답변받은 어 내용을 이제 변수로 프롬프트 템플릿에다가 넣어 줄 수 있도록 설정을 해 주었습니다. 그럼 이제 한국어 요점을 글리 기호로 어 정리해 달라라고 했는데요. 어 좋은 관계는 건강하고 행복한 삶의 필수적이다. 그다음에 사회적 연결이 중요하고 외로움과 어 외로움은 건강과 행복에 부정적인 영향을 미친다. 그래서 관계의 질이 양보다 중요하면 만족스러운 관계가 나이 될수록 더 나은 결과를 가져온다. 그래서 관계를 유지하는데 시간과 에너지를 투자하는 것이 충만한 삶의 핵심이다라고 해서 어 테드 어 영상을 이렇게 번역하고 요약하는 테스크를 이제 진행을 해 봤다라고 보시면은 될 거 같아요. 그래서 이번 실습에서는 이제 유튜브 어 그에 트랜스크립트 API와 그다음에 랭체인을 사용을 해서 어 간단한 RH 실습을 해 봤다. 검색 증강 생성 실습을 해 봤다라고 보시면은 될 것 같습니다. 그래서 인베드 체인을 사용을 해도 되지만 여기에서는 이제 어 별도의 개별적인 라이브러리를 사용을 해서 R를 이제 구현을 하고 실습을 해 보았습니다. 감사합니다.')]},\n",
       " {'id': 'aDN8hm4pfPE',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLBkzzRK-6gLFE2KFpAQ6KmdBvKE3w',\n",
       "   'https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBLCzdjvCdb-JFdr8K1JAJtcH1Mfw'],\n",
       "  'title': \"아직도 '랭체인'을 모른다고 해서 5분 설명해드림\",\n",
       "  'long_desc': None,\n",
       "  'channel': '노마드 코더 Nomad Coders',\n",
       "  'duration': '6:01',\n",
       "  'views': '조회수 46,383회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=aDN8hm4pfPE&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'video_url': 'https://youtube.com/watch?v=aDN8hm4pfPE&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'content': [Document(metadata={'source': 'aDN8hm4pfPE'}, page_content=\"in this video I want to tell you about L chain and how it can make your life so much easier when building GPT powered apps L chain is a framework that has a ton of modules and pre-made components that make building language model powered apps incredibly easy and fast the developer speed with L chain is through the roof to build a GPT powered app is not enough to just use the open AI python package if you want to build anything remotely useful you will have to add memory to your chat boo you will need to format and validate you will need to parse outputs you will need to talk to Vector stores and more you could build all those on your own or you could use l chain L chain has all the things I mentioned already and much more from Models to prompts output parsers Vector stores embedding models agents toolkits monitoring debugging parallelization and more all for free and ready to use in JavaScript or python L chain also allows you to be model agnostic which means that if you use open eyes gpt3 and later want to change to Asher gpt3 or anthropics clot or to a model hosted in hogging phas or hosted in your machine if you use l chain that change will take you less than five lines of code without L chain you will have to rewrite your entire implementation to use a different API with L chain you change just one part of your app and the chat memory the vector stores the prompts and output parsers stay the same L chain is like a compatibility layer between all the components that an llm powered app needs after the chaos that happened in open AI now more than ever if you build llm powered apps you need to be able to easily switch between different providers without having to rewrite your entire code base this video is not sponsored by Lang chain it is sponsored by me more on that later so let me show you how Lang chain works by building a tiny translator bot it all starts with The Prompt here we are importing the chat prompt template class from lanching this class allows us to create a prompt that is made out of messages first we have a system message which sets defaults to the Ai and how it should behave we are telling the AI that it is a translator bot and that it translates sentences from one language to another as you can see we wrote Source language and target language that is because we want to make this prompt customizable by providing those variables later then we create a message sent by a human that says translate this followed by another variable that we are going to provide later here we are not worrying about the AI model we're going to use l chain will format this prompt into whatever shape the model needs later now we import the model and initialize it with a low temperature which as we know makes the responses less random and finally we create a chain which is a sequence of actions this might look weird to you at first but all you have to know is that the pipe operator is magical in Lang what it does is to chain each component to the next one and it will run them sequentially first it will format The Prompt and then it will give the prompt to the llm this syntax is called the Lin expression language or LC L and it is awesome because it allows you to construct really complex chains that all have multiple steps and it also allows you to chain change with other chains and run them in parallel is so cool for example if we also had an output parer our chain would look like this and L chain will first format The Prompt then give it to the chat model and then take the output of that and run it through the output parter LC is super powerful back to our code we are now going to run the Chain by using the invoke method if we do this we are going to have an error that is because L chain also validates our inputs if we go back and look at our prompt we can see that our prompt requires three variables Source language target language and sentence thankfully before we spend money calling the AI with an incomplete prompt L chain is validating that the template has all the inputs it needs to fix this all we have to do is provide the variables the template needs when we invoke the chain and we are done and if we print the response we will see the response from the llm formatted in a nice AI message class that we can later put put into our chatbot memory or save on a database if you want to change model and go from gpt3 to gp4 all you have to do is this or if tomorrow another fight breaks out at open Ai and everyone quits and the company implodes you can quickly get yourself an API key from anthropic to replace gpt3 for clock and as you can see just by changing two lines of code you moved from one model to another without touching anything else as of today Lin supports more than 76 llms and 25 chat models that you can swap with each other seamlessly the same goes for memory modules Vector stores text Splitters and more I hope that by now you can see how awesome L chain is which is why I am sponsoring this video I just finished recording a 15-hour l chain course called Full stack GPT we across 123 videos we will build seven GPT powered apps including a custom chat GPT plugin using lanching streamlit fast API GPT 4 whisper Mistral huging face and more we will build document GPT private GPT quiz GPT site GPT meeting GPT investor GPT and Chef GPT we will build a custom GPT that users will be able to install from the GPT store and I also added two bonus sections one that uses the newly released assistance API from open aai that allows us to build autonomous agents with function calling memory and document retrieval and after what happened at openai I made another section on how to migrate from openai to ashure openai or AWS Bedrock if you are interested and I hope are please click the link below to get your hands on full stack GPT more than 15 hours and 123 videos building GPT powered app is so much fun I really hope you can join click the link below and I will see you there on Kam see you on the next one byebye m\")]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 개 유튜브 영상 자막 가져오기\n",
    "for v in videos:\n",
    "    # 여기는 \n",
    "    v['video_url'] = 'https://youtube.com' + v['url_suffix']\n",
    "\n",
    "    # YoutubeLoader를 이용하여 비디오 로드\n",
    "    loader = YoutubeLoader.from_youtube_url(\n",
    "        v['video_url'],\n",
    "        language=['ko', 'en'],\n",
    "    )\n",
    "\n",
    "    v['content'] = loader.load()\n",
    "\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 영상 수: 5\n",
      "60분 이하 영상 수: 5\n"
     ]
    }
   ],
   "source": [
    "# 길이가 1시간 이하인 영상 고르기\n",
    "print('총 영상 수:', len(videos))\n",
    "# 영상 길이가 60분 이하인 영상만 남기기\n",
    "videos = [v for v in videos if len(v['duration'].split(':')) < 3] # 리스트 컴프리헨션 문법\n",
    "print('60분 이하 영상 수:', len(videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a6321",
   "metadata": {},
   "source": [
    "### 자막 내용 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0810c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BqXGdWOpAldHRIFsZHmHd49HZKRcu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7d597abe-40ac-42d7-9aca-a137251d8477-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model.invoke('안녕?') # 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950c3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"이 영상은 챗 GPT와 최신 정보 반영 기술인 RAG(검색 증강 생성)에 관한 내용을 다룹니다. 챗 GPT는 흥미로운 이미지 생성 외에도 업무에 활용될 수 있지만, 비공식적인 정보나 최신 데이터에 대한 답변은 제한적입니다. 이런 문제를 해결하기 위해 RAG기술이 필요합니다. \\n\\nRAG는 질문에 대해 관련 정보를 외부 데이터베이스에서 검색한 후, 이를 바탕으로 AI가 보다 정확한 답변을 제공하도록 돕는 기술입니다. 이때, '랭체인'이라는 도구가 사용되어 RAG 시스템을 쉽게 구축할 수 있게 해줍니다. 다양한 분야에서 사용 가능하며, 행사 정보나 고객 서비스, 전자 제품 관련 질문에 대한 자동 응답 서비스 생성 등에도 활용될 수 있습니다. \\n\\n영상은 RAG와 랭체인을 통해 일반 사용자도 똑똑한 챗봇 서비스를 쉽게 만들 수 있다는 점을 강조하며, 더 자세한 학습을 원하면 추가 자료를 참고하라고 안내합니다.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영상 하나만 요약하기 \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 동영상 요약 프롬프트 작성\n",
    "prompt = ChatPromptTemplate(\n",
    "    [(\"system\", \"다음 영상에 대한 요약을 한국어로 만들어줘:\\\\n\\\\n{context}\")]\n",
    ")\n",
    "\n",
    "chain = create_stuff_documents_chain(model, prompt)\n",
    "\n",
    "result = chain.invoke({\"context\": videos[0]['content']})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60410898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'PzeQ-H9q3Y8',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAS3g7BBhHj50lH81nWFkPFL5dCFA',\n",
       "   'https://i.ytimg.com/vi/PzeQ-H9q3Y8/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLDGG2TJ0b_qeStZ6URpvlbqXe6TlQ'],\n",
       "  'title': '랭체인 + RAG 5분만에 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '나도코딩',\n",
       "  'duration': '5:34',\n",
       "  'views': '조회수 7,929회',\n",
       "  'publish_time': '2개월 전',\n",
       "  'url_suffix': '/watch?v=PzeQ-H9q3Y8&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'video_url': 'https://youtube.com/watch?v=PzeQ-H9q3Y8&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'content': [Document(metadata={'source': 'PzeQ-H9q3Y8'}, page_content='여러분 채 GPT 많이 사용하시죠? 네. 최근에는 가족 사진을 다양한 스타일의 이미지로 만들어 보는 재미 덕분에 이용자가 폭주하면서 샘 얼트먼이 이미지 생성을 자세해 달라는 글도 올렸었는데요. 어 G지PT는 재미있는 이미지 생성에도 많이 사용되지만 실제로 여러분들이 사용할 또는 업무에 필요한 용도로도 많이 활용을 하실 것 같습니다. 네. 이렇게 많은 분야에서 사용되는 챗 GPT. 그런데 사실 채 GPT라고 해서 모든 것을 알고 있는 건 아니에요. GPT는 특정 시점까지 데이터를 학습하고이 내용을 바탕으로 답변을 하기 때문에 최신 데이터에 대해서는 답변을 올바로 하지 못하는 문제가 있는데요. 네. 이런 부분을 보완하고자 최신 정보를 즉각적으로 반영할 수 있는 실시간 웹 기능을 제공하고 있지요. 그런데 이것 말고도 여전히 채지가 답변을 올바로 하지 못하는 부분이 있습니다. 바로 비공개 데이터인데요. 예를 들어서 우리 가족이 이렇게 있을 때 우리 집에서 가장 키가 큰 사람은 누구야라고 물어본다면 대체 GPT는 아마도 올바른 답을 하지 못할 겁니다. 또는 가족 여행으로 제주도를 간다고 했을 때 우리 가족 제주도 여행 출발 항공편은이라고 물어봐도네 역시 잘 모른다고 답을 하고 있지요. 우리 가족의 키 또는 우리 가족의 여행 정보는 우리 식구들 또는 매우 가까운 사람들만 알고 있는 정보이지 채 GPT는 당연히 알 수가 없을 겁니다. 그런데 제가 질문을 조금 다르게 해 볼게요. 이번에는 우리 가족의 키 정보를 주면서 물어보는 거예요. 네. 이렇게 키 정보를 주면서 우리 집에서 키가 가장 큰 사람은이라고 했더니 네. 이번에는 아빠가 가장 크다고 답변을 잘 해 줍니다. 다음 질문도 바꿔 볼까요? 자, 지금 보고 계신 네, 우리 가족 여행 계획서 중에서 항공편 정보와 관련된 부분만 채치T에게 전달하면서 다시 한번 물어보도록 할게요. 우리 가족 제주도 여행 출발 항공편은 이렇게 물었더니 네, 역시 정확하게 네, n254라고 답변을 잘하지요. 자, 이렇게 질문과 관련된 참고 자료를 함께 주면 채 G지pt도 제대로 답변을 할 수 있게 됩니다. 그런데 문제가 있어요. 자주 키 정보나 항공편 정도야 간단하지만 만약 책 한 권 전체 내용이라든지 수백 페이지에 달하는 회사 내부 매뉴얼 전체 등네 방대한 정보에 대해서 질문을 하고 싶다고 하면 어떻게 할까요? 어, 질문을 할 때마다 모든 내용을 대화창에 복사 붙여 넣게 하기에는 아마도 쉽지가 않을 것 같습니다. 데이터 양도 너무 많고 그에 따라 비용도 발생할 거고요. 또 참고 자료가 너무 많으면 오히려 책 GPT가 필요한 정보를 찾는데 혼란을 줄 가능성이 큽니다. 결국 올바른 답변을 얻지 못할 수도 있는 거예요. 바로이 문제를 해결하는 기술이 RH입니다. 네. 우리말로는 검색 증강 생성이라고 하는데 어렵게 들리지만 원리는 앞에서 본 것과 같습니다. 채치T에게 정보를 제공하고 그 정보 내에서 답변을 해 달라고 하는 거예요. 앞에서 보셨던 것처럼 우리 가족 여행 계획 데이터가 있으면이 전체 내용 중에서 우리가 궁금한 항공 일정과 관련된 부분만 뽑아서 질문제에 넣은 것. 이게 바로 Rage이 핵심입니다. Rag의 구조는 간략히 설명드리면 이렇습니다. 우리가 질문을 하면 RA 시스템은 먼저 우리가 미리 준비해 둔 외부 문서나 데이터베이스에서 질문과 가장 관련 높은 정보를 검색합니다. 네. 마치 오픈북 시험 볼 때 책에서 관련된 내용을 찾는 것과 같아요. 자, 그리고 이렇게 찾은 핵심 정보와 원래 질문을 함께 AI에게 전달하면서 자, 여기 참고 자료 있으니까 이거를 보고 답을 해 줘 하고 시키는 거죠. 그러면 채pt는이 참고 자료를 바탕으로 훨씬 정확하고 구체적인 답변을 생성합니다. 생각보다 간단해 보이기도 하죠. 그런데이 R 시스템을 직접 만들려면 데이터를 불러오고 검색하기 좋게 나누고 검색도 하고 또 AI 모델하고 연결하고 등등 복잡한 작업들이 필요합니다. 이때 랭체인이라고 하는게 빛을 바라는데요. 어 랭체인은 마치 AI 프로그램 개발을 위한 레고 블록세트와 같습니다. Rag를 만드는데 필요한 여러 기능들 가령 데이터를 불러오거나 나누거나 검색하거나 AI를 연동하는 작업들을 미리 만들어진 형태로 제공합니다. 그래서이 랭체인 블록들을 가져다 쉽고 빠르게 조립해서 R이 기반의네 똑똑한 채복 같은 서비스를 뚝딱 만들 수 있는 거예요. 네.이 이 화면은 랭체인과 레그 기술을 사용해서 만들어 본 PDF 문서 기반 인공지능 Q&A 채포인데요. 이렇게 어떤 내용이 담긴 PDF 파일을 업로드하고 나서 질문을 해 보면 PDF 파일에서 관련 있는 부분을 찾아서 올바로 답변을 해 주는 모습을 보실 수 있습니다. 아주 다양한 환경에서 사용될 수 있는데요. 누군가 어떤 큰 행사를 준비하는데 행사 기간 및 장소는 어떻게 되는지, 입장 비용은 어떻게 되는지 음식물 반입은 가능한지 주차 지원은 되는지 등 행사 관련하여 다양한 질문을 채포을 통해서 해 줄 수도 있고요. 여러분이 사용하고 계신 전자 제품의 어떤 고장이 났을 때 AS를 받기 전에 가정에서 자가 소리를 하기 위한 방법이 어떻게 되는지 물어볼 수도 있겠죠.데 네. 고객센터 입장에서는 어 제품 매뉴얼이나 자주 묻는 질문 등에 대한 데이터가 있다면이 내용을 바탕으로네 채봇을 통해서 빠르고 정확하게 답변이 가능할 겁니다. 네. 자, 온라인에서 어떤 물건을 구매할 때도 Q&A 게시판에 보면 질문이 굉장히 많은데요. 이런 내용들을 어딘가 잘 정리해 두면 지금까지 답변한 내용을 바탕으로 새로운 질문이 왔을 때 자동으로 응답하는 것도 생각해 볼 수 있을 것 같습니다. AI가 단순히 알고 있는 것을 넘어서 여러분이 가진 정보를 활용해서 여러분만의 똑똑한 체포 서비스를 개발할 수 있다는게 네, 흥미롭지 않나요? 자, 이렇게 해서 아주 빠르게 내 한 개를 넘는 R과이를 쉽게 구현하도록 돕는 레인체인에 대해서 알아봤습니다. 네. 혹시라도 보다 더 자세히 공부하고 싶으신 분들이 계시다면 영상 본문 또는 고정 댓글을 참고해 주시면 좋겠습니다. 네, 그러면 이번 영상은 여기에서 마치도록 하겠습니다. 감사합니다.')],\n",
       "  'summary': \"이 영상에서는 챗GPT를 활용한 이미지 생성과 정보 제공의 한계를 설명하고 있습니다. 챗GPT는 특정 시점까지 학습한 데이터를 바탕으로 답변을 하지만, 가족이나 개인적 정보를 알지 못하기 때문에 질문에 대한 정확한 답변을 할 수 없는 경우가 많습니다. 예를 들어, 가족의 키나 여행 항공편 정보처럼 비공식적인 데이터에 대해서는 올바른 답변을 하지 못합니다. 하지만 관련 정보를 제공하면 원하는 답변을 받을 수 있습니다.\\n\\n이러한 문제를 해결하기 위해 'RAG'(검색 증강 생성)이라는 기술이 소개됩니다. RAG는 질문에 대한 답변을 제공하기 위해 관련 문서나 데이터베이스에서 정보를 검색하여 AI에 전달하는 방식을 사용합니다. 이를 통해 더 정확하고 구체적인 답변을 생성할 수 있습니다.\\n\\n또한, '랭체인'이라는 도구를 사용하면 RAG 시스템을 쉽게 구축할 수 있습니다. 랭체인은 AI 프로그램 개발에 필요한 다양한 기능을 제공하여 개발자들이 신속하게 원하는 서비스를 만들 수 있도록 돕습니다.\\n\\n영상에서는 PDF 문서 기반 AI Q&A 예시를 통해 다양한 분야에서 랭체인과 RAG 기술이 어떻게 활용될 수 있는지에 대해 설명합니다. 이를 통해 고객센터, 대행사, 전자제품 AS 등 다양한 환경에서 AI가 정보를 활용하여 서비스할 수 있음을 강조합니다. 마지막으로, 더 자세한 정보는 영상 본문이나 댓글을 통해 확인할 수 있다고 안내하고 있습니다.\"},\n",
       " {'id': 'm8tIOcMcwno',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLD6ACjB-c0R9H3HEfaeu323mLS9MQ',\n",
       "   'https://i.ytimg.com/vi/m8tIOcMcwno/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCHenGlwslkGWHJ48R06LOGC-wZgQ'],\n",
       "  'title': '랭체인 이해하기',\n",
       "  'long_desc': None,\n",
       "  'channel': '다비드스튜디오 dabidstudio ',\n",
       "  'duration': '9:16',\n",
       "  'views': '조회수 14,231회',\n",
       "  'publish_time': '8개월 전',\n",
       "  'url_suffix': '/watch?v=m8tIOcMcwno&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=m8tIOcMcwno&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': 'm8tIOcMcwno'}, page_content=\"l&m 서비스 개발에 관심이 많으신 분들은 자주 접하셨을 단어가 있습니다 바로이 랭 체인이라고 하는 것인데요 랭 체인은 l&m 서비스 개발을 굉장히 편리하게 해 주는 툴입니다 그런데 랭 체인을 처음 공부할 때 어려운 부분들이 좀 있습니다 일단 너무 복잡하고 종류가 많습니다 벡터 스토어 리트리버 체인 등등등 다양한 컴포넌트들이 있고 뭐가 뭔지 잘 모르겠습니다이 랭 체인이 어떻게 작동을 하는지 잘 이해가 안 갑니다 그래서 예제 코드를 보거나 코드를 다운받아도 내가 원하는 방식으로 바꾸는 것이 굉장히 어렵습니다 그래서 이번 영상에서는 링 체인의 특징 세 가지를 중심으로 l&m 서비스 개발 관점에서 어떤 문제를 해결해 주는지를 다뤄보려고 합니다 추상화 표준화 그리고 체이닝 이렇게 세 가지입니다 그래서 이런 특징들을 기반으로 우리가 랭 체인을 효과적으로 활용하기 위해서는 어떻게 접근을 하면 될지에 대해서 저희 생각을 공유해드리고자 합니다 랭 체인의 첫 번째 특징은 추상화입니다 랭 체인은 l&m 서비스를 만들 때 필요한 각종 복잡한 작업들을 굉장히 간결하게 표현을 해 주고 간소화해 줍니다 예를 들어 대표적인 l&m 서비스라고 할 수 있는 레그 체포 또는 문서 q&a 체포를 만들려고 할 때 꼭 필요한 작업들이 있습니다 PDF Pro 되어 있는 문서에서 텍스트를 불러와 주고 그 텍스트를 쪼개고 임베딩을 하고 벡터 DB 저장을 해 주는 과정을 거칩니다 그런데이 과정은 랭킹이 있으면 단 세 줄로 간결하게 표현을 하고 구현을 할 수가 있습니다 만약에 랭 체인이 없다고 하면은 우리가 PDF 불러오고 임베딩 모델을 정의하고 사용을 하고 벡터 디비를 활용하는 부분까지 다 직접 코드를 작성을 하고 구현을 해야 됩니다 그런 번 그름을 랭 치는 해소를 해 줍니다 링 체인의 두 번째 특징은 표준화합니다 링 체인은 비슷한 기능들을 가지고 있는 여러 요소들을 똑같은 형식을 갖춘 컴포넌트로 표준화해 줍니다 l&m 서비스를 만들 때 우리가 용을 할 수 있는 AI 모델은 이제는 정말로 종류가 다양합니다 채즈 피티도 있고 제미 아도 있고 정말 다양한데 이런 다양한 AI 모델을 우리는 랭지 인을 이용하면 챗 모델이라고 하는 하나의 표준화된 형식으로 통일을 해 줍니다 챗 모델이라고 하는 표준화된 컴퍼넌트가 없었으면 각 AI 모델마다 갖고 있는 엔드 포인트라는 API든지 활용하는 형태가 다 다르기 때문에 이걸 제대로 구현화 해 주기 위해서는 굉장히 번거로운 과정들이 있을 건데 그런 부분들이 체인이 알아서 간소화해 줘서이 챗 모델이라고 하는 표준화된 형식으로 통일을 해 줍니다 그래서 각각의 AI 모델들은 챗 엔트로픽 챗 오픈 AI 등등의 이름을 가진 클래스로 선언 할 수 있는데이는 모두이 챗 모델이라고 하는 컴퍼넌트의 종류이기 때문에 똑같은 성질을 가지고 있습니다 마찬가지로 정말로 다양한 원본 데이터를 활용해서 l&m 서비스를 만들 수 있습니다 우리가이 서비스에 맥락을 주입하고 데이터를 를 주입할 때 그 데이터는 pdf's 올 수도 있고 워드 문서에서 올 수도 있고 다양한 출처에서 올 수 있습니다 이렇게 다양한 소스에서 오는 데이터를 체인은 도큐먼트 아고 하는 표준화된 컨테이너를 이용해서 관리합니다 어떤 소스는 체인의 컴포넌트를 통해서 다양한 소스의 데이터들은 그 데이터 안에 있는 텍스트를 표현해 주는 페이지 콘텐트 그리고 데이터의 부가 정보를 담고 있는 메타데이터이 두 개로 이루어진 도큐먼트 아고 하는 형태로 표준화를 해서 우리는 도큐먼트를 다루고 도큐먼트를 가공하고 도큐먼트를 쪼개고 등의 작업들을 하게 됩니다 지금 가져온 코드는 링 틴으로 작성된 레그 코드인데요 여기서도 지금 AI 모델 부분은이 한 줄입니다 지금은 채 GPT GPT 4o 미니 모델을 쓰고 있는 컴퍼넌트를 활용하는데 만약에 우리가이 코드에서 AI 모델을 클로드로랭 1을 활용하면 재활용 가능한 코드를 작성할 수 있습니다 자주 쓰이는 주요 컴포넌트는 다음과 같은데 그래서이 주요 컴포넌트들의 성격만 잘 알고 있으면 어차피 표준화된 형태로 관리가 되기 때문에 다른 세부적인 클래스들은 쉽게 습득할 수가 있습니다 랭의 세 번째 특징은 체이닝 있니다 우리가 자주 활용하는 주요 컴포넌트를 쉽게 연결을 해서 우리 l&m 서비스가 어떤 로직으로 데이터를 주고받고 전달을 하는지 선명하게 보여줄 수 있습니다 제가 앞서 말씀 말씀드린 주요 컴포넌트들의 공통점들이 있습니다 100% 아니지만 대부분의 컴포넌트는 인풋이 있으면은 그 인풋에 대해서 아웃풋을 주는 형태로 구성되어 있습니다 예를 들어서 프롬트 템플릿이고 하는 컴포넌트는 이런 딕셔너리 형태의 데이터를 받으면은이를 기반으로 완전한 형태의 메시지 프롬프트를 만들어 줍니다 챗 모델이라고 하는 컴퍼넌트는 프롬트 또는 질문 또는 메시지라고 하는 인풋을 받으면 그 메시지에 대한 응답 결과 그리고 관련 부가 정보를 담고 있는 결과값을 아웃풋으로 줍니다 PDF 주로 다루는 PDF 로더는 컴퍼넌트는 우리가 인풋으로 PDF 파일을 주면은 도큐먼트의 리스트 형태로 아웃풋을 반환을 해 줍니다 텍스트 스플리터고 하는 컴포넌트도 인풋으로이 다큐먼트 리스트를 주면이를 다시 재조합하고 더 잘게 쪼개거나 등의 방식으로 또 도큐먼트 리스트를 반환을 해 줍니다 이렇게 컴포넌트들이 인풋과 아웃풋 형태로 이어져 있기 때문에 여러 개의 컴포넌트를 연쇄적으로 연달아서 연결을 해서 첫 번째 컴포넌트의 아웃풋이 그다음 컴포넌트의 인풋으로 그대로 보내질 수 있도록 할 수 있습니다 예를 들어서 이런 딕셔너리가 있으면이를 우리는 프롬트 템플의 인풋으로 넣어 주면이 프롬트 템플릿은 완성된 프롬프트를 아웃풋으로 줍니다 그 아웃풋은 챗 모델이라고 하는 컴포넌트의 인풋으로 들어가서 응답 결과가 포함된 아웃풋이 나옵니다 그리고 마지막으로이 챗 모델의 아웃풋 중에서 실제로이 챗 모델이 응답한 텍스트 결과만 뽑아내는 내용이 최종 출력 결과로 나오도록 하나의 체인을 구성을 할 수가 있습니다 이런 체인은 실제로 코드상에서 구현을 할 때도이 파이프라고 하는 특수 기호로 쉽게 연결을 할 수 있습니다 그래서 지금 이렇게 시각화에서 보여준 체인도 실제로 코드에서도 프롬트 템플릿이 파이프 챗 오픈 AI 파이프 스트링 아프 파서 형태로 표현할 수가 있습니다 그리고 이런 체인에서 크라는 메소드를 이용하면 실제로이 체인에 들어갈 인풋을 넣어주고 그 체인의 최종 결과 값을 받아볼 수가 있습니다 그래서 우리가 레 체인을 접할 때는 제일 중요한게 인풋과 아웃풋이 있는 주요 컴포넌트들을 완벽하게 이해를 해 주는 것입니다 랭지 홈페이지에서도 이런 주요 컴포넌트를 빌딩 블록이라고 표현을 하고이 주요 컴포넌트는 이렇게 여덟 개 정도로 정리가 되어 있습니다이 컴포넌트들이 구체적으로 어떤 인풋을 받고 어떤 아웃풋을 주는지 이것만 집중적으로 봐도 아 랭 체이 이렇게 인풋과 아웃풋으로 이루어진 컴포넌트들을 조합해서 만드는구나 를 정확히 파악할 수가 있습니다 그 주요 컴포넌트에 대해서 정말로 잘 소개가 된 문서가이 랭 체인 공식 홈페이지에 있는 컨셉츄얼 가이드라고 하는 문서인데 제가 이거 영상 하단에 링크를 첨부해 두겠습니다 여기 컴포넌트를 눌러 보면은이 조요 컴포넌트들이 어떤 인풋과 어떤 아웃풋으로 이루어져 있고 어떤 기능을 하는지 굉장히 자세하게 설명이 되어 있기 때문에 여러 번 읽어 보시는 것을 추천드립니다 두 번째로 말씀드리고 싶은 건 랭 체인에서 분명히 복잡하고 잘 이해가 안 되는 체인들도 많은데 그런 체인들은 일단 넘어가거나 아니면은 내가 이해 가능한 주요 컴포넌트들의 조합으로 이루어져 있는 형태로 풀어서 활용을 하는 것입니다 예를 들어서 레그를 표현하는 예제 코드 중에서도 아이 랭 체인에서 자체적으로 제공하는 크레이트 리트리버 체인이나 크이 st 도큐먼트 체인 같은 체인들이 있는데 사실 이렇게만 보면은 체인이 지금 어떤 주요 컴포넌트들을 가지고 있고 어떻게 인풋과 아웃풋으로 구성이 되어 있는지 잘 이해가 가지 않고 내가 제대로 활용하기가 까다로운 부분 들이 많습니다 그런데 이런 체인들도 실제로는 이렇게 주요 컴포넌트들을 파이프로 연결한 형태로도 똑같이 표현을 할 수가 있습니다 지금 앞에 나와 있는이 레그 체인이 코드는 지금 뒤에 있는이 레그 체인고 완전히 동일한 기능을 가지고 있습니다 그래서 우리는 최대한 주요 컴퍼넌트 둘로 이루어진 형태로 체인 대를 풀어서 쓰거나 너무 추상화가 돼서 너무 구체적인 내용이 안 보여지는 체인들은 가급적이면 지향을 하는 것이 좋은 거 같습니다 마지막으로는 그래서이 랭 체인을 다루 에는 필요한 로직을 위주로 부분적으로 내 서비스나 내 프로그램에 활용하는 것이 제일 좋은 거 같습니다 링치 인은 표준나사 아이 특징 때문에 LM 서비스를 처음 개발하려고 하는 분들이 쉽고 빠르게 MVP 만들고 이미 주어져 있는 예제 코드를 활용해서 빠르게 뭔가를 구현하기에는 굉장히 좋은 툴입니다 그런데 조금만 더 내가 구현을 하고자 하는 대상이 구체적이고 또 내가 데이터 수집부터 프런트까지 단계별로 커스트마이징을 하거나 수정을 하거나 튜닝을 할 부분들이 많아질수록 랭 체인만으로 100% 되는 부분들은 안정적입니다 그래서 코드 전체를 랭 체인으로 무조건 해야 되겠다라는 생각보다는 빨리빨리 구현하고 내가 100% 이해할 수 있는 부분만 부분적으로 랭 체인의 주요 컴포넌트를 활용하면 좋을 것 같습니다\")],\n",
       "  'summary': '이 영상에서는 L&M 서비스 개발에 필요한 \"랭 체인\"에 대해 설명하고 있습니다. 랭 체인은 L&M 서비스를 더욱 간편하게 개발할 수 있도록 도와주는 도구로, 처음 접근할 때는 복잡한 컴포넌트들 덕분에 어려움을 느낄 수 있습니다. 영상에서는 랭 체인의 세 가지 주요 특징인 \"추상화\", \"표준화\", 그리고 \"체이닝\"을 소개하며, 이러한 특징들이 L&M 서비스 개발 시 어떤 문제를 해결하는지를 다룹니다.\\n\\n1. **추상화**: 랭 체인은 복잡한 작업을 간결하게 표현합니다. 예를 들어, PDF 문서에서 텍스트를 불러오고, 임베딩 모델을 적용하는 과정이 랭 체인을 사용하면 단 세 줄의 코드로 해결할 수 있습니다.\\n\\n2. **표준화**: 다양한 AI 모델을 챗 모델이라는 표준화된 형식으로 통일합니다. 이렇게 하면 여러 AI 모델을 일관된 방식으로 사용할 수 있어 구현이 훨씬 쉬워집니다. 데이터 소스도 표준화된 \\'도큐먼트\\' 구조로 관리되어, 다양한 형태의 데이터를 통합적으로 처리할 수 있게 됩니다.\\n\\n3. **체이닝**: 컴포넌트들이 인풋과 아웃풋 형태로 연결되어 데이터 흐름을 명확하게 표현합니다. 이를 통해 여러 컴포넌트를 연계하여 원하는 로직을 구성할 수 있습니다.\\n\\n영상은 랭 체인의 이러한 특징들을 활용하여 L&M 서비스를 효과적으로 개발하는 방법에 대한 인사이트를 제공하며, 코드의 예시와 함께 각 주요 컴포넌트의 사용법도 설명하였습니다. 랭 체인을 처음 사용하는 개발자들에게 유용한 가이드를 제공합니다.'},\n",
       " {'id': '1scMJH93v0M',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLC8Bbvnyigui44yjlyGJQCfFV7MqA',\n",
       "   'https://i.ytimg.com/vi/1scMJH93v0M/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBIUwbKKCmlPJKcw2nTifu92hXaZg'],\n",
       "  'title': '#langchain 의 #RAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작',\n",
       "  'long_desc': None,\n",
       "  'channel': '테디노트 TeddyNote',\n",
       "  'duration': '21:47',\n",
       "  'views': '조회수 41,428회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=1scMJH93v0M&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=1scMJH93v0M&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': '1scMJH93v0M'}, page_content='안녕하세요 오늘은 레그에 대해서 알아보겠습니다 레그에 대해서 잘 아시는 분도 계시고 처음 들어보시는 분도 계실 것 같아요 요즘에이 레그라 주제가 굉장히 핫한데라는 것은 뭐의 약자면 retrial augmented generation 요렇게 해가지고라고 부르는데 rri 하면은 추출의 의미를 가지고 있고요 어그멘티드 하면은 뭐 데이터 증가 그다음에 제네레이션 어떤 데이터로부터 우리가 원하는 내용을 추출해서 우리가 원하는 답변으로 lml 활용해서 만들어내는 거 요거에 전반적인 프로세스를 우리가 레그라 부릅니다 자이 레그가 요즘에 굉장히 핫한 이유가 lml 활용할 때 이런 경험이 있으실 거예요 만약에 채치 PT 테 우리가 다양한 질문을 던질 수가 있죠 그러면 채치 ptga 정말 똑똑하니까 잘 답변을 해 줘요 그런데 채지 피티가 이런 걸 할 수 있을까요 우리 회사의 내규 중에서 뭐뭐를 알려 줘 이런 거 모르죠 왜냐면 얘는 우리 회사의 내규 정보를 모르고 있기 때문이에요 그러면 우리가 원하는 건 뭐냐면 채체 피티한달 정보를 먼저 던져 줍니다 근데이 정보가 압축적이다 참 좋을 텐데 어 우리 회사 내규의 정보가 200페이지에 그러면이 중에서 우리가 원하는 내규 정보 정보를 찾으려면 시간이 굉장히 오래 걸리죠 이런 것들을 우리가 레그라는 걸 통해서 서비스로 만들 수가 있는 거죠 200페이지 짜리를 쥐어주고 그다음에 우리가 어떤 질문을 던지면이 200페이지 중에서 우리 질문에 답변할 수 있는 데이터들을 먼저 추출을 하는 거 rri 하는 거죠 그다음에이 추출된 거를 그대로 우리한테 토해내는게 아니죠 그냥 추출된 걸 주면은 그거는 그냥 DB 검색이 DB 검색 DB 검색입니다 근데 그냥 DB 검색이 아니라이 추출된 내용을 우리 질문에 맞게 이러이러 합니다라고 친절하게 답변을 만들어서 는 거죠 그래서이 리그라는 기술이 많이 주목받고 핫해진 이유 자체가 더 이상 채치 PT 일반화해서 학습한 정보를 답변하는 걸 원하는게 아니라 우리 회사 정보 우리가 가지고 있는 정보 우리만의 어떤 법률 정보 우리만의 어떤 마케팅 정보 기반으로 답변해 줘 뭐뭐를 기반으로 답변해죠 요렇게 하려면 레그 기술을 잘 활용해서 어 qa 시스템을 만들어야지 된다라는 거죠 사실이 레그에 대해서 깊게 다뤄 보려면 정말 영상의 길이가 길어질 수밖에 없습니다 그렇지만 여러분들이 찍먹 수 있을 정도 수준의 튜토리얼을 가지고 와 봤고요이 찍먹 mas 알려 드리면 좀 재미가 없어요 왜냐면은 다른 데서도 많이 하는게이 레그의 찍먹 수준이거든요 근데 여기서 더 나아가서 우리가 어떤 점들을 개선할 수 있는지를 같이 한번 보실게요 자 먼저 레그 개발을 위해서는이 전반적인 흐름에 대해서 알고 계셔야 됩니다이 레그 프로세스는 데이터로드 데이터를 불러오는 거 그다음에 불러왔으면 분할하는 거 임베딩 하는 거 벡터 디비에 저장하는 거 그다음에 저장을 했으면 이제 사용자가 질문을 하겠죠 질문을 하면은이 질문을 기반으로 데이터에서 검색해서 원하는 내용을 발제를 하고 발췌된 내용과 프롬프트를 더해 가지고 l&m 넣어서 우리가 원하는 답변으로 이끌어내는 이런 큰 흐름을 머릿속에 가지고 계시는게 좋아요 근데 우리가이 랭 체인을 쓰면은라는 걸 개발할 때 굉장히 편리하죠 왜냐면 지금 여기에 제가 단계를 나눠 놨는데이 나뉘어진 단계 안에서도 세부 태스크들을 굉장히 많아요 예를 들면 데이터로드 할 때 우리가 PDF로드 할 건지 워드 문서를 로드할 건지 아니면 웹페이지를 로드할 건지 이미지를 로드할 건지 그밖에 엄청나게 많은 데이터를로드 할 수가 있어요 근데 우리가 만약에 에 PDF로드 할 거야 워드로드 할 거야 이거를 다 파이썬 코딩으로 구현하려 그러면 머리 빠지죠 그런데이 랭 아인에서 통합된 인터페이스라는 표현을 써요 네가 알고 있어야 되는 거는 한 개에 통합된 함수 하나만 알면 돼 뭐 예를 들면은 로드라는 함수만 알면 돼 그리고 앞단에서 내가 여기다가 워드 문서를 넣으면은 워로드 뭐 웹페이지 넣으면 웹페이지로드 뭐 요런 식으로 해 줄게 네가 앞에 것만 바꿔 주면 돼 뭐 이런 식으로 통합된 페이스로 개발을 해 놨기 때문에 우리는 랭 체인을 사용하면은 굉장히 여러 종류의 문서를 손쉽게 로드할 수 있는 거 그런 것들이 있고요 그래서이 랭 체인을 써서 레그를 사용하면은 개발이 굉장히 쉬워진다고 보시면 돼요 랭 체인을 쓰면은 어떤 레그의 품질이 좋아진다 이런 측면이 아니에요 이런 측면이 아니라 개발이 굉장히 속도가 붙고 그다음에 편리하다 그렇기 때문에 생산성이 좋다 이렇게 설명드릴 수 있습니다 자 그래서 여기 보시면 이제 로더 터 차례대로 저희가 나가 볼 건데요이 프로세스는이 프로세스는 거의 변하지 않습니다 변하지 않기 때문에 여러분들이 이번 영상에서는 어떤 큰 그림을 한 번씩 체험해 보시는 거고요 어 나는 이번 튜토리얼에서는 저희가 웹페이지를 볼 건데 웹페이지가 아니라 다른 걸 로드하고 싶은데 예를 들어서 PDF 로드하고 싶은데 이러면은 다른 모듈을 로드하는 거 그거 응용하시면 거죠 그니까 큰 틀만 잡고 있으면요 사이에서 바꾸는 거는 충분히 쉽다 이렇게 말씀드릴 수 있을 것 같아요 바로 한번 가보시죠 자 먼저 환경 설정하고 자이 환경 안에서는 제가 랭 스미스 API 써 가지고 저희가 실행하는 모든 것들을 다 트레이싱을 할 거고요 그다음에 llm 오픈 AI 앱 API 키 어 설정해 주도록 하겠습니다 레그 튜토리얼 이렇게 설정해 주고 자 그리고 뭐 필요한 모듈도 임포트 해 오고요 첫 번째로는 저희가 네이버 뉴스를 가지고 올 거거든요이 네이버 뉴스를 가져올 때 웹베이스 로더는 걸 쓰면은 어 손쉽게 웹페이지의 내용을 크롤링해서 결과로 가져올 수가 있어요 뉴스 기사가 이렇게 나와 있습니다 굉장히 훈훈한 기사여서 요거를 한번 가지고 와 봤고요 자 여기서 우리가 궁금한 거는 여기 안에 있는 내용들이죠 이걸 가져와야 돼요 우리가 원래는 파이썬으로 뭐 크롤러 써 가지고 뷰티풀 수비나 아니면은 셀레니움 써 가지고 이거 긁어 와야 되죠 랭 체인의 웹베이스 로더 쓰면 는 쉽게 가져옵니다 어떻게 가져오냐 먼저 우클릭해서 요소 검사를 하신 다음에 여기 안에 우리가 가지고 오고자 하는 요소를 클릭해요 요렇게 바디를 클릭합니다 클릭하면 여기 dib 해 가지고 뉴스 CT 언더바 아티클이 되어 있고 클래스 네임도 되어 있죠 만약에요 내용을 가지고 오고 싶어요 그러면 아이디로 가지고 오셔도 되고 아니면 클래스 네임으로 가지고 오셔도 됩니다 요거를 복사를 해요 복사를 하신 다음에 여기 비주얼 스튜디오 코드에서 요거 붙여 넣게 하면 되는 거예요 제가 방금 복사한 내용이거든요 바디 부분 요거는 이제 뉴스 기사의 타이틀도 가지고 오고 싶어서 이렇게 넣었습니다 di 는 태그에 여기에 지금 DI 태그로 붙어 있는 어 클래스 어트리뷰트 클래스 속성값이 그니까 요거 있 놈과 요거 있 놈을 가지고 와라라고 한 거예요 이걸 한번 실행해 볼게요 실행하면 뉴스 기사의 본문을 기가 막히게 쉽게 잘 가져오는 것을 볼 수가 있어요 자 만약에 여러분들이 웹사이트에서 크롤링해서 가지고 와야 된다라고 했을 때는 여기에 들어가는 유아를 바꿔 주시고 방금 요소 검사해 가지고 그 클래스의 이름 바꿔 주시면 가지고 오실 수가 있거든요 근데 나는 웹페이지를 가지고 올게 아니라 PDF 문서를 로드하고 싶은데요 하시면은 로더를 PDF Pro 가지고 오시면 돼요 제가 작성하고 있는 다큐먼트 로더는 문서에 보시면은 PDF 로더가 있거든요 요거를 가지고 오는 거죠 여기 보면은 다큐먼트 로더스 아는 모듈 안에서 PI PDF 로더로 가지고 오죠 요게 이제 PDF 문서의 제목이 아아 그 요거를 복사해서 뭐 대신 쓰면 될까요 로더 대신 요거 대신 요거를 주석 치고 이렇게 가져오면 되는 그럼 어때요 얘는 웹문서에서 가져오는 거고 어 내가 이번에 PDF에서 가져올 거야 요거 가져오는 거죠 자 이거 로드해 보죠 문제없이 동작을 한다거 이게 정말 랭 이인이 잘만 거죠 그러니까 랭 체인이 어 너 왼 문서 가져오고 싶어 그럼 이거 써 그리고 너 PDF 가지고 오고 싶어 이거 써 대신 이거 함수는 네가 안 건드려도 돼요 앞단 네가 바꿔 주면 돼 PDF 할 때는 PDF 로더 쓰면 되고 웹베이스 로더 쓰면은 웹베이스 로더 쓰면 돼 예제로 작성해 놓은 파일들을 보면은 여러 가지 형태의 파일들을 이렇게 가지고 올 수 있습니다 아래쪽에 보면은 폴더를 지정하면 폴더 안에 있는 내용들 전부 다 가져오는 것도 가능하고요 그리고 csb 가져오는 거 html 문서도 가져오실 수가 있고 그리고 뭐 제이슨 형태나 그밖에 파이 파일 등등 다양한 문서들을 이렇게 가지고 오실 수가 있어요 다 보면은 로더 점 로드는 똑같죠이 앞에 있는 부분만 바꿔 주시면 되는 거예요 나중에 여러분들이 PDF 가지고 하고 싶다면 요것만 바꿔 주시면 되겠죠 다시 뉴스 기사 내용 볼게요 이렇게 해서 뉴스 기사의 본문을 잘 가지고 왔습니다 메타데이터에 보면은 어느 소스에서 가져온 건지 URL이 잘 들어가 있는 것을 볼 수가 있고요 다음으로 보시 내용이 이제 스플리터 있니다 자 우리가 로드를 했으면 그다음으로 해 주셔야 되는게 스플릿이 그럼 스플릿은 언제 쓰는 거냐 스플릿은 청크를 만들 때 씁니다 데이터 청크를 만들 때 데이터 청크는 거는 뭘까요 우리 l&m 보면은 대표적으로 GPT 모델 볼게요 GPT 3.5 4등 무한정으로 텍스트를 받아들일 수 있는 건 아니잖아요 그런데 우리 문서의 길이는 얘가 받아들일 수 있는 양보다 클 수 있어요 더 쉬운 예를 들어 볼게요 만약에 PDF 문서를 로드를 했는데 PDF 100장짜리 LM이 받아들일 수 있는 거는 한 번에 열 장까지 밖에 못 받아들여요 그럼 100장짜리 얘한테 넘기면 어떻게 될까요 그러면 에러가 떨어지죠 어 얘가 허용할 수 있는 거는 10장까지만 받아들일 수 있는데 당신 100장 넘겨주면 어떡합니까라고 해서 에러가 떨어집니다 그럼 우리 어떻게 해야 될까요 열 장보다 작은 단위를 넣어 줘야 되는 거예요 그래서 우리는 뭐 어떤 걸 하냐면 분할이라는 단계를 수행하는 거죠 분할을 해 가지고 100장짜리 문서를 잘게 쪼개 놓는 거예요 뭐 사실 열 장으로 곱하기 개 이렇게 쪼개도 되죠 근데 보통 이렇게 쪼개는 경우는 잘 없어요 더 잘게 쪼개다 글자수 단위로 쪼갤 수도 있고 뭐 토큰 단위 뭐 여러 가지 단위 기준으로 쪼갤 수 있어요 여기서 중요한 거는 뭐 어떻게 쪼개냐 이것도 중요한 포인트가 될 수 있어요 하지만 여기서 중요한 거는 쪼갠다는 거 근데 여기서 쪼갤 때도요 여러분들이 신경 써 주셔야 되는 포인트가 있어요 100장짜리 문서에서 하나의 주제를 다룰 때 보통 한 장 정도 분량을 하나의 주제로 다르고 그 하나의 소 주제라고 보시면 되겠죠 이게 한 100개 정도 있는 거예요 그래서 100장짜리 됐어요 그러면 여러분들이 만약에 10장씩 쪼이면 어떻게 될까요 한 장에 하나의 소주제가 맵핑이 되어 있는데 열 장씩 끊으면이 열 장 안에는 열 개의 소주제가 난립해 있겠죠 우리가 어떤 질문을 할 거예요 질문했을 때 쪼개진 단위에서 하나의 대표적인 단락을 가지고 올 거거든요데 단락을 가졌는데 봤더니 열개의 주제가 짬뽕 돼 있어 그러면은이 짬뽕 되어 있는 주제가 나중에 l&m 쪽으로 흘러 들어갈 텐데 아무래도 품질이 떨어질 거잖아요 그러니까 제가 드리고 싶은 말씀은 쪼갤 때도 이왕이면 내가 어떤 질문을 하면은 그 질문을 포함하는 범위만 깔끔하게 쪼개지면 가장 베스트 겠죠 그 단위가 얼마나 되는지는 저도 모르죠 문서마다 너무 달라집니다 문서마다 이런 것들을 최적화는게 중요하고요 사실 문서마다 다 다르기 때문에 우리가 이거를 아 최적 하기는 사실 거의 불가능해요 이거는 여러 가지를 테스트해 보면서 어느 정도로 쪼개는게 어 우리 상황이 맞는지 그런 것들을 확인해 보시는게 중요합니다 자 그러면 여기 리커시브 캐릭터 텍스트 스플리터는 걸 써서 쪼개 쪼개는데 청크 사이즈라는 거는 쪼개는 단위 뭐 글자수 정도라고 생각하시면 되고요 청크 오버랩을 뭐냐면 우리가 쪼갤 때 문단을 자를 때 이렇게 자르고 이렇게 자르나요 그러면 어떻게 되죠 만약에 어떤 내용이 여기 끝부분에 나오고 여기 끝부분에 나올 수가 있어요 이렇게 걸쳐 있을 수도 있잖아요 그렇기 때문에 오버랩이란 걸 줍니다 그래서 우리가 이렇게 가운데 부분을 뚝 자르는게 아니라 문서 하나가 있고 이렇게 겹쳐져서 가져올 수 있도록 쪼개진 단위에서 시작이 어색하지 않도록 앞에 있는 내용을 좀 포함할 수 있도록 그게 보통은 오버랩을 주는 편이에요 그래서 이거를 해석을 하자면 최대 1 글자 단위로 쪼갤 건데 중간에 50 글자 정도는 겹치게 가져와라 요런 의미로 보시면 될 거 같아요 자 그래서 스플릿 도큐먼트 씁니다 쓰면은 요거는 굉장히 짧은 문서아 자 짧은 문서인데 몇 개로 쪼개져 있는지 한번 볼게요 자 렌에 스플릿을 찍어 보면 세 개의 문서로 쪼개진 거를 볼 수가 있어요 기사가 길지 않다 보 까 세 개의 문서로 쪼개진 거죠 자 다음으로는 이제 임베딩 하고 벡터 스토에 저장하는 거예요 우리가 나중에 검색을 할 거예요 검색을 해서 가져올 건데 예를 들어서이 신문 기사에 기사의 내용을 바탕으로 우리 질문할 거예요 뭐 가령 출산 직원에게 얼마를 샀습니까 아는 질문을 던져요 그러면 얘는 얼마를 쌓느냐라는 질문과 유사도가 높은 문단을 발라낼 거예요 발라내서 그걸 기반으로 얼마를 쐈는지 유치를 하게 됩니다 자 그러면이 문단이 예를 들면 이렇게 쪼개져 있고 뭐 한 요렇게 쪼개져 있었어요이 1번 문단이 있고 2번 문단이 있고 3번 문단이 있어요 그럼 출산 직원에게 얼마를 샀습니까라는 거를이 각 문단별로 유사도 계산을 해요요 내용이 들어가 있으면은 유사도가 아무래도 높게 나올 가능성이 높겠죠 얘가 유사도가 높게 나오고 얘가 그다음으로 높게 나오고 얘가 마지막으로 높게 나왔어요 그러면 얘는 어떤 액션을 취하면요 문단을 가져와서이 안에서 얼마를 썼는지 그 답변을 생성에서 주게 되는 거예요 자 그런데 그 유사도 계산하려면 우리가 필요한게 임베딩이란게 필요하고요 우리가 그냥 문장으로 들어가 는게 아니라 이거를 어 벡터 표현으로 변환 합니다 오픈 아이의 임베딩은 1536 차원의 어떤 벡터 공간에다가 우리가 질문한 내용들을 임베딩 해서 어떤 좌표계로 만들어 두는 거예요 좌표계로 만들어서이 스라는 벡터 DV 다가 저장을 해 둡니다 그서 요거는 이제 벡터 스토어를 생성하는 그런 로직이 이렇게 생성을 했으면 그다음에 리트리버를 가져오는 자요 코드와요 코드는 어떻게 보시면 되냐면 지금 DB 뉴스 기사를 저장하죠 저장하는 단계가 바로요 코드예요 근데 우리가 저장만 한다 라고 해서 여기서 검색해서 쓸 수 있는 건 아니에요 검색을 하려면 뭐가 필요하냐면 리트리버가 필요하죠 그래서이 DB 리트리버를 가져오는 거예요 자 우리가 저장만 한 거예요 요거는 저장만 한 거고 우리가 나중에 리트리버를 통해서 우리가 원하는 단락을 검색을 할 겁니다 그때 쓸 거예요 자 그래서 리트리버까지 가지고 왔고요 다음으로는 프롬프트 있니다 프롬프트는 레그 프롬프트는 걸 쓸 건데 허브점 풀을 하죠이 허브는 어디냐면 랭 체인의 허브에요 아 이거 정말 저는 추천드립니다 제가 지금 보여 드릴 거는 랭스 이스의 허브라는 건데 여러분들이 프롬프트 엔지니어링을 하려면 굉장히 많은 시간이 들어가잖아요 근데이 랭스 이스의 허브에 오셔서 qa 오벌 도큐먼트 뭐 체보 에이전트 여러 가지 카테고리로 잘 정리가 되어 있거든요 여기 있는 미리 만들어 놓은 좋은 프롬프트 그냥 가져다 쓰시면 돼요 우리 레그를 할 거니까 레그라 입력을 하고이 중에서 어 탑비드 요걸 입력하면요 rlm이라는 거에 슬래시 하고 레그 빼기 프롬트 이렇게 나오죠 자 요거에 프롬프트를 내가 쓰고 싶어요 밑에 내려 보시면은 어떤 식으로 프롬프트 입력됐는지 이거 복사해도 쓰실 수 있거든요 근데 이럴 필요 없이 여기 밑에 코드도 나와 있네요 여기에 있는 이름을 복사를 합니다 복사를 하고 여기 여기 오셔서 붙여 넣기를 하고 그다음에 허브점 프 하면은 여러분들이 업로드되어 있는이 프롬프트를 바로 가져다 쓸 수 있는 거예 근데 여기 인풋 베리에 보면은 퀘는 사용자가 입력하는 질문이 들어갈 거고요 그다음에 컨텍스트에는 우리가 문서를 지금 여러 개 쪼개 아아 그다음에 어떤 질문 하면은이 중에 과장 관련성 높은 문서를 뽑을 거예요 그리고 그 뽑힌 문서가 컨텍스트로 들어가는 거예요 그러면 우리의 답변은이 뽑힌 문서에 대한 답변을 생성해서 얘가 주는 거 이런 식으로 동작합니다 컨텍스트에는 리트리버 여기 이전에 벡터 스토어에서 검색기 가져 왔잖아요 검색 로 검색한 결과 그러니까 퀘에 대해서 가장 연관성이 높은 단락을 가져올 거거든요 그 단락이 여기에 있는 컨텍스트로 들어간다고 보시면 됩니다 다음으로 필요한 거는 이제 l&m이에요 지금 우리 단계는 리트리버가 만들었잖아요 검색 기까지 만들었으면 트도 만들었고요 그다음에 이제 LM LM 브레인에 해당하는 거예요 두 뇌저 두뇌 IQ 100인 사람이 있고 IQ 200인 사람이 있어요 똑같은 문서와 똑같은 프롬프트를 주더라도 200 인상이 더 잘할 가능성이 높잖아요이 IQ 해당하는게 LM이라고 보시면 돼요 여러분들의 상황에 맞게 쓰시면 되는데 아 물론 우리가 제일 좋은 gpt4 모델 쓰면 좋겠죠 근데 이걸 쓰려고 보면은 속도 문제도 있지만 비용적인 측면도 꽤 크잖아요 그럼 나는 비용 좀 저렴하게 가고 싶다 GPT 3.5를 가도 되고 나는 아예 무료로 쓰고 싶다 그럼 허깅 페이스에 오픈 소스 모델 쓰시면 됩니다 이런 것들도 교체도 자유롭고 여러분들이 상황에 맞게 쓰시면 돼요 저는 GPT 3.5 터보 모델을 쓸 거고요 소소한 팁 하나를 드리자면 어 한글 관련된 처리는 GPT 4 모델 있죠 GPT 4의 터보의 프리뷰 모델 훨씬 더 좋습니다 근데 요 영어로 된 처리하는 거는 3,5 터보가 가성비가 좋죠 그거는 알아서 상황에 맞게 쓰시면 되고요 자 그다음에 포맷 도큐먼트 요거는 뭐 해 주는 거냐면 검색한 문서 결과를 하나의 문단으로 합쳐 주는 거죠 자이 검색을 할 적에 얘는 단락을 하나만 뽑는 건 아니에요 우리가 정할 수 있는데 단락을 두 개를 뽑을 수 있고 세 개를 뽑을 수 있어요 만약에 신문기사의 주제는 무엇입니까라고 물어봤어요데 단락이 1번 2번 3번 이렇게 쭉 많아요이 중에서 주제가 한 군데서만 나오는 건 아니잖아요 여러 군데에서 핵심 아이디어가 나올 수 있잖아요 그렇기 때문에 유사도 제일 높은 거 하나만 뽑는 경우는 잘 없고 잘게 쪼개 놓은 데에서 뭐 세 개를 뽑든 다섯 개를 뽑든 열 개를 뽑든 이렇게 n 개를 뽑는 거예요 뽑으면 여러 개의 문서가 될 거잖아요이 여러 개의 문서를 하나로 합쳐 가지고 하나의 문장처럼 만들어서 넣어 주기 위해서 있는 함수가 바로이 포맷 도큐먼트고 보시 자 그래서 마지막으로 완성되는게 바로요 체인이에요 렇게 하면 완성이 되는 건데 다시 한번 복습해 볼게요 자 우리가 질문을 하잖아요 질문을 하면은 그 질문 내용이 여기에 들어가요 패션이라는 키값에 러너블 패스 스루로 들어갑니다 들어가면이 질문 기반으로 얘가 여기에 있는 리트리버 리트리버는 검색을 수행해요 그니까 만약에 출산 정책이 어떻게 됩니까라고 하면은이 출산 정책이라는 키워드와 가장 연관성이 높은 단락을 이렇게 쭉 뽑아 내요 그게 바로 리트리버 하는 역할이고 여러 개의 단락을 뽑아 냈으면 이거에 하나의 문장으로 합쳐준게이 포맷 박스요 그러면 리트리버의 역할은 내 질문의 연관성이 높은 단락을 뽑아 주는 역할을 하는 거고요 그럼 이거 하나로 로 문장을 연결지어서 나오게 되는 거죠 결국에는 여기서는 요게 중요한 거예요 내가 사용자가 질문을 던진다 그 질문을 바탕으로 연관성 높은 도큐먼트를 서칭을 한다 서칭 된 결과를 하나로 합친다 그러면이 하나로 합쳐진이 문장은 질문과 연관성이 높은 단락에 그냥 하나로 이어진 문장이 되는 거예요 그 문장을 프롬프트 테 넘겨 주는 거죠 넘겨 주고한테 생각해서 결과를 달라라고 하는 거예요 그러면 주어진 주어진 정보라고 하면 리트리버를 통해서 검색된 정보를 의미합니다 주어 정보와 그다음에 사용자의 질문 등을 고려를 해서 원하는 답변을 주게 되는 거죠 요렇게 만들어 주는 체인을 생성을 해보고요 자 그러면 한번 질문을 해 볼게요 자 요런 신문 기사입니다 출산 직원에게 1억 원 쏜다 격적 저출생 정책이라는 기사이고 저는 요렇게 한번 질문을 던져 볼게요 부형 그룹의 출산 장려 정책에 대해서 설명해 주세요라고 질문을 하면요 자 요렇게 답변을 줬네요 출산 장려 정책으로 2021년도 이후에 태어난 자녀에게 1억 원씩 지급을 하고 쌍둥이 자녀가 있을 경우에 2억원 지급한다 셋째 의 자녀를 나을 경우에는 주택을 제공하겠다는 계획을 밝혔다 자이 내용이 맞는지 볼까요 자 여기에 그 내용이 있네요 자녀의 1억 원씩 쌍둥이 자녀가 있으면 2억원 받고 그다음에 국민 주택을 제공하겠다는 뜻도 밝혔습니다 잘 나와 있어요 여기에서이 단락이 아마 인풋으로 들어갔을 거예요 이거를 랭 스미스에 가면은 확인해 볼 수가 있거든요 자 여기 보시면 제가 질문이 요렇게 들어갔잖아요 출산 장려 정책에 대해서 설명해 주세요 그러면 아웃풋이 렇게 나왔는데이 리트리버가 어떤 도큐먼트를 뽑았냐 요런 도큐먼트를 뽑았어요 이게 그 오픈 AI GPT 4에 들어간거든요 도큐먼트를 한번 보면은 요게 첫 번째 출생 정책 그다음에 음모한 것도 있다 뭐 요런 식으로 되어 있고 그다음에 마지막으로는 요렇게 들어가 있는 거죠 아마 여기 유용한 정보들이 들어가 있잖아요 요거를 뽑아 가지고 줬을 것 같아요 랭 스미스를 활용하시면 리트리버가 어떤 도큐먼트를 이렇게 검색을 했고 이거를 l&m 테 넘겨 줬는지 볼 수가 있거든요 챗 오픈 AI 들어가 있는 입력을 보시면 지금 컨텍스트에 요렇게 들어가 있잖아요 신문 기사의 내용 자 이거 어떻게 발치를 한 거죠 내가 질문한 거 기반으로 리트리버부터 검색을 해서 그 문단들을 하나로 이어붙여 가지고 주는 거죠 그러면이 주어진 정보를 바탕으로 부형 그룹의 출산 장려 정책에 대해서 설명해 주세요라는 퀘이 들어왔기 때문에 이거를 바탕으로 지금 답변을 주는거다 이렇게 보시면 됩니다이 뉴스 기사는 짧아 가지고 거의 모든 기사의 내용이 다 들어갔을 것 같긴 한데요 PDF 문서의 내용이 굉장히 길 경우에는 레그를 잘 써서 중요한 정보가 여기 안에 포함되는게 반드시 필요하고요 그거에 따라서 성능이 많이 달라지고이 랭 스미스를 활용해서 리트리버가 원하는 단락을 잘 뽑아냈는지 하나하나 보면서 디버깅 하는게 선행이 돼야 돼요 lml 아무리 좋은 걸 쓰면 뭐 합니까 여기서 발라내는 결과가 좋지 못하다면 아무리 좋은 lml 써도 결과가 만족스럽지 못하실 거예요 그래서 랭스 미스의 리트리버의 우리가 쿼리를 날렸을 때 질문을 날렸을 때 답변을 하기 위해서 그 필요한 정보들이 여기 들어가 있는지 반드시 사전에 검출 해 주셔야 됩니다 그다음에 얼마에 지원을 제공하나요 요것도 한번 해 볼게요 이것도 해 봤더니 1억 원 지원한다 요것도 2억 원 지원한다 답변이 이렇게 잘 나오고요 그다음에 저출생 대책을 블랙포인트 형식으로 작성해 달라 내가 원하는 형식으로 출력을 요구할 수도 있는 이거는 l&m이 너무 잘해 주는 일 중에 하나니까 자 이렇게 했더니 블랙포인트 형식으로 깔끔하게 어 잘 정리해서 주는 것을 볼 수가 있고요 아 요거는 제가 재미삼아서 한번 넣어 봤는데 부형 그룹의 임직원 숫자는 몇 명인가요 이런 거는 기사에 없습니다 없는데 얘가 어떤 식으로 답변하지 볼게요 자 답변이 이렇게 나왔어요 임직원 숫자에 대한 정보는 제공된 문맥에서 확인될 수 없다 요거는 출산 장 정책과 관련된 내용을 다루고 있고 임직원 숫자에 대한 구체적인 정보를 얻기 위해서는 추가적인 자료가 필요하다라고 나오죠 얘가 할루시네이션 통해서 막 임직원 숫자는 뭐 80명 이니다 이런 식으로 얘기하는게 아니라 지금 얘는 제공된 문맥에서 확인할 수 없다라고 잘 대답을 하죠 그 비밀은 바로 이제 프롬프트에 들어가 있습니다 자 이게 프롬프트 든요 그러면이 프롬프트를 읽어 보시면 퀘 서링 태스크를 수행하고 있는데 요게 핵심이죠 답변을 모르면 그냥 모른다고 할 것이지 만들어 내지 말아라라는 프롬프트가 들어가 있기 때문에 이렇게 모르는 답변에 대해서 할루시네이션 어느 정도 방지해 주는 것을 볼 수가 있고요 제가 지금 썼던이 레그 프라프라 거는 가장 기본적인 프롬프트에 이거보다 훨씬 더 할루시네이션 스트릭트게 방지해 줄 수 있는 좋은 프도 많이 나와 있거든요 이런 것들을 여러분들이 추가해서 하면은 얘가 막 말을 지어내거나 하는 현상들을 많이 없애실 수가 있습니다 오늘은이 네이버 뉴스를 토대로 레그를 한번 살펴봤습니다데 오늘 제가 공유드릴 내용은 사실 어떻게 보면은 뼈대에 해당하는 내용이거든요 가장 기본적인 요소들을 모아다가 끝까지만 한번 훑어 본 거예요 답변을내는 것까지데 당연히 여기에 PDF 문서가 더 방대한 양의 자료가 들어가거나 문서가 여러 개가 되면은 난이도가 더 올라갈 거예요 그럴 때는 스플릿 하는 방식도 새롭게 고민 해 보셔야 되고 베딩도 바꿔 보셔야 되고 비도 여러 가지를 써 보시면서 테스트를 해 보셔야 됩니다 이거 하나하나마다 경우의 수가 굉장히 많은데요 그래도 다행스러운 점은 랭 체인은 통합된 인터페이스를 제공해 주기 때문에 우리가 쉽게쉽게 다른 방법들을 시도해 볼 수가 있어요 제가 앞으로 텍스트 스플리터 임베딩 벡터 스토어이 내용들을 를 계속 업로드를 할 예정이거든요이 업로드되는 내용들을 보시고 여러분들이 여러 가지 방법들로 한번 해 보시고요이 레그 2 자료는 요거를 모듈별로 좀 더 심도 있게 보는 내용이에요 혹시 관심 있으신 분들은이 레그 2 파일도 한번 보시면서 연구해 보시고요 또 궁금한 점이 있다면 댓글로 남겨 주시기 바랍니다 앞으로 제가 업로드할 파일들은 모두 랭 cein 한국어 튜토리얼이라요 기업 리파지토리에 올려 드릴 예정이고요 주소는 정보를 안에 넣어 놓도록 하겠습니다 관심 있으신 분들은요 안에 있는 튜토리얼 실행해 보면서 연구해 보셔도요 것 같아요 오늘은 외에 대해서 간단히 한번 알아봤고 오늘 영상은 여기까지입니다 [음악] 감사합니다')],\n",
       "  'summary': '이번 영상에서는 \"레그(레트리벌 증강 생성)\"에 대해 다루고 있습니다. 레그는 RAG(Retrieval-Augmented Generation)의 약자로, 데이터에서 원하는 정보를 추출하고 활용하여 답변을 생성하는 기술입니다. 최근 LLM(대형 언어 모델)을 사용함에 따라 회사의 내규나 특정 정보를 요청할 수 있지만, 이러한 정보가 크고 복잡할 경우 일반적인 DB 검색으로는 부족하다는 점을 설명합니다. \\n\\n레그 기술을 사용하면, 먼저 데이터를 로드하고 분할하여 임베딩한 후, 이를 벡터 DB에 저장합니다. 이후 사용자가 질문을 던지면, 관련된 정보를 검색하여 추출한 후, 이 정보를 기반으로 LLM을 통해 자연스러운 답변을 생성합니다. \\n\\n영상에서는 이 과정에서 \"랭 체인\"이라는 통합된 인터페이스를 사용하면 다양한 형태의 문서를 손쉽게 처리할 수 있음을 강조합니다. 또한, PDF나 웹페이지의 데이터를 빠르게 가져오는 방법과, 데이터를 적절히 분할하고 최적화하여 LLM이 이해할 수 있도록 구성하는 과정도 설명합니다. \\n\\n마지막으로, 실제 사례를 통해 출산 장려 정책에 대한 질문을 던지고, 리트리버가 이와 관련된 정보를 어떻게 추출하고 답변을 생성하는지에 대한 데모를 보여줍니다. 레그 기술이 어떻게 작용하는지에 대해 기본적인 흐름을 이해할 수 있도록 돕는 영상입니다.'},\n",
       " {'id': '84paXmEsjjg',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLARhrBfQwlUZu-kL78JiAK12VYMjA',\n",
       "   'https://i.ytimg.com/vi/84paXmEsjjg/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCZHMGJ0GLCy1Fzpxt0GmCqTmCD5w'],\n",
       "  'title': '9장 LangChain + YouTube Transcript API +GPT-4o-mini  으로 유튜브 자막 추출부터 요약, 번역, 요점 정리까지',\n",
       "  'long_desc': None,\n",
       "  'channel': '오늘코드todaycode',\n",
       "  'duration': '12:07',\n",
       "  'views': '조회수 376회',\n",
       "  'publish_time': '3개월 전',\n",
       "  'url_suffix': '/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'video_url': 'https://youtube.com/watch?v=84paXmEsjjg&pp=ygUJbGFuZ2NoYWlu',\n",
       "  'content': [Document(metadata={'source': '84paXmEsjjg'}, page_content='안녕하세요. NLP와 LM 실전 가이드 9장에 있는 책 어 312쪽부터 317쪽에 있는 유튜브 영상 요약하기를 실습을 진행을 해 보도록 하겠습니다. 일단이 책은 이제 원서 마스터링 NLP 어 from롬파데이션투 LLM 책의 이제 번역서인데요. 이제 원서의 실습 내용하고 조금 다르게 구성이 되어 있습니다.이 이제 원서 어의 이제 실습어요 그 코랩 링크를 통해서도 이제 바로 이제 들어와서 이렇게 보실 수가 있는데요. 여기에서는 이제 인베드 체인이라는 것을 이제 사용을 해요. 근데 인베드 체인이 어 유료로 어 변경이 되었고요. 그리고 여기 인베드 체인을 사용해서 이제 어떤 실습을 하냐면 원서에서는여이 유튜브 자막을 가지고 와요. 그래서 그 자막을 이제 번역하고 요약해 보는 실습으로 구성이 되어 있는데이 정도의 실습은 굳이요 인베드 체인을 사용하지 않더라도 실습이 가능하기 때문에 인베드 체인을 이제 복잡하게 이제 설정하는 것보다는 어 저희는 그냥 오픈소스 라이브러리들을 이제 사용을 해서 진행을 해 볼 예정입니다. 일단 이제 실습에 들어가기 전에 어 저희가 할 실습에 대해서 요약을 해보고 진행을 해 보도록 할 텐데요. 유튜브 영상 어 자막 추출 및 요약을 진행을 해 볼 예정이고요. 그래서 유튜브 영상의 자막을 API로 이제 추출을 해서 랭체인과 GPT 45니로 이제 요약하고 이제 다구어 번역하는 이제 전체 과정을 소개를 해 보도록 하겠습니다. 그래서이 내용은 NLP와 LM 실전 가이드 9장을 기반으로 이제 한국어 주요를 깔끔하게 이제 정리하는 이제 방법을 익혀보도록 할 예정이에요. 그래서 필요한 라이브러리 랭체인 그다음에 랭체인 오픈 AI 그다음에 유튜브 트랜스크립트 API를 설치를 할 거고이 유튜브 트랜스크립트 API 같은 경우에는 유튜브에서 공식적으로 이제 제공하고 있는 API가 아니라 그냥 오픈 소스로 개발자들이 만들어서 이제 어 공유하고 있는 어 API다라고 보시면은 됩니다. 그래서 이제 필요한 모듈 이제 임포트 할 때 이제 OS나 이제 텍스트 랩도 임포트를 할 텐데 뭐 긴 텍스트들에 대한 줄바금 처리를 할 때 텍스트 랩을 사용할 거예요. 그래서 다국어 번역을 했을 때 뭐 한국어, 뭐 러시아, 뭐 독일어 요런 것들 이제 텍스트 랩을 통해서 조금 보기 좋게 전 처리를 해 볼 예정이고요. 그다음에 유튜브 트랜스크립트 API를 통해서 유튜브 자막을 이제 추출을 해 볼 예정이고 어 랭체인으로 이제 프롬프트 템플릿이라든지 오픈 AI의 채팅 어 기반의 LLM을 이제 사용을 해 볼 예정입니다. 그래서 API 키도 마찬가지로 이제 저희는 콜랩을 통해서 이제 실습을 하기 때문에 그 콜랩 왼쪽에 열쇠 모양 클릭을 하시게 되면은 요런 식으로 오픈 AI API 키 등록하고 이제 사용하실 수가 있고요. 로컬에서 이제 사용하실 때는 어 이런 이제 환경 변수에 설정을 하고 사용을 하실 수도 있습니다. 그래서 유튜브 자막 최출 과정은 일단 영상 URL를 지정을 하고 유튜브 트랜스크립트 API를 통해서 가져오는데 일단요 아이디값 영상의 아이디값만 있으면은 어 유튜브 트랜스크립트 API를 통해서 스크립트 트랜스크립트 하게 되면은 영어 자막을 가져올 수가 있습니다. 그래서 자막 딕셔너리에서 텍스트 항목만 이제 추출을 해서 하나의 문자열로 합쳐서 어 실습을 진행을 해 볼 예정이에요. 그리고 이제 랭체인으로 요약하고 번역 설정을 해 보도록 할 텐데 GPT 45 미니는 어 굉장히 이제 가격도 저렴하고 성능도 그렇게 이제 떨어지진 않아서 GPT 45 미니를 이제 사용을 해 볼 예정이고요. 그다음에 이제 어 비용도 어 저렴하다 이렇게 이제 볼 수 있습니다. 그래서 이제 프롬프트 템플릿을 구성을 해서 뭐 전체 내용을 내문장 길이로 요약한다든지 아니면은 한국어 러시아 독일어로 번역을 해 본다든지 그다음에 언어간 이제 구분을 위해서 특수 문자를 지어 그 지정을 하고 이제 텍스트 랩으로 전 처리하는 어 그런 과정이 있고요. 그다음에 이제 템플릿 프롬프트 템플릿으로 입력 변수를 이제 설정해서 여기에다가 이제 자막을 넣어 준다든지 하는 내용으로 이제 구성이 되어 있습니다. 그다음에 이제 프롬프트 템플릿이 구성했다면 이제 체인을 구성을 해 주는데 어이 체인 구성할 때 이제 파이프 연산자로 이제 런너블 시퀀스 형태로 연결을 해서 사용을 할 거고요. 그다음에 이제 프롬프트에다가 이제 자막 텍스트 입력을 해 주고 그다음 이제 LM 호출해서 인보크 메 그 메서드를 통해서 LLM의 입력을 전달하고 결과를 받을 예정이에요. 그다음에 텍스트 랩으로 이제 가독성 좋게 어 전처리까지 이제 해 보는게 실습 내용입니다. 어, 그리고 이제 뭐 번역을 했다면 다음으로 이제 요약 테스크를 진행을 할 텐데 이제 간결한 한국어 요점을 이제 정리해 달라. 그래서 뭐 세 개에서 다섯 개 분리 어 형태로 머리끌로 이제 정리해 달라 요렇게 이제 어 요청을 할 예정입니다. 그래서 이제 글머리 기호로 시작하는 이제 한국어로 이제 작성을 해 달라라고 할 거예요. 그래서 이제 프롬프트 템플릿 구성하고 체인 구성하고 이전 결과 번역 결과를 새 체인에 전달을 해서 마지막에는 이제 한국어 주요 요점을 이제 표시하는 이제 요약을 해 보는 어 방법으로 이제 번역과 요약 테스크를 진행을 해 보도록 하겠습니다. 그럼 이제 코랩으로 넘어와서 어 직접 이제 실습 진행을 해 보도록 할 텐데요. 일단 PP 인스톨 해서 이제 앞에서 이제 소개했었던 것처럼 이제 랭체인 그다음에 랭체인에서 이제 오픈 AI API 이제 사용할 거기 때문에 랭체인 오픈 A AP AI 그다음에 어 랭체인 커뮤니티 유튜브 트랜스크립트 API 설치를 해 주도록 하고요. 그다음에 이제 OS 뭐 텍스트 랩 그다음에 유튜브 어 API 그다음에 랭체인에서는 이제 프롬프트 템플릿과 채 높은 오픈 AI 불러오도록 하고요. 그다음에 이제 왼쪽 열쇠 버튼 누르게 되면은 이제 미리 어 저장을 해 두었기 때문에 한 번만 입력을 해 두게 되면 내 계정에 저장이 되는 거기 때문에 어 별도로 따로 입력을 해 주시지 않아도 됩니다. 네. 만약에 내가 환경 변수 로컬에서 실습하고 있다 하시게 되면은 환경 변수에서 직접 불러오시거나 아니면 여기에다가 지정하고 사용을 해 주시는 방법도 있습니다. 그래서 이제 오픈 AI API 키 어가 만약에 이제 없다라고 하게 되면은이 코랩에서 오픈 AI API 키를 이제 불러오도록 어 했습니다. 그다음에 유튜브 비디오 URL를 통해서 URL을 지정을 해 주었고요. 그리고 유튜브 트랜스크립트 API를 통해서요 비디오 아이디에서요 언어 같은 경우에는이 유튜브 영상 같은 경우 이제 테드의 강연 영상이에요. 그래서요 테드 강연 영상에 대한 뒤에 있는요 아이디값만 요렇게 이제 가지고 온다. 그래서 영어로 되어 있기 때문에 어 이이라고 지정을 해 주었고 만약에 이제 한국어다라고 하게 되면은 이제 K5 요런 식으로 이제 지정을 해 주시면은 되겠죠. 그럼 이제 GPT 45니 어를 이제 사용을 해서 어 저희가 이제 다구어 번역을 이제 진행을 해 보도록 할 텐데 여기에 이제 서머리 프롬프트 템플릿에다가 이제 전체 내용을 검토하고 한국어 러시아 독일어로 이제 번역을 해 달라라고 프롬프트 템플릿을 작성을 했습니다. 그래서 여기에다가 어 그 문자열을 다른 문자열로 이제 구분을 해서 한국어 러시아 독일어를 구분을 하도록 했고요. 그래서 프롬프트 템플릿에다가 지금 위에 서머리 프롬프트 템플릿 써 놓은 내용 지정을 해 주고 그다음에 인풋 베리어블에다가 이제 컨텐츠 해서 이제 넣어 주도록 했어요. 그다음에이 서머리 그 프롬프트에서요 프롬프트와 llm 모델은 이제 오픈 AI의요 채 어 오픈 AI요 모델을 이제 지정을 해 주도록 했습니다. 그다음에 여기 이제 그 서머리 프롬프트의 포맷 해서 이제 컨텐츠에다가는 어 영어 텍스트를 이제 넣어 주도록 했어요.이 영어 텍스트는 어디에 있냐면 우리가이 유튜브에서 가져온 자막을 잉글시 텍스트라는 어 내용으로 이제 넣어 줬어요. 그래서 그 영어 텍스트 이제 확인을 해 보게 되면은 여기에서 어 요렇게 이제 테드의 어 영상에 대한 그 영어 어 자막을 가지고 왔고이 천자만 이제 일단 보여 주도록 했어요. 이제 너무 어 기니까. 그래서요 내용을 어 지금이 잉글리시 텍스트에다가 넣어 줄 예정입니다. 그래서 여기 컨텐츠라고 지정을 했는데요 인풋 베리어블 해서요 프롬프트 템플릿의요 컨텐츠가 여기에 이제 들어가게 된다라고 이제 보시면은 되고 그리고요 컨텐츠는요 서머리 프롬프트 템플릿의 이제 변수로 여기 컨텐츠로 이제 들어가게 됩니다. 그래서요 컨텐츠 어를 이제 그 영어 자막 텍스트를 넣어 주도록 하고요. 프롬프트 체인 구성해 준 거를 이제 서머리 체인이라는 변수에다가 넣어 주었는데요. 여기에서 인보크 해서 저 런너블 시퀀스로 어 되어 있는이 프롬프트와 모델을요 변수로 이제 넣어 주었습니다. 그다음에 여기에서 내문장 길이에 영어로 요약한 다음 한국어 러시아 독일어로 이제 번역해 달라 아라고 했죠. 그래서 요약하고 이제 번역을 이제 수행 어 한 결과를 이제 출력을 해 보고 여기에서 위에서 이제 구분자 요걸로 이제 넣어 달라라고 했으니까 이제 구분자로 어 번역과 이제 요약이 되는지 확인을 해 보도록 하겠습니다. 그럼 이렇게 번역 결과가 나왔는데요. 일단이 원문 나왔고요. 그다음에 요약하고 이제 번역해 달라라고 했는데 영어로 요약을 먼저 하고 그다음에 이제 번역을 하는데 한국어 러시아 독일어로 이제 번역을 해 달라고 했어요.이 한국어 위에는 요렇게 어 그 대시 어 문자를 넣어 주고 그다음에 여기에는 어 아스트리크 문자를 넣어 주고 그다음에는 요렇게 이제 문자로 이제 구분을 해서 한국어 러시아 독일어를 이제 구분을 했고 그다음에 요약 및 번역 결과 아까지 요렇게 이제 넣어 주었습니다. 그래서 이제 보기 좋게 이제 출력한 거는요 텍스트 랩을 통해서 어 보기 좋게 어 렇게 그 출력까지 이제 해 주도록 했는데 한국어로 이제 번역한 결과를 보게 되면은 이제 좋은 관계는 건강하고 행복한 삶에 필수적이며 그다음에 어 연구한 결과 어 사회적 연결이 중요하고 외로움이 건강과 행복에 부정적을 낀 영향을 미친다고 강 그 강조한다. 요런 이제 어 내용들이 이제 나와 있습니다. 그래서 각 언어별 요청한 언어별로 요약과 번역을 했고요. 그다음에 여기에서 글리로 작성해 달라라고 했어요. 그래서 각 요점은 글리 기호로 시작하는 한국어로만 이제 작성을 해 달라라고 했습니다. 그래서 이제 프롬프트 템플릿에다가요 키포인트 프롬프트 템플릿을 넣어 줬고 그 변수로는 오리지널 엔서라고 요렇게 어 변수를 이제 넣어 주도록 했어요. 이전 질문에 대한 답변을 넣어 주고 그걸 이제 글리 기호로 이제 만들어 주는데요. 여기에서도 이제 체인어요 프롬프트 템플릿과 LLM 모델 오픈 AI에 사용을 하고요. 그다음에이 인보크에다가이 위에서 구성한 이제 체인의 인보크에서 오리지널 엔서 이전에 이제 답변받은 어 내용을 이제 변수로 프롬프트 템플릿에다가 넣어 줄 수 있도록 설정을 해 주었습니다. 그럼 이제 한국어 요점을 글리 기호로 어 정리해 달라라고 했는데요. 어 좋은 관계는 건강하고 행복한 삶의 필수적이다. 그다음에 사회적 연결이 중요하고 외로움과 어 외로움은 건강과 행복에 부정적인 영향을 미친다. 그래서 관계의 질이 양보다 중요하면 만족스러운 관계가 나이 될수록 더 나은 결과를 가져온다. 그래서 관계를 유지하는데 시간과 에너지를 투자하는 것이 충만한 삶의 핵심이다라고 해서 어 테드 어 영상을 이렇게 번역하고 요약하는 테스크를 이제 진행을 해 봤다라고 보시면은 될 거 같아요. 그래서 이번 실습에서는 이제 유튜브 어 그에 트랜스크립트 API와 그다음에 랭체인을 사용을 해서 어 간단한 RH 실습을 해 봤다. 검색 증강 생성 실습을 해 봤다라고 보시면은 될 것 같습니다. 그래서 인베드 체인을 사용을 해도 되지만 여기에서는 이제 어 별도의 개별적인 라이브러리를 사용을 해서 R를 이제 구현을 하고 실습을 해 보았습니다. 감사합니다.')],\n",
       "  'summary': '이 영상은 NLP와 LM 실전 가이드 9장에 기반하여 유튜브 영상의 자막을 추출하고 요약하는 실습을 소개합니다. 실습은 오픈소스 라이브러리를 이용해 진행되며, 인베드 체인을 사용하지 않고 대신 랭체인, GPT-4.5 미니를 활용합니다. \\n\\n실습 과정은 다음과 같습니다:\\n1. 유튜브 자막을 API를 통해 추출합니다.\\n2. 추출한 자막을 랭체인과 GPT-4.5 미니로 요약하고 다국어로 번역합니다.\\n\\n필요한 라이브러리인 랭체인, 랭체인 오픈 AI, 유튜브 트랜스크립트 API를 설치한 후, 유튜브 영상의 URL을 지정해 자막을 가져옵니다. 가져온 자막은 텍스트 랩을 통해 가독성을 높인 후, 번역 및 요약 요청을 위한 프롬프트 템플릿을 구성합니다.\\n\\n이를 통해 최종적으로, 요점을 한국어로 요약하는 작업도 수행하며, 각 언어로의 번역 결과와 함께 정리된 요점을 도출합니다. 실습을 통해 유튜브 자막을 효과적으로 처리하고 요약할 수 있는 방법을 배운다고 설명하고 있습니다.'},\n",
       " {'id': 'aDN8hm4pfPE',\n",
       "  'thumbnails': ['https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEjCOgCEMoBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLBkzzRK-6gLFE2KFpAQ6KmdBvKE3w',\n",
       "   'https://i.ytimg.com/vi/aDN8hm4pfPE/hq720.jpg?sqp=-oaymwEXCNAFEJQDSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBLCzdjvCdb-JFdr8K1JAJtcH1Mfw'],\n",
       "  'title': \"아직도 '랭체인'을 모른다고 해서 5분 설명해드림\",\n",
       "  'long_desc': None,\n",
       "  'channel': '노마드 코더 Nomad Coders',\n",
       "  'duration': '6:01',\n",
       "  'views': '조회수 46,383회',\n",
       "  'publish_time': '1년 전',\n",
       "  'url_suffix': '/watch?v=aDN8hm4pfPE&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'video_url': 'https://youtube.com/watch?v=aDN8hm4pfPE&pp=ygUJbGFuZ2NoYWlu0gcJCcEJAYcqIYzv',\n",
       "  'content': [Document(metadata={'source': 'aDN8hm4pfPE'}, page_content=\"in this video I want to tell you about L chain and how it can make your life so much easier when building GPT powered apps L chain is a framework that has a ton of modules and pre-made components that make building language model powered apps incredibly easy and fast the developer speed with L chain is through the roof to build a GPT powered app is not enough to just use the open AI python package if you want to build anything remotely useful you will have to add memory to your chat boo you will need to format and validate you will need to parse outputs you will need to talk to Vector stores and more you could build all those on your own or you could use l chain L chain has all the things I mentioned already and much more from Models to prompts output parsers Vector stores embedding models agents toolkits monitoring debugging parallelization and more all for free and ready to use in JavaScript or python L chain also allows you to be model agnostic which means that if you use open eyes gpt3 and later want to change to Asher gpt3 or anthropics clot or to a model hosted in hogging phas or hosted in your machine if you use l chain that change will take you less than five lines of code without L chain you will have to rewrite your entire implementation to use a different API with L chain you change just one part of your app and the chat memory the vector stores the prompts and output parsers stay the same L chain is like a compatibility layer between all the components that an llm powered app needs after the chaos that happened in open AI now more than ever if you build llm powered apps you need to be able to easily switch between different providers without having to rewrite your entire code base this video is not sponsored by Lang chain it is sponsored by me more on that later so let me show you how Lang chain works by building a tiny translator bot it all starts with The Prompt here we are importing the chat prompt template class from lanching this class allows us to create a prompt that is made out of messages first we have a system message which sets defaults to the Ai and how it should behave we are telling the AI that it is a translator bot and that it translates sentences from one language to another as you can see we wrote Source language and target language that is because we want to make this prompt customizable by providing those variables later then we create a message sent by a human that says translate this followed by another variable that we are going to provide later here we are not worrying about the AI model we're going to use l chain will format this prompt into whatever shape the model needs later now we import the model and initialize it with a low temperature which as we know makes the responses less random and finally we create a chain which is a sequence of actions this might look weird to you at first but all you have to know is that the pipe operator is magical in Lang what it does is to chain each component to the next one and it will run them sequentially first it will format The Prompt and then it will give the prompt to the llm this syntax is called the Lin expression language or LC L and it is awesome because it allows you to construct really complex chains that all have multiple steps and it also allows you to chain change with other chains and run them in parallel is so cool for example if we also had an output parer our chain would look like this and L chain will first format The Prompt then give it to the chat model and then take the output of that and run it through the output parter LC is super powerful back to our code we are now going to run the Chain by using the invoke method if we do this we are going to have an error that is because L chain also validates our inputs if we go back and look at our prompt we can see that our prompt requires three variables Source language target language and sentence thankfully before we spend money calling the AI with an incomplete prompt L chain is validating that the template has all the inputs it needs to fix this all we have to do is provide the variables the template needs when we invoke the chain and we are done and if we print the response we will see the response from the llm formatted in a nice AI message class that we can later put put into our chatbot memory or save on a database if you want to change model and go from gpt3 to gp4 all you have to do is this or if tomorrow another fight breaks out at open Ai and everyone quits and the company implodes you can quickly get yourself an API key from anthropic to replace gpt3 for clock and as you can see just by changing two lines of code you moved from one model to another without touching anything else as of today Lin supports more than 76 llms and 25 chat models that you can swap with each other seamlessly the same goes for memory modules Vector stores text Splitters and more I hope that by now you can see how awesome L chain is which is why I am sponsoring this video I just finished recording a 15-hour l chain course called Full stack GPT we across 123 videos we will build seven GPT powered apps including a custom chat GPT plugin using lanching streamlit fast API GPT 4 whisper Mistral huging face and more we will build document GPT private GPT quiz GPT site GPT meeting GPT investor GPT and Chef GPT we will build a custom GPT that users will be able to install from the GPT store and I also added two bonus sections one that uses the newly released assistance API from open aai that allows us to build autonomous agents with function calling memory and document retrieval and after what happened at openai I made another section on how to migrate from openai to ashure openai or AWS Bedrock if you are interested and I hope are please click the link below to get your hands on full stack GPT more than 15 hours and 123 videos building GPT powered app is so much fun I really hope you can join click the link below and I will see you there on Kam see you on the next one byebye m\")],\n",
       "  'summary': \"이 영상에서는 L 체인(LangChain)이라는 프레임워크에 대해 설명하며, GPT 기반 애플리케이션을 구축할 때 어떻게 삶을 더 쉽게 만들어 줄 수 있는지를 소개합니다. L 체인은 다양한 모듈과 미리 만들어진 구성 요소를 제공하여 언어 모델 기반 앱을 빠르고 쉽게 구축할 수 있게 해줍니다. \\n\\n단순히 OpenAI 파이썬 패키지를 사용하는 것만으로는 충분하지 않으며, 메모리 추가, 출력 파싱, 벡터 저장소와의 상호작용 등 여러 요소를 추가해야 합니다. L 체인은 이러한 모든 기능을 포함하고 있으며, 모델에 구애받지 않고 사용할 수 있어 다양한 모델 간 전환이 용이합니다. L 체인을 사용하면 5줄 이하의 코드 변경으로 모델을 변경할 수 있으며, API를 변경할 필요 없이 앱의 특정 부분만 수정하면 됩니다.\\n\\n영상에서는 간단한 번역 봇을 구축하는 과정도 보여주며, L 체인을 활용해 프롬프트 작성, 모델 초기화, 체인 생성의 단계별 진행 과정도 설명합니다. L 체인은 입력 검증 기능이 있어 불완전한 프롬프트로 AI를 호출하는 일을 방지합니다.\\n\\n마지막으로, L 체인으로 15시간 분량의 강좌인 '풀스택 GPT(Full Stack GPT)'를 만들었다는 소개도 있습니다. 이 과정에서는 다양한 GPT 기반 앱을 구축하는 방법을 배우고, OpenAI와 다른 API로의 이전 방법도 포함되어 있습니다. 관심이 있는 사람은 링크를 통해 강좌에 참여할 수 있습니다.\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 비디오에 대해 요약 생성\n",
    "from tqdm import tqdm # 진행 상황을 보여주는 라이브러리\n",
    "\n",
    "for v in tqdm(videos):\n",
    "    v['summary'] = chain.invoke({\"context\": v['content']})\n",
    "\n",
    "videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
