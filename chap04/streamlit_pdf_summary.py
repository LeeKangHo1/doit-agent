import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv
import pymupdf

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=api_key)

# PDF â†’ í…ìŠ¤íŠ¸ ë³€í™˜
def pdf_to_text(pdf_file_path):
    doc = pymupdf.open(pdf_file_path)
    header_height = 80
    footer_height = 80
    full_text = ''

    for page in doc:
        rect = page.rect
        text = page.get_text(clip=(0, header_height, rect.width, rect.height - footer_height))
        full_text += text + '\n------------------------------------\n'

    return full_text

# ìš”ì•½ ìƒì„±
def summarize_txt(txt: str):
    system_prompt = f'''
    ë„ˆëŠ” ë‹¤ìŒ ê¸€ì„ ìš”ì•½í•˜ëŠ” ë´‡ì´ë‹¤. ì•„ë˜ ê¸€ì„ ì½ê³ , ì €ìì˜ ë¬¸ì œ ì¸ì‹ê³¼ ì£¼ì¥ì„ íŒŒì•…í•˜ê³ , ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ë¼. 

    ì‘ì„±í•´ì•¼ í•˜ëŠ” í¬ë§·ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 
    
    # ì œëª©

    ## ì €ìì˜ ë¬¸ì œ ì¸ì‹ ë° ì£¼ì¥ (15ë¬¸ì¥ ì´ë‚´)
    
    ## ì €ì ì†Œê°œ

    
    =============== ì´í•˜ í…ìŠ¤íŠ¸ ===============

    {txt}
    '''

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.1,
        messages=[
            {"role": "system", "content": system_prompt}
        ]
    )

    return response.choices[0].message.content

# âœ… Streamlit ì•±
st.set_page_config(page_title="PDF ìš”ì•½ê¸°", layout="wide")
st.title("ğŸ“„ PDF ë¬¸ì„œ ìš”ì•½ê¸° (OpenAI + Streamlit)")

uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

if uploaded_file is not None:
    # ì €ì¥í•  ì„ì‹œ ê²½ë¡œ
    temp_path = os.path.join("temp", uploaded_file.name)
    os.makedirs("temp", exist_ok=True)

    with open(temp_path, "wb") as f:
        f.write(uploaded_file.read())

    with st.spinner("ğŸ“– ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
        extracted_text = pdf_to_text(temp_path)
        summary = summarize_txt(extracted_text)

    st.success("âœ… ìš”ì•½ ì™„ë£Œ!")
    st.subheader("ğŸ“Œ ìš”ì•½ ê²°ê³¼:")
    st.text_area("ìš”ì•½ ë‚´ìš©", summary, height=500)

    os.remove(temp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
