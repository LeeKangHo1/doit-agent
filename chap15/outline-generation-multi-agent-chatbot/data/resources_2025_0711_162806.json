[
    {
        "url": "https://ko.wikipedia.org/wiki/EXAONE",
        "title": "EXAONE - 위키백과, 우리 모두의 백과사전",
        "content": "위키백과, 우리 모두의 백과사전.\n\nEXAONE(엑사원)은 LG AI 연구원에서 개발한 초거대 멀티모달 AI 모델이다.( \"Exascale AI for Everyone\"의 약자로, 누구나 활용할 수 있는 엑사급 인공지능이라는 비전을 담고 있다.( 텍스트와 이미지를 동시에 이해하고 생성하며, 전문 문헌까지 이해할 수 있는 생성형 인공지능을 목표로 개발되었다.( EXAONE 프로젝트는 2021년부터 시작되었으며, 2021년 12월에 LG AI 연구원 출범 1년 만에 공개되었다.( 개발 초기부터 언어와 시각 정보, 즉 멀티모달 정보의 이해를 통한 혁신을 추구해왔다.( 한국어와 영어를 모두 이해하고 처리할 수 있도록 설계되어 국내외 다양한 환경에서 활용될 수 있다.( [...] EXAONE Deep은 EXAONE 3.5를 기반으로 추론 능력에 특화하여 미세 조정된 모델이다.( 수학, 과학, 코딩 등 다양한 영역에서 높은 추론 성능을 보인다.( EXAONE Deep 32B 모델은 2025학년도 수능 수학 영역에서 높은 점수를 기록했으며, 국제 AI 수학 문제 해결 평가에서도 우수한 성적을 거두었다.(\n\nLG 계열사를 중심으로 LG전자, LG이노텍, LG디스플레이 등에서 기업용 인공지능 모델로 적용되고 있다.( 신소재 개발이나 공정 최적화에 활용될 수 있다. 또한, LG AI 연구원은 EXAONE을 기반으로 생성형 AI 서비스인 ChatEXAONE을 개발하여 임직원들의 업무 생산성 향상에 활용하고 있다.( ChatEXAONE은 실시간 웹 정보 기반 질의응답, 문서 및 이미지 기반 질의응답, 코딩, 데이터베이스 관리 등 다양한 기능을 제공한다.(\n\n각주\n--\n\n[편집] [...] 2023년 7월에는 EXAONE 2.0이 공개되었으며, 학습 데이터 품질 강화, 비용 효율성 강화, 맞춤형 모델 제공에 집중하여 기존 생성형 AI와의 차별화를 꾀했다.( EXAONE 2.0은 이전 모델 대비 추론 처리 시간을 단축하고 메모리 사용량을 감소시켜 비용 효율성을 개선했다.(\n\n2024년 8월에는 EXAONE 3.0이 오픈소스로 공개되었다.( EXAONE 3.0은 이전 모델인 EXAONE 2.0 대비 성능과 경제성 모두 향상되었으며, 추론 처리 시간과 구동 비용을 크게 절감했다.( 7.8B(78억) 매개변수와 8T(8조) 토큰으로 학습된 대규모 모델이다.( 한국어와 영어를 지원하며, 6천만 건 이상의 전문 데이터를 학습했다.(\n\n2024년 12월에는 EXAONE 3.5가 오픈소스로 공개되었다.( EXAONE 3.5는 32B, 7.8B, 2.4B의 세 가지 크기로 제공되며, 긴 맥락 이해 능력과 명령어 수행 능력을 통해 다양한 언어 작업에서 사용될 수 있다.(",
        "score": 0.8443195,
        "raw_content": "EXAONE - 위키백과, 우리 모두의 백과사전\n\n===============\n[본문으로 이동](https://ko.wikipedia.org/wiki/EXAONE#bodyContent)\n\n- [x] 주 메뉴 \n\n주 메뉴\n\n사이드바로 이동 숨기기\n\n 둘러보기 \n\n*   [대문](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EB%8C%80%EB%AC%B8 \"대문으로 가기 [alt-shift-z]\")\n*   [최근 바뀜](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EC%B5%9C%EA%B7%BC%EB%B0%94%EB%80%9C \"위키의 최근 바뀐 목록 [alt-shift-r]\")\n*   [요즘 화제](https://ko.wikipedia.org/wiki/%ED%8F%AC%ED%84%B8:%EC%9A%94%EC%A6%98_%ED%99%94%EC%A0%9C \"최근의 소식 알아 보기\")\n*   [임의의 문서로](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EC%9E%84%EC%9D%98%EB%AC%B8%EC%84%9C \"무작위로 선택된 문서 불러오기 [alt-shift-x]\")\n\n 사용자 모임 \n\n*   [사랑방](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%82%AC%EB%9E%91%EB%B0%A9)\n*   [사용자 모임](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%82%AC%EC%9A%A9%EC%9E%90_%EB%AA%A8%EC%9E%84 \"위키백과 참여자를 위한 토론/대화 공간입니다.\")\n*   [관리 요청](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%9A%94%EC%B2%AD)\n\n 편집 안내 \n\n*   [소개](https://ko.wikipedia.org/wiki/%EB%8F%84%EC%9B%80%EB%A7%90:%EC%86%8C%EA%B0%9C)\n*   [도움말](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EB%8F%84%EC%9B%80%EB%A7%90 \"도움말\")\n*   [정책과 지침](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8)\n*   [질문방](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A7%88%EB%AC%B8%EB%B0%A9)\n\n[![Image 1](https://ko.wikipedia.org/static/images/icons/wikipedia.png)![Image 2: 위키백과](https://ko.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-ko.svg)![Image 3](https://ko.wikipedia.org/static/images/mobile/copyright/wikipedia-tagline-ko.svg)](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EB%8C%80%EB%AC%B8)\n\n[검색](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EA%B2%80%EC%83%89 \"위키백과 검색 [alt-shift-f]\")\n\n검색\n\n- [x] 보이기 \n\n보이기\n\n사이드바로 이동 숨기기\n\n글\n\n*   작음  표준  큼   \n\n이 페이지는 항상 작은 글꼴 크기를 사용합니다.\n\n너비\n\n*   표준  넓게   \n\n콘텐츠는 브라우저 창에 맞도록 최대한 넓게 맞춥니다.\n\n색 (베타)\n\n*   자동  라이트  다크   \n\n이 페이지는 항상 라이트 모드입니다.\n\n*   [기부](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=ko.wikipedia.org&uselang=ko)\n*   [계정 만들기](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EA%B3%84%EC%A0%95%EB%A7%8C%EB%93%A4%EA%B8%B0&returnto=EXAONE \"계정을 만들고 로그인하는 것이 좋습니다. 하지만 필수는 아닙니다\")\n*   [로그인](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EB%A1%9C%EA%B7%B8%EC%9D%B8&returnto=EXAONE \"위키백과에 로그인하면 여러가지 편리한 기능을 사용할 수 있습니다. [alt-shift-o]\")\n\n- [x] 개인 도구 \n\n*   [기부](https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=ko.wikipedia.org&uselang=ko)\n*   [계정 만들기](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EA%B3%84%EC%A0%95%EB%A7%8C%EB%93%A4%EA%B8%B0&returnto=EXAONE \"계정을 만들고 로그인하는 것이 좋습니다. 하지만 필수는 아닙니다\")\n*   [로그인](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EB%A1%9C%EA%B7%B8%EC%9D%B8&returnto=EXAONE \"위키백과에 로그인하면 여러가지 편리한 기능을 사용할 수 있습니다. [alt-shift-o]\")\n\n![Image 4: 숨기기](blob:http://localhost/24a5df97f8822495020cf6567aa66835)\n\n*   ![Image 5](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Document_text_edit.svg/20px-Document_text_edit.svg.png) 6월 27일부터 7월 15일까지 [광주광역시 에디터톤](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EA%B4%91%EC%A3%BC%EA%B4%91%EC%97%AD%EC%8B%9C_%EC%97%90%EB%94%94%ED%84%B0%ED%86%A4 \"위키백과:광주광역시 에디터톤\")이 진행됩니다.\n*   ![Image 6](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Group_half.svg/20px-Group_half.svg.png) 7월 26일에 [오프라인 모임](https://ko.wikipedia.org/wiki/%ED%96%89%EC%82%AC:2025%EB%85%84_7%EC%9B%94_26%EC%9D%BC_%EC%98%A4%ED%94%84%EB%9D%BC%EC%9D%B8_%EB%AA%A8%EC%9E%84 \"행사:2025년 7월 26일 오프라인 모임\")이 서울에서 열립니다.\n\n- [x] 목차 토글 \n\n목차\n--\n\n사이드바로 이동 숨기기\n\n*   [처음 위치](https://ko.wikipedia.org/wiki/EXAONE#)\n*   [1 각주](https://ko.wikipedia.org/wiki/EXAONE#%EA%B0%81%EC%A3%BC)\n\n*   [2 외부 링크](https://ko.wikipedia.org/wiki/EXAONE#%EC%99%B8%EB%B6%80_%EB%A7%81%ED%81%AC)\n\nEXAONE\n======\n\n- [x] 언어 추가 \n\n[링크 추가](https://www.wikidata.org/wiki/Special:NewItem?site=kowiki&page=EXAONE \"언어 간 링크 추가\")\n\n*   [문서](https://ko.wikipedia.org/wiki/EXAONE \"본문 보기 [alt-shift-c]\")\n*   [토론](https://ko.wikipedia.org/w/index.php?title=%ED%86%A0%EB%A1%A0:EXAONE&action=edit&redlink=1 \"문서의 내용에 대한 토론 문서 (없는 문서) [alt-shift-t]\")\n\n- [x] 한국어 \n\n*   [읽기](https://ko.wikipedia.org/wiki/EXAONE)\n*   [편집](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=edit \"이 문서의 원본 코드를 편집 [alt-shift-e]\")\n*   [역사 보기](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=history \"이 문서의 과거 편집 내역입니다. [alt-shift-h]\")\n\n- [x] 도구 \n\n도구\n\n사이드바로 이동 숨기기\n\n 동작 \n\n*   [읽기](https://ko.wikipedia.org/wiki/EXAONE)\n*   [편집](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=edit \"이 문서의 원본 코드를 편집 [alt-shift-e]\")\n*   [역사 보기](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=history)\n\n 일반 \n\n*   [여기를 가리키는 문서](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EA%B0%80%EB%A6%AC%ED%82%A4%EB%8A%94%EB%AC%B8%EC%84%9C/EXAONE \"여기를 가리키는 모든 위키 문서의 목록 [alt-shift-j]\")\n*   [가리키는 글의 최근 바뀜](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EB%A7%81%ED%81%AC%EC%B5%9C%EA%B7%BC%EB%B0%94%EB%80%9C/EXAONE \"이 문서에서 링크한 문서의 최근 바뀜 [alt-shift-k]\")\n*   [파일 올리기](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%ED%8C%8C%EC%9D%BC_%EC%98%AC%EB%A6%AC%EA%B8%B0 \"파일 올리기 [alt-shift-u]\")\n*   [고유 링크](https://ko.wikipedia.org/w/index.php?title=EXAONE&oldid=40199505 \"이 문서의 이 판에 대한 고유 링크\")\n*   [문서 정보](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=info \"이 문서에 대한 자세한 정보\")\n*   [이 문서 인용하기](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EC%9D%B4%EB%AC%B8%EC%84%9C%EC%9D%B8%EC%9A%A9&page=EXAONE&id=40199505&wpFormIdentifier=titleform \"이 문서를 인용하는 방법에 대한 정보\")\n*   [축약된 URL 얻기](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:UrlShortener&url=https%3A%2F%2Fko.wikipedia.org%2Fwiki%2FEXAONE)\n*   [QR코드 다운로드](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:QrCode&url=https%3A%2F%2Fko.wikipedia.org%2Fwiki%2FEXAONE)\n*   [언어 간 링크 추가](https://www.wikidata.org/wiki/Special:NewItem?site=kowiki&page=EXAONE \"언어 간 링크 추가\")\n\n 인쇄/내보내기 \n\n*   [책 만들기](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:%EC%B1%85&bookcmd=book_creator&referer=EXAONE)\n*   [PDF로 다운로드](https://ko.wikipedia.org/w/index.php?title=%ED%8A%B9%EC%88%98:DownloadAsPdf&page=EXAONE&action=show-download-screen)\n*   [인쇄용 판](https://ko.wikipedia.org/w/index.php?title=EXAONE&printable=yes \"이 문서의 인쇄용 판 [alt-shift-p]\")\n\n 다른 프로젝트 \n\n위키백과, 우리 모두의 백과사전.\n\n**EXAONE**(엑사원)은 LG AI 연구원에서 개발한 [초거대 멀티모달 AI](https://ko.wikipedia.org/wiki/%EB%8C%80%ED%98%95_%EC%96%B8%EC%96%B4_%EB%AA%A8%EB%8D%B8 \"대형 언어 모델\") 모델이다.[[1]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:0-1)[[2]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:1-2) \"Exascale AI for Everyone\"의 약자로, 누구나 활용할 수 있는 엑사급 [인공지능](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5 \"인공지능\")이라는 비전을 담고 있다.[[1]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:0-1) 텍스트와 이미지를 동시에 이해하고 생성하며, 전문 문헌까지 이해할 수 있는 [생성형 인공지능](https://ko.wikipedia.org/wiki/%EC%83%9D%EC%84%B1%ED%98%95_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5 \"생성형 인공지능\")을 목표로 개발되었다.[[2]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:1-2) EXAONE 프로젝트는 2021년부터 시작되었으며, 2021년 12월에 LG AI 연구원 출범 1년 만에 공개되었다.[[1]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:0-1) 개발 초기부터 언어와 시각 정보, 즉 [멀티모달](https://ko.wikipedia.org/wiki/%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC_%ED%95%99%EC%8A%B5 \"멀티모달 학습\") 정보의 이해를 통한 혁신을 추구해왔다.[[2]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:1-2) 한국어와 영어를 모두 이해하고 처리할 수 있도록 설계되어 국내외 다양한 환경에서 활용될 수 있다.[[1]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:0-1)[[3]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:2-3)\n\n2023년 7월에는 EXAONE 2.0이 공개되었으며, 학습 데이터 품질 강화, 비용 효율성 강화, 맞춤형 모델 제공에 집중하여 기존 생성형 AI와의 차별화를 꾀했다.[[2]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:1-2) EXAONE 2.0은 이전 모델 대비 추론 처리 시간을 단축하고 메모리 사용량을 감소시켜 비용 효율성을 개선했다.[[2]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:1-2)[[4]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:3-4)\n\n2024년 8월에는 EXAONE 3.0이 오픈소스로 공개되었다.[[5]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:4-5)[[6]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:5-6)[[7]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:6-7) EXAONE 3.0은 이전 모델인 EXAONE 2.0 대비 성능과 경제성 모두 향상되었으며, 추론 처리 시간과 구동 비용을 크게 절감했다.[[8]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:7-8)[[9]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:8-9) 7.8B(78억) [매개변수](https://ko.wikipedia.org/wiki/%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98 \"매개변수\")와 8T(8조) 토큰으로 학습된 대규모 모델이다.[[3]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:2-3) 한국어와 영어를 지원하며, 6천만 건 이상의 전문 데이터를 학습했다.[[5]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:4-5)\n\n2024년 12월에는 EXAONE 3.5가 오픈소스로 공개되었다.[[10]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:9-10)[[11]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:10-11) EXAONE 3.5는 32B, 7.8B, 2.4B의 세 가지 크기로 제공되며, 긴 맥락 이해 능력과 명령어 수행 능력을 통해 다양한 언어 작업에서 사용될 수 있다.[[10]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:9-10)\n\nEXAONE Deep은 EXAONE 3.5를 기반으로 추론 능력에 특화하여 미세 조정된 모델이다.[[12]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:11-12) 수학, 과학, 코딩 등 다양한 영역에서 높은 추론 성능을 보인다.[[13]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:12-13)[[14]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:13-14) EXAONE Deep 32B 모델은 2025학년도 수능 수학 영역에서 높은 점수를 기록했으며, 국제 AI 수학 문제 해결 평가에서도 우수한 성적을 거두었다.[[14]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:13-14)\n\n[LG](https://ko.wikipedia.org/wiki/LG \"LG\") 계열사를 중심으로 [LG전자](https://ko.wikipedia.org/wiki/LG%EC%A0%84%EC%9E%90 \"LG전자\"), [LG이노텍](https://ko.wikipedia.org/wiki/LG%EC%9D%B4%EB%85%B8%ED%85%8D \"LG이노텍\"), [LG디스플레이](https://ko.wikipedia.org/wiki/LG%EB%94%94%EC%8A%A4%ED%94%8C%EB%A0%88%EC%9D%B4 \"LG디스플레이\") 등에서 기업용 인공지능 모델로 적용되고 있다.[[15]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:14-15)[LG화학](https://ko.wikipedia.org/wiki/LG%ED%99%94%ED%95%99 \"LG화학\")에서는 신소재 개발이나 공정 최적화에 활용될 수 있다. 또한, LG AI 연구원은 EXAONE을 기반으로 [생성형 AI 서비스](https://ko.wikipedia.org/wiki/%EC%B1%97%EB%B4%87 \"챗봇\")인 **ChatEXAONE**을 개발하여 임직원들의 업무 생산성 향상에 활용하고 있다.[[15]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:14-15)[[8]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:7-8)[[11]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:10-11) ChatEXAONE은 실시간 웹 정보 기반 질의응답, 문서 및 이미지 기반 질의응답, 코딩, 데이터베이스 관리 등 다양한 기능을 제공한다.[[8]](https://ko.wikipedia.org/wiki/EXAONE#cite_note-:7-8)\n\n각주\n--\n\n[[편집](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=edit&section=1 \"부분 편집: 각주\")]\n\n1.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:0_1-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:0_1-1)[다](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:0_1-2)[라](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:0_1-3)[“Exaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP”](https://www.msap.ai/blog/exaone-lg-llm/). msap.ai. 2025년 5월 9일에 확인함.\n2.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:1_2-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:1_2-1)[다](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:1_2-2)[라](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:1_2-3)[마](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:1_2-4)[“LG의 초거대 AI ‘EXAONE 2.0’이 최초 공개된 LG AI Talk Concert 2023 현장 속으로 - LG AI Research News”](https://www.lgresearch.ai/news/view?seq=330&page=1&pageSize=12)). lgresearch.ai. 2025년 5월 9일에 확인함.\n3.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:2_3-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:2_3-1)[“LG 엑사원 3.0:AI로 실생활 혁신을 이루”](https://brunch.co.kr/@donghyungshin/183). brunch.co.kr. 2025년 5월 9일에 확인함.\n4.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:3_4-0 \"이동\")[“7월 - EXAONE 2.0 최초 공개 & 상반기 결산 FLEX Meet-up!”](https://careers.lgresearch.ai/fd2602c3-00fb-48a5-937b-605ec7854231). lgresearch.ai. 2025년 5월 9일에 확인함.\n5.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:4_5-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:4_5-1)[“[오픈 소스 AI] [로컬 환경] LG 에서 개발한 오픈소스 LLM, EXAONE 3.0을 소개합니다.”](https://marcus-story.tistory.com/58). tistory.com. 2025년 5월 9일에 확인함.\n6.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:5_6-0 \"이동\")[“LG AI연구소, 7.8B 크기의 EXAONE 3.0 모델 및 기업용 AI Agent ChatEXAONE 공개 - 읽을거리&정보공유 - 파이토치 한국 사용자 모임”](https://discuss.pytorch.kr/t/lg-ai-7-8b-exaone-3-0-ai-agent-chatexaone/4995). pytorch.kr. 2025년 5월 9일에 확인함.\n7.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:6_7-0 \"이동\")[“EXAONE 3.0: 글로벌 Top 수준의 성능 갖춘 오픈소스 모델 공개 - LG AI Research BLOG”](https://www.lgresearch.ai/blog/view?seq=459). lgresearch.ai. 2025년 5월 9일에 확인함.\n8.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:7_8-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:7_8-1)[다](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:7_8-2)[“보도자료”](https://www.lg.co.kr/media/release/27972). lg.co.kr. 2025년 5월 9일에 확인함.\n9.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:8_9-0 \"이동\")[“LG, 국내 최초 오픈소스 AI ‘엑사원(EXAONE) 3.0’ 공개”](https://www.thevaluenews.co.kr/news/184769). thevaluenews.co.kr. 2025년 5월 9일에 확인함.\n10.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:9_10-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:9_10-1)[“🤖EXAONE-3.5: 한국어와 영어를 지원하는 LG의 최신 대규모 언어 모델”](https://fornewchallenge.tistory.com/entry/%F0%9F%A4%96EXAONE-35-%ED%95%9C%EA%B5%AD%EC%96%B4%EC%99%80-%EC%98%81%EC%96%B4%EB%A5%BC-%EC%A7%80%EC%9B%90%ED%95%98%EB%8A%94-LG%EC%9D%98-%EC%B5%9C%EC%8B%A0-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8). tistory.com. 2025년 5월 9일에 확인함.\n11.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:10_11-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:10_11-1)[“LG, 생성형 AI 새 버전 ‘엑사원 3.5’ 공개... 챗엑사원 정식 서비스”](https://www.boannews.com/media/view.asp?idx=135015&page=9&kind=3). 보안뉴스. 2025년 5월 9일에 확인함.\n12.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:11_12-0 \"이동\")[“🤖🔍📊EXAONE Deep: LG AI의 오픈소스 추론 능력 강화 모델”](https://fornewchallenge.tistory.com/entry/%F0%9F%A4%96%F0%9F%94%8D%F0%9F%93%8AEXAONE-Deep-LG-AI%EC%9D%98-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%EC%B6%94%EB%A1%A0-%EB%8A%A5%EB%A0%A5-%EA%B0%95%ED%99%94-%EB%AA%A8%EB%8D%B8). tistory.com. 2025년 5월 9일에 확인함.\n13.   [↑](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:12_13-0 \"이동\")[“EXAONE Deep 공개 ━ Reasoning AI의 새로운 기준을 세우다 - LG AI Research BLOG”](https://www.lgresearch.ai/blog/view?seq=541). lgresearch.ai. 2025년 5월 9일에 확인함.\n14.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:13_14-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:13_14-1)[“LG의 혁신, EXAONE Deep 으로 여는 AI 새 시대 — IT Totality: 개발, 웹, 인프라까지”](https://dmomo.co.kr/216). dmomo.co.kr. 2025년 5월 9일에 확인함.\n15.   ↑ [이동: 가](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:14_15-0)[나](https://ko.wikipedia.org/wiki/EXAONE#cite_ref-:14_15-1)[“LG AI연구원 우수사례”](https://cloud.google.com/customers/intl/ko-kr/lgai?hl=ko). Google Cloud. 2025년 5월 9일에 확인함.\n\n외부 링크\n-----\n\n[[편집](https://ko.wikipedia.org/w/index.php?title=EXAONE&action=edit&section=2 \"부분 편집: 외부 링크\")]\n\n*   [홈페이지](https://huggingface.co/LGAI-EXAONE)\n\n원본 주소 \"[https://ko.wikipedia.org/w/index.php?title=EXAONE&oldid=40199505](https://ko.wikipedia.org/w/index.php?title=EXAONE&oldid=40199505)\"\n\n[분류](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%88%98:%EB%B6%84%EB%A5%98 \"특수:분류\"): \n*   [대형 언어 모델](https://ko.wikipedia.org/wiki/%EB%B6%84%EB%A5%98:%EB%8C%80%ED%98%95_%EC%96%B8%EC%96%B4_%EB%AA%A8%EB%8D%B8 \"분류:대형 언어 모델\")\n*   [AI 슈퍼컴퓨터](https://ko.wikipedia.org/wiki/%EB%B6%84%EB%A5%98:AI_%EC%8A%88%ED%8D%BC%EC%BB%B4%ED%93%A8%ED%84%B0 \"분류:AI 슈퍼컴퓨터\")\n\n*    이 문서는 2025년 7월 2일 (수) 18:04에 마지막으로 편집되었습니다.\n*   모든 문서는 [크리에이티브 커먼즈 저작자표시-동일조건변경허락 4.0](https://creativecommons.org/licenses/by-sa/4.0/deed.ko)에 따라 사용할 수 있으며, 추가적인 조건이 적용될 수 있습니다. 자세한 내용은 [이용 약관](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use/ko)을 참고하십시오.\n\nWikipedia®는 미국 및 다른 국가에 등록되어 있는 [Wikimedia Foundation, Inc.](https://www.wikimediafoundation.org/) 소유의 등록 상표입니다.\n\n*   [개인정보처리방침](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy)\n*   [위키백과 소개](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%86%8C%EA%B0%9C)\n*   [면책 조항](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EB%A9%B4%EC%B1%85_%EC%A1%B0%ED%95%AD)\n*   [행동 강령](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct)\n*   [개발자](https://developer.wikimedia.org/)\n*   [통계](https://stats.wikimedia.org/#/ko.wikipedia.org)\n*   [쿠키 정책](https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement)\n*   [모바일 보기](https://ko.m.wikipedia.org/w/index.php?title=EXAONE&mobileaction=toggle_view_mobile)\n*   [미리보기 설정 수정](https://ko.wikipedia.org/wiki/EXAONE#)\n\n*   [![Image 8: Wikimedia Foundation](https://ko.wikipedia.org/static/images/footer/wikimedia.svg)](https://www.wikimedia.org/)\n*   [![Image 9: Powered by MediaWiki](https://ko.wikipedia.org/w/resources/assets/mediawiki_compact.svg)](https://www.mediawiki.org/)\n\n검색\n\n검색\n\n- [x] 목차 토글 \n\nEXAONE\n\n[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)[](https://ko.wikipedia.org/wiki/EXAONE#)\n\n언어 추가[새 주제](https://ko.wikipedia.org/wiki/EXAONE#)\n\n![Image 10](https://upload.wikimedia.org/wikipedia/commons/2/2e/Up_%2889591%29_-_The_Noun_Project.svg)[](https://ko.wikipedia.org/wiki/EXAONE?action=edit)\n"
    },
    {
        "url": "https://zdnet.co.kr/view/?no=20250322134718",
        "title": "LG의 새 AI '엑사원 딥', 수능서 94.5% 정답률...수학·코딩 능력 탁월",
        "content": "무료로 사용 가능한 EXAONE Deep, 상업용은 별도 라이선스 필요\n\nEXAONE Deep 모델은 연구 목적으로 모든 사람이 사용할 수 있도록 공개되어 있다. 이 모델들은 허깅페이스(Hugging Face)를 통해 다운로드할 수 있다. 그러나 이 모델은 추론 작업에 특화되어 있으므로, 넓은 범위의 실제 사용 사례에 적용하려면 EXAONE 3.5 Instruct 모델 사용을 권장한다. 또한, EXAONE AI 모델 라이선스 계약에 따르면, 이 모델은 상업적 용도로 사용할 수 없으며, 별도의 상업용 라이선스 계약이 필요하다.\n\nFAQ\n\nQ: EXAONE Deep 모델은 어떤 특징이 있나요?\n\nA: EXAONE Deep은 추론 능력에 특화된 AI 모델로, 단계적 사고 과정을 포함하는 특별한 데이터셋으로 학습되었습니다. 수학, 코딩 등 논리적 추론이 필요한 과제에서 뛰어난 성능을 보이며, 2.4B, 7.8B, 32B 세 가지 크기로 제공됩니다. [...] EXAONE Deep 모델은 단계적 사고 과정을 포함하는 특화된 데이터셋으로 학습되었다. 연구팀은 지도 학습(Supervised Fine-Tuning, SFT), 직접 선호도 최적화(Direct Preference Optimization, DPO), 온라인 강화학습(Online Reinforcement Learning, Online RL)과 같은 세 가지 주요 기법을 활용해 모델을 훈련시켰다. [...] Q: 이 모델은 어떻게 사용할 수 있나요?\n\nA: EXAONE Deep 모델은 연구 목적으로 누구나 무료로 사용할 수 있으며, 허깅페이스를 통해 다운로드할 수 있습니다. 상업적 목적으로 사용하려면 별도의 라이선스가 필요합니다.\n\nQ: EXAONE Deep과 다른 AI 모델과의 차이점은 무엇인가요?\n\nA: EXAONE Deep은 추론에 특화된 모델로, 같은 크기의 다른 모델들보다 수학, 과학, 코딩 분야에서 우수한 성능을 보입니다. 특히 7.8B 모델은 상용 추론 모델인 OpenAI o1-mini보다도 더 나은 성능을 입증했습니다.\n\n■ 이 기사는 AI 전문 매체 ‘AI 매터스’와 제휴를 통해 제공됩니다. 기사는 클로드 3.5 소네트와 챗GPT를 활용해 작성되었습니다. (☞ 기사 원문 바로가기)\n\n### 관련기사\n\n## \"챗GPT, 노벨상 연구는 불가\"… 생성형 AI의 과학적 한계, 뭐길래?\n\n2025.03.22\n\n## [Q&AI] '고공행진' 한화에어로, 주가 15% 폭락…왜?",
        "score": 0.798643,
        "raw_content": "# [ZDNet Korea](/)\n\n![ZDNet Korea](/img_mobile/logo.png?ver=20210901)\n\n컴퓨팅\n\n## LG의 새 AI ‘엑사원 딥’, 수능서 94.5% 정답률...수학·코딩 능력 탁월\n\nAI 에디터\n\n입력 :2025/03/22 13:47\n\n![](/img_mobile/left_arrow.png)\n![](/img_mobile/right_arrow.png)\n![](/images/f_on.png)\n![](/images/x_on.png)\n![](/images/k_on.png)\n![](/img_mobile/txt_bt1.gif)\n![](/img_mobile/txt_bt2.gif)\n![](https://image.zdnet.co.kr/2025/03/21/aic9b6deee93716d1058502b69c8c25eb6.jpg)\n\n\n**동급 최강 성능의 EXAONE Deep, 작은 모델도 오픈AI 추월**\n\nLG AI 연구소가 개발한 EXAONE Deep 시리즈가 수학과 코딩 등 다양한 추론 과제에서 뛰어난 성능을 보여주고 있다. EXAONE Deep 시리즈는 2.4B, 7.8B, 32B 세 가지 크기로 출시되었으며, 이 모델들은 기존 EXAONE 3.5 시리즈를 기반으로 추론 능력을 강화하기 위해 특별히 최적화된 버전이다.\n\nEXAONE Deep 모델은 단계적 사고 과정을 포함하는 특화된 데이터셋으로 학습되었다. 연구팀은 지도 학습(Supervised Fine-Tuning, SFT), 직접 선호도 최적화(Direct Preference Optimization, DPO), 온라인 강화학습(Online Reinforcement Learning, Online RL)과 같은 세 가지 주요 기법을 활용해 모델을 훈련시켰다.\n\n성능 평가 결과에 따르면, 가장 작은 모델인 EXAONE Deep 2.4B는 DeepSeek-R1-Distill-Qwen-1.5B보다 우수한 성능을 보여주었다. 중간 크기인 7.8B 모델은 DeepSeek-R1-Distill-Qwen-7B와 DeepSeek-R1-Distill-Llama-8B 같은 오픈 웨이트 모델뿐만 아니라 상용 추론 모델인 OpenAI o1-mini보다도 뛰어난 성능을 입증했다. 가장 큰 모델인 32B는 QwQ-32B와 DeepSeek-R1 같은 최첨단 오픈 웨이트 추론 모델과 견줄 만한 성능을 보여주었으며, DeepSeek-R1-Distill-Qwen-32B와 DeepSeek-R1-Distill-Llama-70B를 능가했다.\n\n![](https://image.zdnet.co.kr/2025/03/21/ai5014b6b4db3008aaec59f3a1581258d1.jpg)\n\n\n**단계별 논리적 사고로 무장한 EXAONE Deep, 120억 토큰 데이터로 학습**\n\nEXAONE Deep 모델의 추론 능력을 강화하기 위해 연구팀은 약 160만 건의 SFT 데이터, 2만 건의 선호도 데이터(DPO용), 그리고 1만 건의 온라인 RL 데이터를 활용했다. SFT 데이터셋은 약 120억 개의 토큰을 포함하며, 확장된 사고 연쇄(chain-of-thought) 과정을 통해 모델이 추론을 수행하도록 설계되었다.\n\n특히 눈에 띄는 점은 이 데이터셋의 구조이다. 각 학습 인스턴스는 구조화된 사고 과정과 최종 답변으로 구성되어 있다. EXAONE 3.5 모델은 &lt;thought> 태그 내에서 논리적 진행, 자기 반성, 자체 검사, 수정 등의 단계별 추론을 수행하도록 훈련되었다. 이렇게 추론 후 생성된 최종 답변은 자기 완결적이며, 사고 과정에서 도출된 핵심 통찰력을 명확하고 간결하게 요약한다.\n\n훈련 계산 리소스 면에서, EXAONE Deep 모델은 Google Cloud Platform과 NVIDIA NeMo FRAMEwork에서 제공하는 NVIDIA H100 GPU 클러스터를 사용하여 훈련되었다. 기본 모델의 사전 훈련과 추론 능력 향상을 위한 미세 조정에 사용된 계산량은 정밀하게 측정되어, 32B 모델의 경우 총 1.26 × 10^24 FLOP가 사용되었다.\n\n**수학 시험에서 빛난 EXAONE Deep, 한국 수능 수학 94.5% 정답률 달성**\n\nEXAONE Deep 모델은 MATH-500, 미국 수학 초청 시험(AIME) 2024/2025, 한국 대학수학능력시험(CSAT) 2025의 수학 영역, GPQA Diamond, LiveCodeBench, MMLU, MMLU-Pro 등 다양한 벤치마크에서 평가되었다.\n\n수학 분야에서 EXAONE Deep 32B 모델은 MATH-500에서 95.7%, AIME 2024에서 72.1%, AIME 2025에서 65.8%, CSAT 2025에서 94.5%의 놀라운 정확도를 보여주었다. 특히 한국 수능 수학 영역의 세 가지 선택 과목인 미적분, 통계, 기하에서 각각 95.1%, 95.0%, 93.5%의 높은 성능을 보여 전체 평균 94.5%라는 인상적인 결과를 달성했다.\n\n과학 및 코딩 분야에서도 EXAONE Deep 32B는 GPQA Diamond에서 66.1%, LiveCodeBench에서 59.5%의 성능을 보여주었다. 일반 지식을 평가하는 MMLU와 MMLU-Pro에서는 각각 83.0%와 74.0%의 정확도를 달성했다.\n\n7.8B 모델 역시 동급의 모델들과 비교해 모든 분야에서 우수한 성능을 보여주었으며, 특히 수학 분야에서는 MATH-500 94.8%, AIME 2024 70.0%, CSAT 2025 89.9%의 높은 정확도를 기록했다.\n\n**무료로 사용 가능한 EXAONE Deep, 상업용은 별도 라이선스 필요**\n\nEXAONE Deep 모델은 연구 목적으로 모든 사람이 사용할 수 있도록 공개되어 있다. 이 모델들은 허깅페이스(Hugging Face)를 통해 다운로드할 수 있다. 그러나 이 모델은 추론 작업에 특화되어 있으므로, 넓은 범위의 실제 사용 사례에 적용하려면 EXAONE 3.5 Instruct 모델 사용을 권장한다. 또한, EXAONE AI 모델 라이선스 계약에 따르면, 이 모델은 상업적 용도로 사용할 수 없으며, 별도의 상업용 라이선스 계약이 필요하다.\n\n**FAQ**\n\n**Q: EXAONE Deep 모델은 어떤 특징이 있나요?**\n\nA: EXAONE Deep은 추론 능력에 특화된 AI 모델로, 단계적 사고 과정을 포함하는 특별한 데이터셋으로 학습되었습니다. 수학, 코딩 등 논리적 추론이 필요한 과제에서 뛰어난 성능을 보이며, 2.4B, 7.8B, 32B 세 가지 크기로 제공됩니다.\n\n**Q: 이 모델은 어떻게 사용할 수 있나요?**\n\nA: EXAONE Deep 모델은 연구 목적으로 누구나 무료로 사용할 수 있으며, 허깅페이스를 통해 다운로드할 수 있습니다. 상업적 목적으로 사용하려면 별도의 라이선스가 필요합니다.\n\n**Q: EXAONE Deep과 다른 AI 모델과의 차이점은 무엇인가요?**\n\nA: EXAONE Deep은 추론에 특화된 모델로, 같은 크기의 다른 모델들보다 수학, 과학, 코딩 분야에서 우수한 성능을 보입니다. 특히 7.8B 모델은 상용 추론 모델인 OpenAI o1-mini보다도 더 나은 성능을 입증했습니다.\n\n■ 이 기사는 AI 전문 매체 ‘[AI 매터스](https://aimatters.co.kr/)’와 제휴를 통해 제공됩니다. 기사는 클로드 3.5 소네트와 챗GPT를 활용해 작성되었습니다. (☞ [기사 원문 바로가기](https://aimatters.co.kr/?p=17497))\n\n![](/Include2/user/pic/reporter/media1@zdnet.co.kr.jpg)\n\n### 관련기사\n\n![](https://image.zdnet.co.kr/2025/03/21/ai9d51e21f15d0e0a6f990334a5ad9fd77.jpg)\n\n## \"챗GPT, 노벨상 연구는 불가\"… 생성형 AI의 과학적 한계, 뭐길래?\n\n2025.03.22\n\n![](https://image.zdnet.co.kr/2025/03/21/aib3140d3c0cc364a4e32c5cd58fa06ea5.jpg)\n\n## [Q&AI] '고공행진' 한화에어로, 주가 15% 폭락…왜?\n\n2025.03.21\n\n### 오늘의 주요뉴스\n\n![](https://image.zdnet.co.kr/2025/07/09/e6ecfd471423f8fceb12e03eb249be48-300x300.jpg)\n\n## 스테이블코인 대신 카드결제?…금융은 기회 포착했다\n\n### 지금 뜨는 기사\n\n![](https://image.zdnet.co.kr/2025/07/09/e6ecfd471423f8fceb12e03eb249be48-290x182.jpg)\n\n## 스테이블코인 대신 카드결제?…금융은 기회 포착했다\n\n손희연, 김한준, 남혁우, 신영빈 기자 6시간 전\n\n![](https://image.zdnet.co.kr/2025/07/10/869372f643f279088b7d331e01514ce0-290x182.jpg)\n\n## [타보고서] 고속도로가 도서관보다 적막해…더 정숙해진 볼보 XC90\n\n김재성 기자 10시간 전\n\n![](https://image.zdnet.co.kr/2025/07/11/ddbf7f8d87df05f0d39cb0fd99d87e0f-290x182.jpg)\n\n## 파리바게뜨, 인기빵 최대 900원 인하…‘착!한 빵 프로젝트’ 진행\n\n김민아 기자 6시간 전\n\n![](https://image.zdnet.co.kr/2025/07/11/22aa50c0ba58d266bfe675415ac6df09-290x182.jpg)\n\n## 아이폰17 프로 모형 봤더니…\"사과 위치가 바뀌었네\"\n\n이정현 미디어연구소 7시간 전\n\n![](https://image.zdnet.co.kr/2025/07/10/99c6ae013a2a19ce4aa3304b97d2e59f-290x182.png)\n\n## 일론 머스크, `그록4`로 AI 초격차 선언…성능·적용성 모두 `압도적`\n\n조이환 기자 2025.07.10\n\n![TOP](/img_mobile/btn_top.png)\n\nSNS에서도 지디넷코리아뉴스를 받아보세요.\n\n![](/img_mobile/sns_bt1.jpg?ver=20220905)\n![](/img_mobile/sns_bt2.jpg?ver=20220905)\n![](/img_mobile/sns_bt3.jpg?ver=20220905)\n![](/img_mobile/sns_bt4.jpg?ver=20220905)"
    },
    {
        "url": "https://xpert.digital/ko/exaone-deep/",
        "title": "Exaone Deep과의 인공 지능 : LG AI Research - Xpert.Digital",
        "content": "Exaone Deep는 디코더 온 트랜스포머 아키텍처를 기반으로하며 3 가지 크기 변형으로 제공됩니다.\n\n1.   Exaone Deep-32B : 320 억 파라미터와 64 개의 레이어가있는 플래그십 모델은 최대 추론 성능에 최적화되었습니다.\n2.   Exaone Deep-7.8b : 78 억 파라미터와 32 개의 층의 경량 버전으로 크기의 24%만으로 32B 모델의 성능의 95%를 제공합니다.\n3.   Exaone Deep-2.4B : 24 억 개의 매개 변수와 30 개의 층을 가진 기기 모델은 작습니다 (32B 모델의 7.5%)에도 불구하고 여전히 성능의 86%에 도달합니다.\n\n모든 모델의 최대 컨텍스트 범위는 32,768 개의 토큰이며, 이는 이전 모델에 비해 크게 개선되었습니다. 이 모델은 주로 오랜 사고 프로세스를 고려하는 추론 특정 데이터 레코드에 대해 교육을 받았으며, 이는보다 복잡한 관계를 이해하고 논리적 결론을 도출 할 수있게 해줍니다.\n\n적합:",
        "score": 0.79293,
        "raw_content": "Published Time: 2025-03-24T08:58:40+01:00\n\nExaone Deep 🤖와 인공 지능 : LG AI Research는 한국의 🚀 -Agentic AI 앞에서 새로운 추론 AI 모델을 제시합니다.\n\n===============\n\n[![Image 1: 스마트팩토리 블로그/포털 | 도시 | XR | 메타버스 | 인공지능(AI) | 디지털화 | 태양광 | 업계 영향력자 (II) ](https://xpert.digital/wp-content/uploads/2025/04/Xpert-Single-Logo-XWing-Header-329px.png)](https://xpert.digital/ko/)\n\n엑스페이퍼\n\n![Image 2: 비즈니스 혁신가 - Xpert.Digital -Konrad Wolfenstein](https://ecfeda1c.rocketcdn.me/wp-content/uploads/2025/04/business-innovator-image-3-300px-png.png)\n\n[이것에 대한 자세한 내용은 여기에 있습니다](https://xpert.digital/ko/xpert-digital-business-innovator/)\n\n⭐️ [인공 지능 (AI) -AI 블로그, 핫스팟 및 컨텐츠 허브](https://xpert.digital/ko/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-ai/) ⭐️ [디지털 인텔리전스](https://xpert.digital/ko/%EB%94%94%EC%A7%80%ED%84%B8-%EC%9D%B8%ED%85%94%EB%A6%AC%EC%A0%84%EC%8A%A4/) ⭐️ [XPAPIT](https://xpert.digital/ko/%EC%A2%85%EC%9D%B4/)\n\n인쇄/PDF\n\n언어 선택 📢\n\n* * *\n\nExaone Deep과의 인공 지능 : LG AI Research\n====================================\n\n게시 : 2025 년 3 월 24 일 / 업데이트 : 2025 년 3 월 24 일 - 저자 : [Konrad Wolfenstein](https://xpert.digital/ko/%EC%9E%91%EA%B0%80/%EC%A0%84%EB%AC%B8%EA%B0%80/)\n\n[![Image 3: Exaone Deep과의 인공 지능 : LG AI 연구](https://ecfeda1c.rocketcdn.me/wp-content/uploads/2025/03/kleinere-ki-modelle-Xpert.Digital-169-png.png)](https://ecfeda1c.rocketcdn.me/wp-content/uploads/2025/03/kleinere-ki-modelle-Xpert.Digital-169-png.png)\nExaone Deep의 인공 지능 : LG AI Research는 한국 이미지의 새로운 추론 AI 모델 에이전트 AI를 소개합니다 : Xpert.Digital\n\n한국의 AI 공격 : Exaone Deep는 글로벌 표준을 설정합니다\n--------------------------------------\n\n### LG는 Exaone Deep : 혁신적인 에이전트 AI를 오픈 소스 기준으로 제공합니다.\n\nExaone Deep를 통해 LG AI Research는 AI 모델을 한국 AI 노력을 세계 무대에 가져 오는 오픈 소스로 추가로 추론했습니다. NVIDIA의 개발자 컨퍼런스 GTC는 2025 년 3 월에 발표 된이 모델은이를 기반으로 자율적 인 결정을 공식화, 점검, 확인 및 수행하는 능력이 특징입니다. 이 혁신적인 AI 솔루션은 \"에이전트 AI\"시대로의 전환을 나타내며이 기술을 발전시키는 소수의 글로벌 회사들 사이에서 LG를 위치시킵니다. Exaone Deep은 효율적인 모델 크기를 갖춘 수학적, 과학 및 코딩 벤치 마크에서 인상적인 업적을 통해 AI 개발에서 중요한 진전입니다.\n\n### Exaone 모델 가족과 그들의 개발\n\n#### 처음부터 Exaone Deep까지\n\nExaone Deep의 기초는 2020 년 12 월 LG AI Research의 기초로 마련되었습니다. LG Corp 회장 Koo Kwang-Mo의 리더십하에 연구 부서는 AI 기술을 통해 LG의 장기적인 미래를 확보하기 위해 시작되었습니다. 경영 회의에서 KOO는 다음과 같이 강조했다.\n\nExaone 모델 패밀리의 개발은 2021 년 12 월 Exaone 1.0으로 시작하여 약 3 천억 개의 매개 변수를 가진“Supergiant AI”모델입니다. 이어 2023 년 7 월 Exaone 2.0과 2024 년 8 월 Exaone 3.0이 이어졌으며, 후자는 한국 최초의 오픈 소스 AI 모델이 중요한 이정표였습니다. 2024 년 말, Exaone 3.5는 개선 된 교육 준수와 더 긴 상황에 대한 이해가 향상되었습니다. Exaone Deep는이 개발을 바탕으로 구체적으로 추론 기술에 중점을 둡니다.\n\n#### 기술 아키텍처 및 모델 변형\n\nExaone Deep는 디코더 온 트랜스포머 아키텍처를 기반으로하며 3 가지 크기 변형으로 제공됩니다.\n\n1.   Exaone Deep-32B : 320 억 파라미터와 64 개의 레이어가있는 플래그십 모델은 최대 추론 성능에 최적화되었습니다.\n2.   Exaone Deep-7.8b : 78 억 파라미터와 32 개의 층의 경량 버전으로 크기의 24%만으로 32B 모델의 성능의 95%를 제공합니다.\n3.   Exaone Deep-2.4B : 24 억 개의 매개 변수와 30 개의 층을 가진 기기 모델은 작습니다 (32B 모델의 7.5%)에도 불구하고 여전히 성능의 86%에 도달합니다.\n\n모든 모델의 최대 컨텍스트 범위는 32,768 개의 토큰이며, 이는 이전 모델에 비해 크게 개선되었습니다. 이 모델은 주로 오랜 사고 프로세스를 고려하는 추론 특정 데이터 레코드에 대해 교육을 받았으며, 이는보다 복잡한 관계를 이해하고 논리적 결론을 도출 할 수있게 해줍니다.\n\n적합:\n\n*   [비즈니스 사고 실수 : 한국의 예를 사용한 영어 웹 사이트의기만적인 빛 - 글로벌 콘텐츠 이상의 것이 필요합니다.](https://xpert.digital/ko/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4-%EC%8B%A4%EC%88%98/)[![Image 5: 한국의 검색 엔진 최적화 (SEO) : Naver vs. Google 및 포괄적 인 컨텐츠 전략](blob:http://localhost/0ea7ee7f0067e2d49c63bab2fe80efca)](https://xpert.digital/ko/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4-%EC%8B%A4%EC%88%98/ \"비즈니스 사고 실수 : 한국의 예를 사용한 영어 웹 사이트의기만적인 빛 - 글로벌 콘텐츠 이상의 것이 필요합니다.\")\n\n### 성능 기능 및 벤치 마크 결과\n\n#### 수학적 추론 및 과학적 문제 해결\n\nExaone Deep는 특히 수학적 및 과학적 추론 작업에서 인상적인 결과를 보여줍니다. 32B 모델은 수학 부분에서 한국 대학 입학 시험 (CSAT)에서 94.5 점을 기록했으며 미국 초청 수학 시험 (AIME) 2024 90.0 포인트에서 경쟁 모델을 능가했습니다.\n\n수학적 문제 해결 기술 평가를위한 지수 인 Math-500을 사용하면 95.7 포인트를 달성했습니다. 특히이 모델은 DeepSeek-R1 (671 억 파라미터)과 같은 일부 \"거인\"모델의 크기의 약 5%만으로 이러한 서비스를 달성한다는 점에 주목할 만하다.\n\n과학적 추론 분야에서, GPQA 다이아몬드 테스트의 32B 모델은 물리, 화학 및 생물학의 박사 수준에서 문제 해결 기술을 평가했으며 66.1 점을 기록했습니다. 이 결과는 복잡한 과학적 개념을 이해하고 적용하는 모델의 능력을 강조합니다.\n\n#### 코딩 기술과 언어에 대한 일반적인 이해\n\nExaone Deep는 또한 코딩 및 문제 해결 분야에서 강점을 입증합니다. 코딩 기술을 평가하는 LiveCodebench 테스트에서 32B 모델은 59.5의 값에 도달했습니다. 이는 소프트웨어 개발, 자동화 및 높은 수준의 계산이 필요한 기타 기술 영역의 응용 가능성을 강조합니다.\n\n언어에 대한 일반적인 이해 에서이 모델은 한국 모델에서 83.0 점으로 가장 높은 MMLU 점수 (대규모 멀티 태스킹 언어 이해)를 확보했습니다. 이것은 Exaone Deep이 전문적인 추론 과제에서 효율적일뿐만 아니라 언어에 대한 일반적인 이해에서도 효율적임을 보여줍니다.\n\n#### 소규모 모델의 성능 효율성\n\n더 작은 모델 변형의 성능은 특히 주목할 만하다. 7.8B 모델은 Amath-500에서 94.8 점, AIME 2025에서 59.6 점을 기록한 반면, AMIOM-500 92.3 포인트, AIME 2024의 2.4B 모델은 47.9 점을 기록했습니다. 이 결과는 모든 중요한 벤치 마크에서 각 카테고리의 상단에 더 작은 버전의 Exaone을 배치합니다.\n\n커뮤니티는 특히 2.4B 모델의 성능에 놀랐습니다. Reddit 기여 에서이 작은 모델은 특정 벤치 마크에서 상당히 큰 Gemma3 27b 모델을 초과한다는 점에 주목됩니다. 한 사용자는 다음과 같이 썼다.\n\n### AI 시장의 응용 잠재력과 의미\n\n#### 산업, 연구 및 교육 분야\n\nLG AI Research는 Exaone Deep가 다양한 영역에서 사용될 것으로 기대합니다. 보도 자료는 다음과 같이 말합니다.\n\n스마트 폰, 자동차 및 로봇 공학과 같은 장치의 작은 크기로 인해 사용될 수있는 온 디바이스 모델 (2.4B)에 특별한 초점이 초점을 맞추고 있습니다. 외부 서버에 필요한 연결없이 데이터를 안전하게 처리 할 수 ​​있으므로이 모델은 데이터 보안 및 개인 데이터 보호에 대한 이점을 제공합니다.\n\n#### 글로벌 AI 경쟁에서의 포지셔닝\n\nExaone Deep의 출판으로 LG는 점점 경쟁이 치열한 글로벌 AI 시장에서 자리 매김합니다. 따라서 한국 기술 회사는 Openaai, Google Deepmind 및 DeepSeek와 같은 중국 AI 개발자와 같은 대규모 기술 회사와 직접 경쟁을 진행합니다.\n\nLG AI Research의 한 대표는 2 월에 2 월에 2 월에 열린 국내 AI 산업 경쟁 진단 및 검사 회의에 참여한 지 약 한 달 동안 Exaone Deep을 발표했으며 2 월 National Artificial Intelligence Committee에서 열렸으며 DeepSeek R1 레벨 모델의 오픈 소스 출판은 잠재 고객입니다. \" 대표는 다음과 같이 덧붙였다.\n\n추론 능력 분야에서 Chinas Deepseek의 부상 후 비용 효율적인 모델이 큰 관심을받을 때, LGS는 작지만 강력한 모델을 개발하기위한 LGS 접근 방식이 전략적 이점이 될 수 있습니다.\n\n### 추론 -Ki 및 \"Agentic AI\"의 의미\n\n#### 지식 스키에서 추론-키에 이르기까지\n\nExaone Deep를 통해 LG AI Research는 \"Knowledge Ki\"에서 \"Orady-Ki\"로 전환됩니다. 전통적인 AI 모델은 주로 정보 호출 및 제공에 적용되지만 Exaone Deep와 같은 추론은 가설을 독립적으로 설정하고 확인하고 자율적으로 결정을 내릴 수 있습니다.\n\n이 능력은“에이전트 AI” - 활성 AI 시대에 진입하여 독립적으로“생각하고 행동 할 수 있습니다. LG AI Research는 다음과 같이 설명합니다. \"에이전트 AI는 가설을 독립적으로 공식화하고이를 확인하기위한 결론을 수행함으로써 자율적 인 결정을 내릴 수있는 활발한 AI를 말합니다.\"\n\n#### 오픈 소스 전략\n\nExaone Deep Publication의 중요한 측면은 모델을 오픈 소스로 제공하기로 한 결정입니다. 그 다음에는 한국 최초의 오픈 소스 AI 모델 인 Exaone 3.0으로 시작된 전략이 뒤 따릅니다.\n\n오픈 소스 전략을 통해 개발자는 제한없이 연구 목적으로 모델을 사용하고 개발할 수 있습니다. 이로 인해 광범위한 응용 프로그램과 기술의 추가 개발로 이어질 수 있으며 글로벌 AI 생태계에서 LG의 위치를 ​​강화할 수 있습니다.\n\nLG AI Research의 회장 인 경훈 바 (Kyung-Hoon Bae)는 다음과 같이 말했습니다 :“우리는 대학과 연구 기관이 AI 연구 생태계에 기여하고 AI 경쟁 능력을 더욱 향상시키는 최신 생성 AI 기술을 사용할 수 있도록 오픈 소스 로서이 매우 다목적이고 가벼운 모델을 오픈 소스로 제공 할 계획입니다.”\n\n적합:\n\n*   [한국의 검색 엔진 최적화 (SEO) : Naver vs. Google 및 포괄적 인 컨텐츠 전략](https://xpert.digital/ko/suedkorea%EC%9D%98-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%B5%9C%EC%A0%81%ED%99%94/)[![Image 7: 한국의 검색 엔진 최적화 (SEO) : Naver vs. Google 및 포괄적 인 컨텐츠 전략](blob:http://localhost/0ea7ee7f0067e2d49c63bab2fe80efca)](https://xpert.digital/ko/suedkorea%EC%9D%98-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%B5%9C%EC%A0%81%ED%99%94/ \"한국의 검색 엔진 최적화 (SEO) : Naver vs. Google 및 포괄적 인 컨텐츠 전략\")\n\n### 미래의 전망과 지속적인 발전\n\n#### Chatexaone : 회사의 AI 기반 생산성을위한 새로운 표준\n\nLG는 Exaone을 다양한 제품 및 서비스에 통합하기 위해 LG 자회사와 협력 할 계획입니다. 애플리케이션에 따라 Exaons는 온 디바이스 -KI 서비스 용 Ultra-Light-Weight 모델에서 전문 애플리케이션의 고성능 모델에 이르기까지 다양한 모델 크기로 제공됩니다.\n\nExaone 기술의 실제 적용에 대한 구체적인 예는 LG 그룹의 직원을위한 오픈 베타 버전으로 이미 제공되는 Exaone 3.0을 기반으로 한 KI 에이전트 인 Chatexaone입니다. Chatexaone은 실시간 WEB 기반 질문 답변 시스템, 문서 및 이미지 기반 질문 응답 시스템, 코딩 지원 및 데이터베이스 관리를 포함하여 노동 생산성을 높이기위한 다양한 기능을 제공합니다.\n\n#### LG 그룹 내 AI 전문 지식의 추가 개발\n\nExaone Deep의 개발은 LG 그룹 내에서 더 큰 AI 전략의 일부입니다. LG는 이미 9 개월의 석사 학위와 18 개월의 박사 학위를 가진 맞춤형 엔지니어를 홍보하기 위해 내부 AI 대학원을 설립했습니다.\n\n이 과정을 수강하는 직원은 개별 자회사를 위해 개발하기 어려운 프로젝트를 수행합니다. 파일럿 프로젝트의 일환으로 LG Display는 동일한 화면에서 더 많은 픽셀을 수용 할 수있는 설계 기술을 개발 한 반면, AI를 사용한 정확한 수요 예측을위한 LG Electronics 및 LG Innotek 방법은 저장 비용을 크게 줄입니다.\n\n### 소규모 AI 모델이 더 나은 선택이 될 수있는 이유-Exaone Deep를보십시오.\n\nExaone Deep의 도입으로 LG AI Research는 AI 개발에서 중요한 이정표를 달성했습니다. Foundation 모델을 기반으로 한 한국 최초의 추론 AI 모델로서 LG는이 고급 AI 기술을 개발하는 여러 주요 글로벌 기술 회사에 배치합니다. 효율적인 모델 크기를 갖춘 수학적, 과학 및 코딩 벤치 마크의 인상적인 성능은 다양한 응용 분야에 대한이 모델의 잠재력을 강조합니다.\n\nLG의 접근 방식은 특히 크기가 적은 고성능 AI 모델을 개발하는 데 특히 주목할 만하다. 많은 AI 회사가 더 큰 모델에 의존하지만 Exaone Deep는 지능적 최적화와 전문 교육을 통해 소규모 모델이 최고 성능을 달성 할 수 있음을 보여줍니다. 이는 경제적 이점을 제공 할 수있을뿐만 아니라 Edge 장치에서 강력한 AI 모델을 사용할 수 있습니다.\n\nExaone Deep의 오픈 소스 간행물로 LG AI Research는 Global AI Research Ecosystem에 기여하고 동시에 국제 AI 경쟁에서 한국의 위치를 ​​강화합니다. LG 그룹의 다양한 제품 및 서비스 에서이 기술이 어떻게 구현되는지, 그리고 다양한 산업에서 어떤 혁신을 가능하게 할 것인지는 여전히 남아 있습니다.\n\n적합:\n\n*   [이제 한국에서 Deepseek가 금지 - 이탈리아, 대만, 호주 및 미국으로](https://xpert.digital/ko/deepseek-%EA%B8%88%EC%A7%80/)\n*   [SEO (Search Engine Optimization)에서 국가 언어의 중심 역할을 사용](https://xpert.digital/ko/%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84-%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%98-%EC%83%81%ED%83%9C-%EC%96%B8%EC%96%B4/)\n\n귀하의 글로벌 마케팅 및 비즈니스 개발 파트너\n-------------------------\n\n#### ✔️ 우리의 비즈니스 언어는 영어 또는 독일어입니다.\n\n#### ✔️ 새로운 기능: 자국어로 된 통신!\n\n[![Image 9: 디지털 개척자 - Konrad Wolfenstein](blob:http://localhost/3d7e3536fb2191eecfa4af1023c9b129)](https://ecfeda1c.rocketcdn.me/wp-content/uploads/2018/12/digital-pioneer.png)\n콘라드 울펜슈타인\n\n**나는 귀하와 우리 팀에 개인 고문으로 봉사하게 되어 기쁘게 생각합니다.**\n\n[문의 양식을 작성하여](https://xpert.digital/ko/%EB%AC%B8%EC%9D%98-%EC%96%91%EC%8B%9D/) 연락하시거나 **[+49 89 89 674 804](tel:+8989674804)****(뮌헨)** 로 전화해 주세요 . 내 이메일 주소는: [Wolfenstein](https://xpert.digital/ko/)[∂](https://xpert.digital/ko/)[xpert.digital](https://xpert.digital/ko/)\n\n나는 우리의 공동 프로젝트를 기대하고 있습니다.\n\n#### ✓ 전략, 컨설팅, 계획 및 구현에 대한 중소기업 지원\n\n#### ✔️ 디지털 전략 및 디지털화의 생성 또는 재편성\n\n#### ✔️ 해외 영업 프로세스의 확장 및 최적화\n\n#### ✔️ 글로벌 및 디지털 B2B 거래 플랫폼\n\n#### ✔️ 선구적인 사업 개발 / 마케팅 / 홍보 / 무역 박람회\n\n### 다른 주제\n\n*   [![Image 11: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai/ \"에이전트 ai | Openai의 Chatgpt의 최신 개발 : Deep Research, GPT-4.5 / GPT-5, 감성 지능 및 정밀도\")[에이전트 ai | Openai의 Chatgpt의 최신 개발 : Deep Research, GPT-4.5 / GPT-5, 감성 지능 및 정밀도 ...](https://xpert.digital/ko/%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-ai/ \"에이전트 ai | Openai의 Chatgpt의 최신 개발 : Deep Research, GPT-4.5 / GPT-5, 감성 지능 및 정밀도\")  \n*   [![Image 13: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/%EC%B4%88%EA%B8%B0-%EC%84%A0%EB%B3%84-%EB%8F%84%EA%B5%AC%EB%A1%9C%EC%84%9C%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC/ \"OpenAi Deep Research : 사용자에게는 하이브리드 접근 방식이 권장됩니다. 초기 스크리닝 도구로서의 깊은 연구\")[Openai Deep Research : 사용자에게는 하이브리드 접근 방식이 권장됩니다. 초기 스크리닝 도구로서의 AI Deep Research ...](https://xpert.digital/ko/%EC%B4%88%EA%B8%B0-%EC%84%A0%EB%B3%84-%EB%8F%84%EA%B5%AC%EB%A1%9C%EC%84%9C%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC/ \"OpenAi Deep Research : 사용자에게는 하이브리드 접근 방식이 권장됩니다. AI 초기 스크리닝 도구로서의 AI Deep Research\")  \n*   [![Image 15: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/o3-%EB%AF%B8%EB%8B%88-%EC%A7%A7%EC%9D%80-%EB%B2%84%EC%A0%84/ \"짧은 버전 오른쪽\")[앞으로 나올 내용의 간략한 버전: OpenAi의 새로운 AI 모델 \"o3 mini\" - 앞으로 몇 주 안에 공개됩니다...](https://xpert.digital/ko/o3-%EB%AF%B8%EB%8B%88-%EC%A7%A7%EC%9D%80-%EB%B2%84%EC%A0%84/ \"짧은 버전 오른쪽\")  \n*   [![Image 17: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/gemini-deep-research-2-0/ \"Google AI 모델 업그레이드 : New Gemini 2.0-Deep Research 2.0, Flash 2.0, Flash Thinking 2.0 및 Pro 2.0 (실험)\")[신규 : Gemini Deep Research 2.0 -Google Ki -Modell 업그레이드 - Gemini 2.0 Flash, Flash Thinking and Pro (실험적으로)에 대한 정보 ...](https://xpert.digital/ko/gemini-deep-research-2-0/ \"신규 : Gemini Deep Research 2.0-Google Ki-Modell Gemini 2.0 Flash, Flash Thinking and Pro (실험)에 대한 정보.\")  \n*   [![Image 19: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC-%EB%8F%84%EA%B5%AC/ \"가장 어려운 테스트에서 AI Deep Research Tools : 어떤 Ki-Genius가 깊은 지식을 제공합니까? Openai, Perplexity 또는 Google Gemini?\")[강화 테스트의 Ki Deep Research 도구 : OpenAi, Perplexity 또는 Google Gemini 1.5 Pro의 Chatgpt?](https://xpert.digital/ko/%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC-%EB%8F%84%EA%B5%AC/ \"강화 테스트의 Ki Deep Research Tools : OpenAi, Perplexity 또는 Google Gemini 1.5 Pro의 Chatgpt?\")  \n*   [![Image 21: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/gemini%EC%99%80%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC-2-0/ \"Gemini 2.0과의 깊은 연구 - 고급 연구 기능에 대한 포괄적 인 분석\")[Gemini 2.0의 Google Deep Research- 고급 연구 기능에 대한 포괄적 인 분석 ...](https://xpert.digital/ko/gemini%EC%99%80%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC-2-0/ \"Gemini 2.0을 포함한 Google Deep Research- 고급 연구 기능에 대한 포괄적 인 분석\")  \n*   [![Image 23: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/chatgpt%EC%99%80%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC/ \"AI 기반 지식 작업 : Openaai의 Chatgpt에 대한 깊은 연구 : 장점과 한계는 어디에 있습니까?\")[AI 기반 지식 작업 : Openaai의 Chatgpt와의 깊은 연구 : 장점과 한계는 어디에 있습니까?](https://xpert.digital/ko/chatgpt%EC%99%80%EC%9D%98-%EA%B9%8A%EC%9D%80-%EC%97%B0%EA%B5%AC/ \"AI 기반 지식 작업 : Openaai의 Chatgpt에 대한 깊은 연구 : 장점과 한계는 어디에 있습니까?\")  \n*   [![Image 25: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/%EA%B5%AC%EA%B8%80-%EB%94%A5-%EB%A6%AC%EC%84%9C%EC%B9%98/ \"“Google Deep Research”: 기존 Google의 종말 뒤에 숨은 게임 체인저? 모든 것을 바꾸는 AI 보조기술?\")[“Google Deep Research”: 기존 Google의 종말 뒤에 숨은 게임 체인저? 모든 것을 바꾸는 AI 보조기술?…](https://xpert.digital/ko/%EA%B5%AC%EA%B8%80-%EB%94%A5-%EB%A6%AC%EC%84%9C%EC%B9%98/ \"“Google Deep Research”: 기존 Google의 종말 뒤에 숨은 게임 체인저? 모든 것을 바꾸는 AI 보조기술?\")  \n*   [![Image 27: Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind](blob:http://localhost/f6b5df703bca1c10fc465f8af236d09b)](https://xpert.digital/ko/google%EC%9D%98-gemini-%ED%94%8C%EB%9E%AB%ED%8F%BC/ \"Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind\")[Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind...](https://xpert.digital/ko/google%EC%9D%98-gemini-%ED%94%8C%EB%9E%AB%ED%8F%BC/ \"Google AI Studio가 포함된 Google의 Gemini 플랫폼, Gemini Advanced가 포함된 Google Deep Research 및 Google DeepMind\")  \n\n* * *\n\n⭐️ [인공 지능 (AI) -AI 블로그, 핫스팟 및 컨텐츠 허브](https://xpert.digital/ko/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-ai/) ⭐️ [디지털 인텔리전스](https://xpert.digital/ko/%EB%94%94%EC%A7%80%ED%84%B8-%EC%9D%B8%ED%85%94%EB%A6%AC%EC%A0%84%EC%8A%A4/) ⭐️ [XPAPIT](https://xpert.digital/ko/%EC%A2%85%EC%9D%B4/)\n\n© 2025 년 6 월 XPERT.DIGITAL / XPERT.PLUS -KONRAD WOLFENSTEIN- 비즈니스 개발\n\n![Image 29](https://pixel.wp.com/g.gif?v=ext&blog=150760576&post=37437&tz=2&srv=xpert.digital&j=1%3A14.7&host=xpert.digital&ref=&fcp=0&rand=0.7412109351242496)\n"
    },
    {
        "url": "https://www.msap.ai/blog/exaone-lg-llm/",
        "title": "Exaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP.ai",
        "content": "Exaone은 범용 LLM과는 전혀 다른 출발점과 목적, 그리고 활용 환경을 고려해 설계된 모델입니다. 한국어와 산업별 특화된 이해 능력, 텍스트와 이미지를 함께 처리할 수 있는 멀티모달 기능, 그리고 실사용을 전제로 한 아키텍처 설계는 Exaone을 단순한 기술 데모 수준을 넘어선, 실제 산업 현장에서 작동 가능한 인공지능으로 자리매김하게 만듭니다. 여기에 제한적 라이선스를 통한 보안성과 책임성까지 더해지면서, Exaone은 독자적인 가치를 갖는 실전형 LLM으로 평가받고 있습니다. [...] 활용 목적 측면에서도 Exaone은 기존 오픈소스 모델들과 확연히 구분됩니다. Gemma 3, LLaMA 3, DeepSeek R1 등의 모델은 연구자와 개발자 커뮤니티를 겨냥해 공개되었으며, 대부분 상업적 사용까지 허용하는 유연한 라이선스를 제공합니다. 반면, Exaone은 처음부터 기업 내부 환경에서의 실질적 배치를 전제로 개발된 모델입니다. 실제로 LG 계열사의 스마트팩토리 운영, 고객 응대 자동화, 기술 문서 요약, 품질 분석 등 다양한 산업 분야에서 이미 활용되고 있으며, 단순한 생성 성능을 넘어서 데이터 보안, 책임 추적성, 커스터마이징 가능성 등 엔터프라이즈 환경에 필요한 요소들을 포괄하고 있습니다. 이로 인해Exaone은 오픈소스로 공개되어 있음에도 불구하고 라이선스 조건이 연구 목적에 한정되며, 상업적 사용을 원할 경우에는 반드시 LG와 별도의 상업용 라이선스를 체결해야 합니다. [...] Published Time: 2025-04-04T08:47:30+00:00\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP\n\n===============\nSkip to content\n\nSearch for:     로, 텍스트뿐만 아니라 이미지 등 다양한 입력을 동시에 이해하고 처리할 수 있는 모델입니다. “Exaone”이라는 이름은 “Exascale AI for Everyone”의 약어로, 누구나 활용할 수 있는 엑사급 인공지능이라는 비전을 담고 있습니다.\n\nExaone은 단순한 기술 실험이 아닌, 국내 대기업이 직접 개발하고 실사용 사례에 적용하는 LLM이라는 점에서 매우 중요한 모델입니다. OpenAI나 Meta, Google과 같은 글로벌 빅테크가 개발한 LLM에만 의존하지 않고, 한국어와 산업 현장에 최적화된 독자 생태계를 구축하려는 LG의 전략적 움직임이기도 합니다.",
        "score": 0.7900289,
        "raw_content": "Published Time: 2025-04-04T08:47:30+00:00\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP\n\n===============\n[Skip to content](https://www.msap.ai/blog/exaone-lg-llm/#content)\n\n[](https://www.msap.ai/)\n\n[![Image 1: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)![Image 2: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)![Image 3: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)](https://www.msap.ai/)\n\nSearch for: \n\n[](https://www.msap.ai/blog/exaone-lg-llm/#)\n\nToggle Navigation\n*   [MSAP.ai](https://www.msap.ai/msap-ai/)\n    *   [MSA Accelerator](https://www.msap.ai/msap-ai/msa-accelerator/)\n        *   [DDD Designer](https://www.msap.ai/msap-ai/msa-accelerator/ddd-designer/)\n        *   [Application Designer](https://www.msap.ai/msap-ai/msa-accelerator/application-designer/)\n        *   [MSA Framework](https://www.msap.ai/msap-ai/msa-accelerator/msa-framework/)\n\n    *   [PLATFORM](https://www.msap.ai/msap-ai/platform/)\n        *   [Container Platform](https://www.msap.ai/msap-ai/platform/container-platform/)\n        *   [Observability & APM](https://www.msap.ai/msap-ai/platform/observability-apm/)\n        *   [POD Cluster](https://www.msap.ai/msap-ai/platform/pod-cluster/)\n\n    *   [AI](https://www.msap.ai/msap-ai/ai-as-a-service/)\n        *   [LLM](https://www.msap.ai/msap-ai/ai-as-a-service/large-language-model/)\n        *   [RAG](https://www.msap.ai/msap-ai/ai-as-a-service/retrieval-augmented-generation/)\n        *   [AI Framework](https://www.msap.ai/msap-ai/ai-as-a-service/ai-framework/)\n\n    *   [HARDWARE](https://www.msap.ai/msap-ai/hardware/)\n    *   [MSAP.ai 제품문의](https://www.msap.ai/msap-ai/solution-contact/)\n\n*   [컨설팅](https://www.msap.ai/consulting/)\n    *   [MSA 특화 컨설팅](https://www.msap.ai/consulting/msa-special-consulting/)\n    *   [MSA 설계 및 플랫폼 구축](https://www.msap.ai/consulting/msa-design-platform-deployment/)\n    *   [클라우드 네이티브 전환 진단 컨설팅](https://www.msap.ai/consulting/cloud-native-transition-diagnostic-consulting/)\n    *   [MSA 전환, IT 현황 진단 서비스](https://www.msap.ai/consulting/msa-it-assessment/)\n    *   [MSA Conveyor Belt Workshop 신청](https://www.msap.ai/consulting/msa-workshop/)\n\n*   [교육](https://www.msap.ai/training/)\n    *   [MSA 특화 교육](https://www.msap.ai/training/msa-special-training/)\n    *   [MSA 개념과 패턴 교육](https://www.msap.ai/training/msa-concept-pattern-training/)\n    *   [찾아가는 MSA & 클라우드 네이티브 세미나](https://www.msap.ai/training/free-cloud-native-seminar/)\n\n*   [이벤트 & 세미나](https://www.msap.ai/event-seminar/)\n    *   [세미나](https://www.msap.ai/event-seminar/seminar/)\n    *   [이벤트](https://www.msap.ai/event-seminar/event/)\n\n*   [블로그](https://www.msap.ai/msap-blog/)\n    *   [전체 블로그](https://www.msap.ai/msap-blog/msap-all-blog/)\n    *   [AI 블로그](https://www.msap.ai/msap-blog/msap-ai-blog/)\n    *   [MSA 블로그](https://www.msap.ai/msap-blog/msap-msa-blog/)\n    *   [Platform 블로그](https://www.msap.ai/msap-blog/msap-platform-blog/)\n\n*   [자료실](https://www.msap.ai/resource/)\n    *   [공지사항](https://www.msap.ai/resource/notice/)\n    *   [eBook](https://www.msap.ai/docs/msa-expert-from-concepts-to-practice/)\n    *   [Datasheet](https://www.msap.ai/resource/datasheet/)\n    *   [Whitepaper](https://www.msap.ai/resource/whitepaper/)\n    *   [Solution Briefs](https://www.msap.ai/resource/solution-briefs/)\n    *   [Case Studies](https://www.msap.ai/resource/case-studies/)\n    *   [Presentation](https://www.msap.ai/resource/presentation/)\n    *   [Webinars](https://www.msap.ai/resource/webinars/)\n\n*   [기술지원](https://www.msap.ai/support/)\n    *   [기술지원 요청](https://www.msap.ai/support/%ea%b8%b0%ec%88%a0%ec%a7%80%ec%9b%90-%ec%9a%94%ec%b2%ad/)\n    *   [기술지원 소개](https://www.msap.ai/support/%ea%b8%b0%ec%88%a0%ec%a7%80%ec%9b%90-%ec%86%8c%ea%b0%9c/)\n\n*   [회사](https://www.msap.ai/company/)\n    *   [사업영역](https://www.msap.ai/company/business-domain/)\n    *   [기업연혁](https://www.msap.ai/company/history/)\n    *   [BI 소개](https://www.msap.ai/company/msap-ai-bi-introduce/)\n    *   [오시는길](https://www.msap.ai/company/location/)\n    *   [MSAP.ai 굿즈 스토어](https://www.msap.ai/goods/)\n\n*   [](https://www.msap.ai/blog/exaone-lg-llm/# \"Search\")Search for:     [](https://www.msap.ai/blog/exaone-lg-llm/#) \n\nMSAP.ai 블로그\n===========\n\nMSAP.ai 블로그에서 최신 정보와 유용한 팁을 만나보세요. 다양한 콘텐츠와 전문 지식을 통해 더 나은 경험을 제공합니다.\n\nAI Blog,Blog\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델\n=============================\n\n이 글은 LG가 개발한 LLM 모델 Exaone의 특성과 활용 조건, 라이선스 주의사항까지 한눈에 정리한 콘텐츠입니다.\n\n2025년 04월 04일\n\n![Image 4: Exaone 은 무엇인가? LG가 개발한 LLM 모델](https://www.msap.ai/wp-content/uploads/2025/04/msap-body-exaone-lg-llm.webp)\n\nExaone 이란 무엇인가?\n---------------\n\nExaone은 LG AI Research에서 개발한 **초거대 멀티모달 언어 모델**(large-scale multimodal language model)로, 텍스트뿐만 아니라 이미지 등 다양한 입력을 동시에 이해하고 처리할 수 있는 모델입니다. “Exaone”이라는 이름은 “Exascale AI for Everyone”의 약어로, **누구나 활용할 수 있는 엑사급 인공지능**이라는 비전을 담고 있습니다.\n\nExaone은 단순한 기술 실험이 아닌, **국내 대기업이 직접 개발하고 실사용 사례에 적용하는** LLM이라는 점에서 매우 중요한 모델입니다. OpenAI나 Meta, Google과 같은 글로벌 빅테크가 개발한 LLM에만 의존하지 않고, 한국어와 산업 현장에 최적화된 독자 생태계를 구축하려는 **LG의 전략적 움직임**이기도 합니다.\n\n특히, 언어뿐 아니라 **멀티모**달 처리 능력까지 제공하면서, 단순한 텍스트 생성기를 넘어 **기업용 지식 처리, 문서 자동화, 스마트 분석, 비전 기반 응용 분야까지 확장성 있는 LLM으로 진화**하고 있다는 점이 주목할 만합니다.\n\n### Exaone 은 언제 시작되었는가?\n\nExaone 프로젝트는 2021년부터 LG AI Research에 의해 본격적으로 시작되었습니다. 공식 발표는 2021년 12월, LG AI Research가 출범 1년 만에 공개한 결과물이었습니다. LG는 그때 이미 자체 개발한 130억 파라미터 규모의 멀티모달 초거대 AI Exaone을 통해 “기업용 LLM 개발의 시대”를 선언한 셈이었습니다.\n\n##### LG의 공식 발표 당시 메시지에서 읽을 수 있는 의도\n\n> “우리가 필요한 AI는 직접 만들어야 합니다. Exaone은 우리 산업과 언어를 이해하고, 우리 조직의 문제를 함께 해결할 수 있는 AI입니다.”\n> \n> \n> – LG AI Research, 2021\n\n##### Exaone 개발 목적\n\n**1. 한국어 및 영어 지원**: Exaone은 한국어와 영어를 모두 이해하고 처리할 수 있도록 설계되어, 국내외 다양한 환경에서 활용될 수 있습니다.\n\n**2. 멀티모달 처리 능력**: 텍스트뿐만 아니라 이미지 등 다양한 형태의 데이터를 동시에 처리할 수 있는 멀티모달 능력을 갖추어, 예술, 패션 등 다양한 분야에서 활용될 수 있습니다.\n\n**3. 산업별 맞춤형 AI 개발**: LG는 Exaone을 통해 자사 제품과 서비스에 AI를 통합하여 고객 경험을 향상시키고, 산업별 과제를 해결하고자 했습니다.\n\n**4. AI 생태계 확장**: Exaone을 오픈소스로 공개함으로써 연구 기관과 스타트업이 최신 기술을 활용할 수 있도록 지원하고, AI 생태계를 확장하고자 했습니다.\n\n이러한 목적을 통해 LG AI 연구원은 Exaone을 개발하여 다양한 산업 분야에서 AI 기술을 활용하고, 글로벌 시장에서의 경쟁력을 강화하고자 했습니다.\n\n### Exaone 라이선스 알고 사용해야 합니다.\n\n아래는 EXAONE 3.0 라이선스에 포함된 영문 원문을 그대로 인용하면서, 기업이 영리 목적으로 사용하는 경우 문제가 되는 조항을 하나씩 근거와 함께 설명드리겠습니다.\n\n##### 문제 1: 상업적 사용 금지 (Commercial Use Prohibited)\n\n기업이 Exaone 모델 또는 출력물을 자체 서비스에 활용하여 수익을 창출하거나 제품/서비스로 제공하는 행위는 명시적으로 금지되어 있습니다. 단순히 “판매”뿐 아니라 “서비스화”, “라이선싱”, “앱에 통합”하는 것도 포함됩니다.\n\n**라이선스 원문 인용**\n\n> 3.1 Restrictions\n> \n> \n> Licensee shall not use the Model, Derivatives, or Output for any Commercial Purposes.\n> \n> \n> “Commercial Purposes” means the use of the Model, Derivatives, or Output for commercial advantage or monetary compensation, including but not limited to:\n> \n> \n> (a) selling, licensing, or distributing the Model, Derivatives, or Output;\n> \n> \n> (b) using the Model, Derivatives, or Output in connection with a product, service, or application offered for sale, license, or other commercial distribution;\n> \n> \n> (c) incorporating the Model, Derivatives, or Output into a product or service that is sold or licensed to third parties.\n\n**해석**\n\n*   수익 창출을 위한 모든 활용은 금지됩니다.\n*   특히 b항은 “모델을 제품, 서비스, 애플리케이션에 결합하여 판매, 라이선스, 배포하는 것”까지 포함하므로, 기**업이 모델을 API 서비스로 내놓거나 SaaS로 구성해 판매하는 것조차도 위반**이 됩니다.\n\n##### 문제 2: 연구 목적에 한정된 사용 허가 (License Scope)\n\nExaone 3.0은 ‘연구 목적(research purposes)’으로만 사용이 허용됩니다. 연구 이외의 모든 목적은 허용되지 않으며, 이는 기업의 상용화 또는 **제품화**를 포함합니다\n\n**라이선스 원문 인용**\n\n> 2.1 Grant of License\n> \n> \n> Subject to the terms and conditions of this Agreement, Licensor hereby grants Licensee a limited, non-exclusive, non-transferable, non-sublicensable license to use the Model solely for research purposes.\n\n**해석**\n\n*   사용 허가 범위가 “연구 목적에 한해서만” 제한되어 있기 때문에 기업이 이를 자사 서비스에 통합하거나 제품에 적용하는 것은 라이선스 위반입니다.\n\n##### 문제 3: 출력물(Output)의 소유권 및 활용 제한\n\nExaone을 사용하여 생성된 출력물도 기업의 자산으로 자유롭게 활용하거나 판매할 수 없습니다. 출력물(Output)의 권리 역시 라이선스 제공자에게 귀속됩니다.\n\n**라이선스 원문 인용**\n\n> 4.2 Ownership\n> \n> \n> All rights, title, and interest in and to the Model, Derivatives, and Output shall remain with the Licensor.\n> \n> \n> Licensee shall not claim ownership or any other rights in the Model, Derivatives, or Output.\n\n**해석**\n\n*   기업은 출력 결과물에도 **소유권이나 지적재산권을 주장할 수 없으며**, 이를 자유롭게 수익화하거나 공개할 수 없습니다.\n*   이는 **서비스 결과물로 사용자에게 제공하는 형태**도 제한될 수 있음을 의미합니다.\n\n##### 문제 4: 위반 시 라이선스 자동 종료\n\n위의 조건을 위반하면 라이선스는 즉시 종료되며, 법적 책임까지 따를 수 있습니다.\n\n**라이선스 원문 인용**\n\n> 6.2 Termination for Breach\n> \n> \n> Licensor may terminate this Agreement immediately if Licensee breaches any of the terms or conditions of this Agreement.\n\n**해석**\n\n*   만약 상업적 사용 등 금지된 행위를 할 경우, 라이선스 자체가 **자동으로 무효**가 되며, **법적 조치 또는 손해배상 청구**로 이어질 가능성도 있습니다.\n\n### 기업이 주의해야 할 핵심 포인트\n\n| 구분 | 금지된 행위 | 라이선스 조항 근거 |\n| :--- | :--- | :--- |\n| 영리 목적 사용 | 모델을 사용한 제품/서비스/API 제공 | 3.1 Restrictions (a), (b), (c) |\n| 연구 목적 외 사용 | 실서비스 통합, 데이터 분석 상용화 등 | 2.1 Grant of License |\n| 출력물 소유권 주장 | 생성된 결과물의 자유로운 사용/배포 | 4.2 Ownership |\n| 라이선스 위반 시 조치 | 자동 종료 및 법적 책임 | 6.2 Termination for Breach |\n\n기업이 **EXAONE 3.0을 상업적 서비스에 사용하려면** , 현재의 공개 라이선스 하에서는 **불가능**하며, 반드시 **LG AI Research와 별도의 상업용 라이선스 계약을 체결**해야 합니다.\n\n### Exaone 의 특징\n\nExaone은 범용 LLM과는 전혀 다른 출발점과 목적, 그리고 활용 환경을 고려해 설계된 모델입니다. 한국어와 산업별 특화된 이해 능력, 텍스트와 이미지를 함께 처리할 수 있는 멀티모달 기능, 그리고 실사용을 전제로 한 아키텍처 설계는 Exaone을 단순한 기술 데모 수준을 넘어선, 실제 산업 현장에서 작동 가능한 인공지능으로 자리매김하게 만듭니다. 여기에 제한적 라이선스를 통한 보안성과 책임성까지 더해지면서, Exaone은 독자적인 가치를 갖는 실전형 LLM으로 평가받고 있습니다.\n\n활용 목적 측면에서도 Exaone은 기존 오픈소스 모델들과 확연히 구분됩니다. Gemma 3, LLaMA 3, DeepSeek R1 등의 모델은 연구자와 개발자 커뮤니티를 겨냥해 공개되었으며, 대부분 상업적 사용까지 허용하는 유연한 라이선스를 제공합니다. 반면, Exaone은 처음부터 **기업 내부 환경에서의 실질적 배치를 전제로 개발된 모델**입니다. 실제로 LG 계열사의 스마트팩토리 운영, 고객 응대 자동화, 기술 문서 요약, 품질 분석 등 다양한 산업 분야에서 이미 활용되고 있으며, 단순한 생성 성능을 넘어서 데이터 보안, 책임 추적성, 커스터마이징 가능성 등 엔터프라이즈 환경에 필요한 요소들을 포괄하고 있습니다. 이로 인해**Exaone은 오픈소스로 공개되어 있음에도 불구하고 라이선스 조건이 연구 목적에 한정되며, 상업적 사용을 원할 경우에는 반드시 LG와 별도의 상업용 라이선스를 체결**해야 합니다.\n\n이와 같은 특성은 Exaone의 생태계 운영 전략에도 그대로 반영되어 있습니다. 예를 들어 Gemma 3나 DeepSeek R1은 Hugging Face, Colab 등과 연동되며 오픈소스 커뮤니티에서 빠르게 확산되고 있고, 다양한 파생 모델과 실험이 활발하게 이루어지고 있습니다. 하지만 Exaone은 그러한 개방형 생태계 확장보다는, **내부 활용을 중심으로 안정성과 실효성을 확보하는 방향**을 택하고 있습니다. 다시 말해, Exaone은 불특정 다수를 위한 범용 AI 플랫폼이 아니라, 특정 산업 도메인에 최적화된 실용 중심의 AI로서, 명확한 정체성과 방향성을 갖고 있는 모델이라 할 수 있습니다.\n\n마무리\n---\n\nExaone은 멀티모달 처리 능력과 산업 특화 성능을 바탕으로 다양한 분야에서의 활용이 기대됩니다. 특히, 의료, 법률, 금융 등 전문 지식이 요구되는 분야에서의 적용이 예상되며, LG AI 연구원은 Exaone의 성능 향상과 적용 범위 확대를 위해 지속적인 연구와 협력을 진행하고 있습니다. 또한, 글로벌 AI 생태계와의 협력을 통해 Exaone의 활용성을 더욱 높이고, 다양한 산업 분야에서의 혁신을 주도할 것으로 전망됩니다.\n\nReferences & Related Links\n--------------------------\n\n*   [LG AI Research EXAONE 공식 페이지](https://www.lgresearch.ai/project/exaone)\n*   [EXAONE 3.0 GitHub 저장소](https://github.com/LG-AI-EXAONE/EXAONE-3.0)\n*   [EXAONE 3.0 라이선스 원문](https://github.com/LG-AI-EXAONE/EXAONE-3.0/blob/main/LICENSE)\n*   [LG, AI연구원 공식 출범…“AI가 LG의 미래를 주도할 것”](https://www.lgcorp.com/media/release/28482)\n*   [LG AI연구원, 초거대 멀티모달 AI ‘EXAONE’ 공개](https://www.lgcorp.com/media/release/27378)\n*   [LG AI Research Builds Multimodal AI Model “Exaone” on AWS to Accelerate Innovation](https://aws.amazon.com/solutions/case-studies/lg-ai-research-case-study/)\n\nBy [MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")Published On: 2025년 04월 04일 Categories: [AI Blog](https://www.msap.ai/category/blog-home/ai-blog/), [Blog](https://www.msap.ai/category/blog-home/blog/)[0 Comments on Exaone 은 무엇인가? LG가 개발한 LLM 모델](https://www.msap.ai/blog-home/blog/exaone-lg-llm/#respond)Tags: [AI](https://www.msap.ai/tag/ai/), [AI 플랫폼](https://www.msap.ai/tag/ai-%ed%94%8c%eb%9e%ab%ed%8f%bc/), [AI라이선스](https://www.msap.ai/tag/ai%eb%9d%bc%ec%9d%b4%ec%84%a0%ec%8a%a4/), [EXAONE](https://www.msap.ai/tag/exaone/), [LLM](https://www.msap.ai/tag/llm/), [LLM 플랫폼](https://www.msap.ai/tag/llm-%ed%94%8c%eb%9e%ab%ed%8f%bc/), [OpenAI](https://www.msap.ai/tag/openai/), [대규모 언어 모델](https://www.msap.ai/tag/%eb%8c%80%ea%b7%9c%eb%aa%a8-%ec%96%b8%ec%96%b4-%eb%aa%a8%eb%8d%b8/), [인공지능](https://www.msap.ai/tag/%ec%9d%b8%ea%b3%b5%ec%a7%80%eb%8a%a5/)\n\n#### Share This Story, Choose Your Platform!\n\n[](https://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&t=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8 \"Facebook\")[](https://x.com/intent/post?text=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"X\")[](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&title=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&summary=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"LinkedIn\")[](https://api.whatsapp.com/send?text=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"WhatsApp\")[](https://www.tumblr.com/share/link?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&name=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"Tumblr\")[](https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC&media= \"Pinterest\")[](https://vkontakte.ru/share.php?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&title=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"Vk\")[](mailto:?subject=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&body=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"Email\")\n\n*   ![Image 5: AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/wp-content/uploads/2025/04/msap-title-ai-accelerators.webp)[AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/blog-home/blog/ai-accelerators/)[](https://www.msap.ai/blog-home/blog/ai-accelerators/)   \n\n[AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/blog-home/blog/ai-accelerators/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T14:43:37+09:00 2025년 04월 04일|\n\n[Read More](https://www.msap.ai/blog-home/blog/ai-accelerators/)\n\n*   ![Image 6: LLM](https://www.msap.ai/wp-content/uploads/2025/03/250326-ChatGPT%EB%8A%94%EC%95%84%EB%8A%94%EB%8D%B0LLM%EC%9D%80.webp)[ChatGPT는 아는데, LLM은 무엇인가요?](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)[](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)   \n\n[ChatGPT는 아는데, LLM은 무엇인가요?](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T15:09:19+09:00 2025년 03월 26일|\n\n[Read More](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)\n\n*   ![Image 7: LLM ( Chatgpt ) 을 효과적으로 활용하기 위한 26가지 프롬프트 원칙](https://www.msap.ai/wp-content/uploads/2025/03/msap-title-llm-chatgpt-prompt.webp)[LLM ( Chatgpt )을 효과적으로 활용하는 26가지 프롬프트 원칙](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)[](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)   \n\n[LLM ( Chatgpt )을 효과적으로 활용하는 26가지 프롬프트 원칙](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T15:08:01+09:00 2025년 03월 27일|\n\n[Read More](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)\n\n*   ![Image 8: workshop](https://www.msap.ai/wp-content/uploads/2025/05/250520-MSA-Conveyor-Belt-1-Day-Workshop_title.webp)[MSA 도입, AI로 혁신을 경험하세요: MSA Conveyor Belt 1 Day Workshop](https://www.msap.ai/blog-home/blog/msa-1day-ws/)[](https://www.msap.ai/blog-home/blog/msa-1day-ws/)   \n\n[MSA 도입, AI로 혁신을 경험하세요: MSA Conveyor Belt 1 Day Workshop](https://www.msap.ai/blog-home/blog/msa-1day-ws/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T14:35:10+09:00 2025년 05월 20일|\n\n[Read More](https://www.msap.ai/blog-home/blog/msa-1day-ws/)\n\n![Image 9: MSAP.ai](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_gray_h40.webp)\n\n엠에스에이피닷에이아이 | MSAP.ai\n\n주소: 경기 성남 분당 성남대로 331번길 11-3, 5층\n\n (정자동, 여민빌딩)\n\n 메일: [hello@msap.ai](mailto:hello@msap.ai)\n\n[MSAP.ai](https://www.msap.ai/msap-ai/)\n\n[MSA Accelerator](https://www.msap.ai/msap-ai/msa-accelerator/)\n\n[PLATFORM](https://www.msap.ai/msap-ai/platform/)\n\n[AI](https://www.msap.ai/msap-ai/ai-as-a-service/)\n\n[HARDWARE](https://www.msap.ai/msap-ai/hardware/)\n\n[MSAP.ai 제품문의](https://www.msap.ai/msap-ai/solution-contact/)\n\n[컨설팅](https://www.msap.ai/consulting/)\n\n[MSA 특화 컨설팅](https://www.msap.ai/consulting/msa-special-consulting/)\n\n[MSA 설계 및 플랫폼 구축](https://www.msap.ai/consulting/msa-design-platform-deployment/)\n\n[클라우드 네이티브 전환 진단 컨설팅](https://www.msap.ai/consulting/cloud-native-transition-diagnostic-consulting/)\n\n[MSA 전환, IT 현황 진단 서비스](https://www.msap.ai/consulting/msa-it-assessment/)\n\n[MSA Conveyor Belt Workshop 신청](https://www.msap.ai/consulting/msa-workshop/)\n\n[교육](https://www.msap.ai/training/)\n\n[MSA 특화 교육](https://www.msap.ai/training/msa-special-training/)\n\n[MSA 개념과 패턴 교육](https://www.msap.ai/training/msa-concept-pattern-training/)\n\n[찾아가는 MSA & 클라우드 네이티브 세미나](https://www.msap.ai/training/free-cloud-native-seminar/)\n\n[이벤트 & 세미나](https://www.msap.ai/event-seminar/)\n\n[이벤트](https://www.msap.ai/event-seminar/event/)\n\n[세미나](https://www.msap.ai/event-seminar/seminar/)\n\n[블로그](https://www.msap.ai/blog/)\n\n[자료실](https://www.msap.ai/resource/)\n\n[공지사항](https://www.msap.ai/resource/notice/)\n\n[eBooks](https://www.msap.ai/docs/msa-expert-from-concepts-to-practice/)\n\n[Datasheet](https://www.msap.ai/resource/datasheet/)\n\n[Whitepaper](https://www.msap.ai/resource/whitepaper/)\n\n[Solution Briefs](https://www.msap.ai/resource/solution-briefs/)\n\n[Case Studies](https://www.msap.ai/resource/case-studies/)\n\n[Presentation](https://www.msap.ai/resource/presentation/)\n\n[Webinars](https://www.msap.ai/resource/webinars/)\n\n[기술지원](https://www.msap.ai/support/)\n\n[회사](https://www.msap.ai/company/)\n\n[사업영역](https://www.msap.ai/company/business-domain/)\n\n[기업연혁](https://www.msap.ai/company/history/)\n\n[BI 소개](https://www.msap.ai/company/msap-ai-bi-introduce/)\n\n[오시는길](https://www.msap.ai/company/location/)\n\n[MSAP.ai 굿즈 스토어](https://www.msap.ai/goods/)\n\nCopyright 2023 – 2024 MSAP.ai All rights reserved.\n\nCreated by Danny\n\n[Page load link](https://www.msap.ai/blog/exaone-lg-llm/#)[Go to Top](https://www.msap.ai/blog/exaone-lg-llm/#)![Image 10](https://pixel.wp.com/g.gif?v=ext&blog=240426082&post=5690&tz=9&srv=www.msap.ai&j=1%3A14.7&host=www.msap.ai&ref=&fcp=1868&rand=0.40940295582559827)\n"
    },
    {
        "url": "https://m.blog.naver.com/dh0985/222596386636",
        "title": "[AI 스터디] LG 초거대언어모델 EXAONE 1편 - 네이버 블로그",
        "content": "- 이를 위해 세계최대 규모에 달하는 2억 5천만장(250M) 이미지-텍스트 Pair 데이터를 사용. 방대한 데이터 학습을 통해 EXAONE은 이미지와 텍스트 간 자유로운 양방향 생성이 가능해짐. 또한, 6000억개(600B) 한국어, 영어 말뭉치 토큰을 학습에 사용. 여기서 한국어 데이터에 국한되지 않음을 강조했음. 데이터 학습과정에서 LG가 보유한 전문 데이터를 사용했고 지속적으로 추가하는 중\n\n​\n\n​\n\n​\n\n2) 파라미터 규모 [...] - LG AI 연구원은 여러 계열사와 함께 양극제, 친환경 촉매와 같은 AI 기반 신소재, 신물질 발굴 과제를 진행하고 있음. 신소재 발굴 AI의 학습을 위해선 전공자가 특허나 논문 전체를 읽고 해당 내용을 요약해서 데이터베이스에 입력해야 함. 문서의 그림 분자, 구조식, 테이블 등을 읽고 전체 컨텍스를 이해하기 때문에 현재는 대부분 수작업으로 이뤄지고 있음. 고급 전문 인력이 물질 데이터 입력에 많은 시간을 쓰고 있는 상황임\n\n​\n\n- EXAONE은 전국 문헌의 전체 컨텍스트를 이해해 대규모의 물질 데이터를 효과적으로 추출하는 것이 가능함. 구체적으로 지난 100년 간 발간된 모든 논문들의 물질 정보를 데이터베이스화하고 이로부터 신소재 신물질 발굴 AI가 새로운 인사이트를 발견해내는 작업을 진행할 예정임. 이런 방대한 자료를 이해하고 지식을 끌어내는 것은 인간 전문가라고 해도 감당하기 어려운 일이며 멀티모달 초거대 AI가 진정 그 빛을 발하는 지점이라 할 수 있겠음 [...] - 아래는 파라미터 증가단계를 나타내는 그래프. 현재 국내 최대 규모인 3000억개 파라미터 모델을 학습중에 있음. EXAONE의 벤치마크 결과는 이미 13억개, 130억개 모델 성능만으로도 GPT 수준을 넘어 최고 수준인 SOTA를 달성. 전문가 커뮤니케이션에서 가장 중요하다고 할 수 있는 목적 대화와 감성 분류 영역에서 최고 수준을 기록했을 뿐만 아니라 이미지 복원의 퀄리티를 보여주는 FID 스코어에서 최상위 점수를 기록하고 실제 애플리케이션에 활용 가능한 1024X1024 해상도로 이미지를 생성함. 아직 벤치마크 테스트 중인 1750억 개, 3000억 개 모델의 성능 측정이 완료되면 현재 기록한 최고 수준을 또다시 뛰어넘을 것이라고 확신\n\nImage 9\n\nImage 10\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n​\n\n3) EXAONE 프로젝트",
        "score": 0.77179235,
        "raw_content": "[AI 스터디] LG 초거대언어모델 EXAONE 1편 - LG엑사원 / LG AI 콘서트 / 멀티모달 / 전문가AI / 3000억개 파라미터 / LG AI 연구원 / GPT-3 : 네이버 블로그\n\n===============\n\n![Image 1](https://ssl.pstatic.net/static/blog/sp_blog72.png)![Image 2](https://ssl.pstatic.net/static/blog/sp_blog_se3_6.png)\n\n[로그인이 필요합니다.](https://m.blog.naver.com/dh0985/222596386636#)\n*   [내소식](https://m.blog.naver.com/News.naver)\n*   [이웃목록](https://m.blog.naver.com/GoMyBuddyList.naver)\n*   [통계](https://m.blog.naver.com/BlogStat.naver)\n*   클립만들기\n*   글쓰기\n\n_My Menu 닫기_\n\n[내 체크인](https://m.blog.naver.com/CheckIn.naver)[최근 본 글](https://m.blog.naver.com/ReadHistoryList.naver)[내 동영상](https://m.blog.naver.com/MyVideo.naver)[내 클립](https://m.blog.naver.com/ClipList.naver)\n\n* * *\n\n내 상품 관리 NEW[마켓 플레이스 NEW](https://m.blog.naver.com/MarketPlace.naver)[장바구니](https://m.blog.naver.com/Cart.naver)[마켓 구매내역](https://new-m.pay.naver.com/historybenefit/paymenthistory)\n\n* * *\n\n[블로그팀 공식블로그 NEW](https://m.blog.naver.com/PostList.naver?blogId=blogpeople)[이달의 블로그](https://m.blog.naver.com/PopularBlog.naver)[공식 블로그](https://m.blog.naver.com/OfficialBlog.naver)블로그 앱\n\n* * *\n\n로그인[PC버전으로 보기](https://blog.naver.com/dh0985/222596386636?viewType=pc)[블로그 고객센터](https://help.naver.com/alias/blog/etc/bl_code_01.naver)\n\n![Image 3: 섬네일](https://m.blog.naver.com/dh0985/222596386636)\n\n[ⓒ NAVER Corp.](https://www.navercorp.com/)\n\n[본문 바로가기](https://m.blog.naver.com/dh0985/222596386636#ct)\n\n[블로그](https://m.blog.naver.com/Recommendation.naver)\n====================================================\n\n[카테고리 이동](https://m.blog.naver.com/dh0985/222596386636#)[모두가 함께하는 여행](https://m.blog.naver.com/PostList.naver?blogId=dh0985)\n----------------------------------------------------------------------------------------------------------------------------\n\n[검색](https://m.blog.naver.com/PostSearchList.naver?blogId=dh0985)MY메뉴 열기\n\n[AI/클라우드/IT](https://m.blog.naver.com/PostList.naver?blogId=dh0985&categoryNo=16&logCode=0&categoryName=AI%2F%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C%2FIT#postlist_block)\n\n[AI 스터디] LG 초거대언어모델 EXAONE 1편 - LG엑사원 / LG AI 콘서트 / 멀티모달 / 전문가AI / 3000억개 파라미터 / LG AI 연구원 / GPT-3\n\n[![Image 4: 프로필](https://blogpfthumb-phinf.pstatic.net/MjAyNDA1MDZfMjky/MDAxNzE0OTY4NDI1NDQw.OEIs7f5QGFviN3HP5NHzrJe16rLZxQLGy8q1pL1JOH8g.21lbBSbqDaWreixSeji-YLhG2LwEm6tHm4A0vxCJYIcg.JPEG/profileImage.jpg?type=s1)](https://m.blog.naver.com/PostList.naver?blogId=dh0985)\n\n[**레드블루**](https://m.blog.naver.com/PostList.naver?blogId=dh0985)\n\n2021. 12. 16. 8:00\n\n[이웃추가](https://m.blog.naver.com/dh0985/222596386636#)\n\n본문 기타 기능\n\n*   **본문 폰트 크기 조정**본문 폰트 크기 작게 보기 본문 폰트 크기 크게 보기 가\n*   [_공감하기_](https://m.blog.naver.com/dh0985/222596386636#)  \n*   [공유하기](https://m.blog.naver.com/dh0985/222596386636#)\n*   [URL복사](https://m.blog.naver.com/dh0985/222596386636#)\n*   [신고하기](https://m.blog.naver.com/dh0985/222596386636#)\n\n> **1. 키노트**\n\n**(1) 연구배경 및 목표**\n\n​\n\n- 20년 12월 LG AI 연구원이 출범한 뒤 21년 12월까지 1년간 글로벌 탑티어 학계 기준으로 **총 18건의 논문이 채택**. LG AI 연구원의 장점은 **다양한 업종의 계열사와 협력이 가능**하다는 점. 이를 통해 연구 성과를 비즈니스에 바로 접목할 수 있으며 기업 경쟁력의 근간이 되는 산업문제 해결에 AI를 활용할 수 있음\n\n​\n\n- 구체적으로 전자, 화학, 통신서비스 계열사들의 전 산업 밸류체인에 걸쳐 실질적인 변화를 만들어내고 있음. 수치로 볼때 지난 1년간 사업적 임팩트가 크고 난이도가 높은 **18건의 난제를 해결**해 약 **2천억원 이상의 사업적 가치** 창출. 22년에는 **25건 이상의 난제**에 도전할 예정\n\n![Image 5](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfNjEg/MDAxNjM5NTY5OTQ0MDIx.7WmQq4yKJIcP1Gm47VmT8VF_ZfNSF0K_T7e07xrkBiQg.RGdiezTueMdB3etKBFv4X-JwonEyiz9rlRT4kdalcLgg.PNG.dh0985/image.png?type=w800)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n​\n\n- 산업에는 아래의 그림처럼 크게 다음의 4가지 영역에 도전\n\n​\n\n**1) 개인 맞춤형 항암 치료제 개발 :**\n\n연구진은 트랜스포머 셀프어텐션 매커니즘을 활용해 높은 정확도의 예측 모델을 개발했음. 환자마다 다르게 나타나는 암세포의 돌연변이에 대응할 수 있는 치료제의 후보 물질을 찾아주는 모델로 이는 개인 맞춤형 항암 치료제 개발의 핵심 요소가 될 것\n\n​\n\n**2) MRC(Machine Reading Comprehension) 기술 챗봇 플랫폼 탑재 :**\n\nMRC 기술이 그룹 챗봇 플랫폼 탑재 되어 전 계열사 임직원이 사용을 시작했고 조만간 고객 여러분에게도 서비스되리라 기대됨\n\n​\n\n3) **딥러닝 기반 수요 예측 :**\n\n기업의 수요예측의 경우 데이터가 적어 기존의 단순한 머신러닝이나 규칙기반에 의존하는 경우가 많았는데 최신 딥러닝 기술을 적용해 기존 방식보다 적은 수의 데이터로 높은 성능을 달성하는 혁신을 이뤄냄\n\n​\n\n**4) 비전검사 최신기술 도입 :**\n\n최근 비전분야에서도 비지도학습을 성공적으로 적용하는 성과를 이뤘음. 기존에도 비지도학습을 적용한 사례는 일부 있었지만, 지도학습을 뛰어넘는 성능으로 비지도학습을 상용화한건 LG가 최초임\n\n![Image 6](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfODUg/MDAxNjM5NTcwNjYwNTMy.8PpXzvR8nE-DLWGqvtb39_YQR7Mslzm1FEU6teQjmmEg.XwG-E743m_w_RuGBCBZTOBnCF9DWrxAYjPhn_VD4x-og.PNG.dh0985/image.png?type=w800)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n- LG의 목표는 AI를 통해서 고객에게 수준높은 전문가 서비스를 저렴하게 제공하는것. 고객은 **나만의 회계사, 나만의 의사, 나만의 변호사, 나만의 쇼핑 큐레이터**를 만날 수 있을것. 이렇게 된다면 인간은 좀 더 창조적인 영역에 집중할 수 있게되고 우리의 삶은 더욱 가치를 가질것. 이는 LG 초거대 AI 모델이 **상위 1% 수준의 전문가 AI를 지향**하는 이유\n\n* * *\n\n**(2) 초거대 AI -****EXAONE**\n\n![Image 7](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjU3/MDAxNjM5NTcwNzAyMDE3.BuDdvxz5MWuiSdQSWUGG8--7UWq0Z3siL_lSG6A3HmEg.peH0QJg8zeFrw839nPiVL6aLssuSb57T9v4aRLB9afgg.PNG.dh0985/image.png?type=w80_blur)\n\n**출처 : LG AI Talk Concert (youtube)**\n\n**​**\n\n**​**\n\n**1) 멀티모달 AI 모델**\n\n- 언어와 시각정보를 모두 다룰 수 있다는 점에서 지금까지의 언어모델과 차별화됨. **인간이 얻는 외부 정보 가운데 가장 큰 비중을 차지하는 것은 시각을 통한 정보**. 따라서 인간에게 실질적으로 도움을 줄 수 있는 전문가 AI는 반드시 시각정보를 이해하고 표현할 수 있어야함. LG 연구원은 이미지를 텍스트로 표현하고, 텍스트를 이미지로 시각화하는 능력을 갖추는 것이 다음 단계 초거대 AI 모델로 발전하기 위한 필수요소라고 판단\n\n![Image 8](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTE2/MDAxNjM5NTcwNzI4MTE1.mXa4AMD9Lyys30LVKalIUKftDEQUoee-l01aJ1CQaYMg._Pzk-crCkCrH5Ub_DV-0ELvmcoclUWDrmOnJFhX6ZI4g.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n​\n\n- 이를 위해 세계최대 규모에 달하는 **2억 5천만장(250M)** 이미지-텍스트 Pair 데이터를 사용. 방대한 데이터 학습을 통해 **EXAONE**은 이미지와 텍스트 간 자유로운 양방향 생성이 가능해짐. 또한, **6000억개(600B)** 한국어, 영어 말뭉치 토큰을 학습에 사용. 여기서 한국어 데이터에 국한되지 않음을 강조했음. 데이터 학습과정에서 LG가 보유한 전문 데이터를 사용했고 지속적으로 추가하는 중\n\n​\n\n​\n\n​\n\n**2) 파라미터 규모**\n\n- 아래는 파라미터 증가단계를 나타내는 그래프. 현재 국내 최대 규모인 **3000억개 파라미터 모델**을 학습중에 있음. **EXAONE**의 벤치마크 결과는 이미 13억개, 130억개 모델 성능만으로도 GPT 수준을 넘어 최고 수준인 **SOTA를 달성**. 전문가 커뮤니케이션에서 가장 중요하다고 할 수 있는 목적 대화와 감성 분류 영역에서 최고 수준을 기록했을 뿐만 아니라 이미지 복원의 퀄리티를 보여주는 FID 스코어에서 최상위 점수를 기록하고 실제 애플리케이션에 활용 가능한 1024X1024 해상도로 이미지를 생성함. 아직 벤치마크 테스트 중인 1750억 개, 3000억 개 모델의 성능 측정이 완료되면 **현재 기록한 최고 수준을 또다시 뛰어넘을 것이라고 확신**\n\n![Image 9](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTE5/MDAxNjM5NTcwNzk1ODEy.n46-4vlkj2XOrfQC4PBhRzb0pSYiJGj3_dvJsk4z34Mg.5jmf96DIyImmAX35Sfp3NokNTxvT-tMguBwwRPHS2Kcg.PNG.dh0985/image.png?type=w80_blur)\n\n![Image 10](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTA5/MDAxNjM5NTcwODQxOTQ1.N1Gi0W61hsj6P_JmxOQ2svXK3nRG5KO0ETjRwqbA38gg.Lq2SUqAd_UTWihW9iogRPEizn8SCe8x7jEatDx9Zh0Ag.PNG.dh0985/image.png?type=w80_blur)\n\n**출처 : LG AI Talk Concert (youtube)**\n\n**​**\n\n**​**\n\n**3) EXAONE 프로젝트**\n\n- LG AI 연구원은 여러 계열사와 함께 양극제, 친환경 촉매와 같은 AI 기반 신소재, 신물질 발굴 과제를 진행하고 있음. 신소재 발굴 AI의 학습을 위해선 전공자가 **특허나 논문 전체를 읽고 해당 내용을 요약해서 데이터베이스에 입력해야 함**. 문서의 그림 분자, 구조식, 테이블 등을 읽고 전체 컨텍스를 이해하기 때문에 현재는 **대부분 수작업**으로 이뤄지고 있음. 고급 전문 인력이 물질 데이터 입력에 많은 시간을 쓰고 있는 상황임\n\n​\n\n- **EXAONE**은 전국 문헌의 전체 컨텍스트를 이해해 대규모의 물질 데이터를 효과적으로 추출하는 것이 가능함. 구체적으로 지난 **100년 간 발간된 모든 논문들의 물질 정보를 데이터베이스화**하고 이로부터 신소재 신물질 발굴 AI가 새로운 인사이트를 발견해내는 작업을 진행할 예정임. 이런 방대한 자료를 이해하고 지식을 끌어내는 것은 인간 전문가라고 해도 감당하기 어려운 일이며 멀티모달 초거대 AI가 진정 그 빛을 발하는 지점이라 할 수 있겠음\n\n![Image 11](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjU1/MDAxNjM5NTcwODgzNzQw.5v9N4bXenDwM5JNQ1QUOpVG5x9bGb9NAFY_zl9TbnFkg.HIgDp5_Ia0RB1X1khT2H0lJdzz5zRDLOOg6f8yrgNqAg.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n​\n\n- 또한, **EXAONE**은 언어 이미지뿐만 아니라 **소리, 영상, 촉감 등 인간의 다양한 감각 기관을 통합한 진정한 멀티모달 AI**로 나아가고자 함. 아바타, AI휴먼, 메타버스와 연계해 새로운 세상을 열것으로 기대하고 있음. 이를 위해선 다양한 모달리티를 동시에 받아들이고 사고할 줄 아는 멀티모달 AI가 필수적인 요건\n\n![Image 12](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTUx/MDAxNjM5NTcwOTAzNTk0.ajNa0Ra3Q3KNe8cJIAEPfRFL8ZbDJ5gFsH-yBKMsDvAg.t74VprbQMyh7zmT6diVGbr-MIiZseKZqy-qJ2T2qLd8g.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n**​**\n\n**​**\n\n**4) EXAONE 생태계 구축**\n\n- 초거대 AI 활용방안은 무궁무진하므로 집단지성을 활용해 **EXAONE**의 생태계를 만들어 나갈것. 이를 위해 외부에서도 사용가능한 API를 준비하고 있음. 생태계 구축의 첫단계는 LG 계열사에 초거대 AI를 배포해 그 가능성을 확인하는 것. 몇몇 계열사의 경우 **22년 프로젝트에 초거대 AI를 투입할 계획이 수립**되어 있음. 이후 개발환경과 지원시스템을 마련해 단계별로 공개할 계획\n\n![Image 13](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjA2/MDAxNjM5NTcwOTgyMTEx.2a1GCoGala4jZcuAJRPsh6xy7yvjAsqNfKpyKKj86NQg.429hj5ZyTfkP1ll-DhDkm56fcXsHXPSr0NzVdP5XVTsg.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : LG AI Talk Concert (youtube)\n\n​\n\n​\n\n- 초거대 AI 모델에는 대규모 인프라가 필수적. 이를 위해 **1초당 9.6경번 연산이 가능한 슈퍼컴퓨터 인프라**를 구축했음. 22년에는 이를 **두 배****(1초에 20경번 연산)**로 확대할 계획. 초거대 AI 모델은 API 서비스를 위한 추론에도 많은 연산이 요구되기 때문에 학습인프라 이외에도 대규모 활용 인프라가 필수적. 이를 위해 **EXAONE** 활용 인프라의 규모를 최적화하기 위해서 **EXAONE** inference 프레임워크라는 병렬처리 구조를 새롭게 디자인\n\n(참고)\n\n* 네이버는 700 페타플롭스 **(1초에 70경번 연산)**\n\n* 테슬라는 1.8 엑사플롭스 **(1초에 180경번 연산)**\n\n​\n\n​\n\n- 생태계 구축의 다음 단계는 전략적 파트너사와의 협업. **EXAONE**과 결합해 높은 시너지가 예상되는 기업들과 전략적 파트너십을 수립해 AI 얼라이언스를 구축하고 있고, 파트너사와의 협업을 고려해 **EXAONE** 튜닝이라는 특화된 기능을 탑재함. 이를 통해 파트너사의 **비밀 데이터를 외부에 노출하지 않으면서** 파트너사가 자신의 활용 목적에 맞게 초거대 AI 모델을 활용할 수 있음\n\n​\n\n- 고객들에게 **EXAONE**을 오픈하기 위해선 **추론 인프라를 보강해야 하고 과금 체계도 고민**해야함. 사용자의 부담을 덜기 위한 최적화와 경량화 연구에도 많은 노력이 필요함. LG는 이러한 고민들을 체계적으로 정리해나가고 있으며 정부에서도 다양한 지원을 준비하고 있는만큼 **EXAONE**의 확산에 도움이 될 것으로 예상함. 내년 상반기중 1단계 API 오픈과 함께 전반적인 생태계 전략을 공개하는 발표를 준비하고 있음\n\n​\n\n​\n\n​\n\n> **2. 느낀점**\n\n**(인상적인 포인트)**\n\n- 최근 본 AI 컨퍼런스 중 가장 기억에 남는다. 국내 최초로 초거대언어모델을 공개한 네이버에 이어서 파라미터 3000억개 규모의 빅모델을 내놓은 LG. **여러 국내 대기업 중 적극적인 스탠스를 보여준 LG**였기에 슈퍼컴퓨팅 등의 인프라를 갖추고 계열사와의 협업을 통해 AI 연구를 진행하며 파라미터 기준으로 글로벌 티어인 AI 모델을 공개할 수 있었지 않나싶다\n\n​\n\n- SKT AI 연구와 유사하게 LG연구원의 **EXAONE**은 LG 그룹 계열사와의 협업이 가능하다는 점에서 데이터확보와 테스트에 있어 유리하다. SKT가 SK하이닉스와 협업해 반도체 연구에 AI를 적용한 사례처럼 LG 또한 앞으로 **LG유플러스, LG에너지솔루션, LG디스플레이, LG전자** 등 여러 계열사들과의 협업을 통해 가치를 창출해 낼것으로 기대된다\n\n​\n\n- 일부지만 멀티모달이 가능하다는 점에서도 인상적이다. **네이버**가 공개한 하이퍼클로바의 경우 지난 네이버 AI 컨퍼런스 기준으로 텍스트기반으로만 학습이 진행돼 DALL-E의 기능을 구현할 수 없다. 반면에 **LG는 텍스트를 통해서 이미지를 만들어 낼 수 있는 멀티모달 언어모델이며, DALL-E 보다 한발 더 나아가 이미지에서 텍스트를 생성하는 기능또한 추가했다**. 물론, 네이버의 경우 AI팀 리더인 하정우님이 최근 밝힌것처럼 멀티모달을 추구하고 있다. 여기서 포인트는 LG가 최근 언어모델 트렌드를 잘 따라가고 있다 정도로 해석하면 되겠다\n\n* * *\n\n**(AI 플랫폼 경쟁)**\n\n- AI 생태계를 중시한다고 밝힌 점과, 외부로의 AI 빅모델 검토를 계획하고 있다는 점에서 향후 국내를 포함해 글로벌하게 **AI 플랫폼 경쟁이 있을것**이라 예상된다. 한국어 데이터 위주로 학습한 네이버와는 달리 영어또한 한국어만큼 상당히 학습했다는 점또한 LG가 세계무대 공략을 계획하고 있음을 알 수 있는 부분이다. 그러나, 영어권 시장을 공략한다고 할 때 이미 상당히 높은 클라우드 점유율을 가진 **MS(Azure), Google(Google Cloud)**과 경쟁이 가능할지는 앞으로 지켜봐야할 부분이라 생각된다(단, 클라우드 경쟁이 아니라 해외기업과의 얼라이언스가 목적이라면 또 다르겠다)\n\n* * *\n\n**(빅모델 트렌드)**\n\n- 최근의 빅모델 트렌드는 두 가지다. **첫번째로 파라미터를 키울수록 모델의 성능이 증가한다**. LG는 **6000억**개 파라미터를 가진 AI 모델을 공개한다고 했으며, 얼마전에는 **엔비디아와 MS**가 협업해 **5300억개** 파라미터를 가진 메가트론을 세상에 내놨다. 개인적으로 openAI의 다음 빅모델인 GPT-4의 등장이 기다려지며 조단위의 파라미터를 가진 언어모델이 나온다면 어떤 성능의 발전이 있을지도 매우 기대가 되는 상황이다\n\n​\n\n- **두번째로 조금 더 효율적인 빅모델이 등장하고 있다**. 최근 **구글 딥마인드**가 발표한 **Gopher 언어모델**은 **2800억개**의 파라미터를 가진다. **GPT-3**와 비교해 약간의 파라미터 수 증가지만 성능 향상은 더욱 가파른 모습을 보여준다. 단순히 크기만 키운것이 아니라, 그 알맹이를 채우는 것에 많은 연구가 진행되고 있고 하나둘씩 결과로 나오고 있는 상황이다\n\n​\n\n- 남세동 대표님의 말처럼 AI가 Human Expert를 따라잡는 날이 올지, 온다면 언제일지, 과연 누가 그런 변화를 가져올지가 매우 궁금하다\n\n![Image 14](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMzEg/MDAxNjM5NTczMzIzOTc2.KQWa7vwD1c5JbuIoalOvYr2VKUoBhonYROozOoZlHfQg.tRDa0c9BJ1jlVsQqB22ThKZTcyigB8Ynl2E42RtPO5gg.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : 페이스북 (남세동 대표님)\n\n* * *\n\n**(소프트웨어 2.0 시대)**\n\n- 딥러닝을 바탕으로한 소프트웨어 2.0 시대는 이제 막 시작됐다. 초거대언어모델의 연구과정을 **신대륙을 찾는 거대한 모험**에 비유한 LG 연구원의 표현처럼, 앞으로 마주하게 될 결과는 생각보다 더 크고 우리의 삶에 지대한 영향을 미치게 될지도 모른다. 그런점에서 작은 우리나라에 이렇게 큰 모델을 선보일 수 있는 기업들이 존재한다는게 정말 다행이라 생각된다. **아메리카 대륙의 발견으로 미국이라는 국가가 등장할 수 있었던 것처럼, 인공지능이 발전이 앞으로 어떤 의미를 가져올지 매우 기대되는 순간이다**\n\n![Image 15](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjgg/MDAxNjM5NTczNzA2MjYw.DnzRxnqer11_Scxh92Qdj96bMfrWCXIFrhOz15LUgQIg.1hIeZefaeOmvWTo2aOnsqVABlWopRrOclHNR9xPIolAg.PNG.dh0985/image.png?type=w80_blur)\n\n출처 : Ark invest\n\n​\n\n*   [#LG초거대언어모델](https://m.blog.naver.com/BlogTagView.naver?orderType=date&tagName=LG%EC%B4%88%EA%B1%B0%EB%8C%80%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8)\n*   [#LGEXAONE](https://m.blog.naver.com/BlogTagView.naver?orderType=date&tagName=LGEXAONE)\n*   [#LG엑사원](https://m.blog.naver.com/BlogTagView.naver?orderType=date&tagName=LG%EC%97%91%EC%82%AC%EC%9B%90)\n*   [#EXAONE](https://m.blog.naver.com/BlogTagView.naver?orderType=date&tagName=EXAONE)\n*   [#엑사원](https://m.blog.naver.com/BlogTagView.naver?orderType=date&tagName=%EC%97%91%EC%82%AC%EC%9B%90)\n*   +25\n\n[](https://m.blog.naver.com/dh0985/222596386636#)\n\n[공감한 사람 보러가기](https://m.blog.naver.com/SympathyHistoryList.naver?blogId=dh0985&logNo=222596386636&categoryId=POST)\n\n[댓글 _6_](https://m.blog.naver.com/CommentList.naver?blogId=dh0985&logNo=222596386636)공유하기\n\n[![Image 16: 프로필](https://blogpfthumb-phinf.pstatic.net/MjAyNDA1MDZfMjky/MDAxNzE0OTY4NDI1NDQw.OEIs7f5QGFviN3HP5NHzrJe16rLZxQLGy8q1pL1JOH8g.21lbBSbqDaWreixSeji-YLhG2LwEm6tHm4A0vxCJYIcg.JPEG/profileImage.jpg?type=s1)](https://m.blog.naver.com/dh0985)\n\n이웃추가\n\n[**레드블루** 비즈니스·경제 이웃 1,003 명 비대칭적 투자를 추구합니다. 한 걸음씩 성장해 나가는 오늘](https://m.blog.naver.com/dh0985)\n\n{\"title\":\"[AI 스터디] LG 초거대언어모델 EXAONE 1편 - LG엑사원 / LG AI 콘서트 / 멀티모달 / 전문가AI / 3000억개 파라미터 / LG AI 연구원 / GPT-3\",\"source\":\"https://blog.naver.com/dh0985/222596386636\",\"blogName\":\"모두가 함..\",\"domainIdOrBlogId\":\"dh0985\",\"nicknameOrBlogId\":\"레드블루\",\"logNo\":222596386636,\"smartEditorVersion\":4,\"meDisplay\":true,\"lineDisplay\":true,\"outsideDisplay\":true,\"cafeDisplay\":true,\"blogDisplay\":true}\n\n[닫기](https://m.blog.naver.com/dh0985/222596386636#)\n\n카테고리\n----\n\n[이 블로그 홈](https://m.blog.naver.com/dh0985)\n\n[](https://m.blog.naver.com/dh0985/222596386636#)\n\n[공감한 사람 보러가기](https://m.blog.naver.com/SympathyHistoryList.naver?blogId=dh0985&logNo=222596386636&categoryId=POST)\n\n[댓글 _6_](https://m.blog.naver.com/CommentList.naver?blogId=dh0985&logNo=222596386636)[공유하기](https://m.blog.naver.com/dh0985/222596386636#)\n\n**레드블루(dh0985)**님을 이웃추가하고 새글을 받아보세요\n\n[취소](https://m.blog.naver.com/dh0985/222596386636#)[이웃추가](https://m.blog.naver.com/dh0985/222596386636#)\n\n[닫기](https://m.blog.naver.com/dh0985/222596386636#)[공유](https://m.blog.naver.com/dh0985/222596386636#)\n\n[**0** / 0](javascript:void(0);)\n\n![Image 17](https://m.blog.naver.com/dh0985/222596386636)\n\n![Image 18](https://m.blog.naver.com/dh0985/222596386636)\n\n![Image 19](https://m.blog.naver.com/dh0985/222596386636)\n\n[](https://m.blog.naver.com/dh0985/222596386636#)\n\n[](https://m.blog.naver.com/dh0985/222596386636#)\n\n*   [![Image 20](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfNjEg/MDAxNjM5NTY5OTQ0MDIx.7WmQq4yKJIcP1Gm47VmT8VF_ZfNSF0K_T7e07xrkBiQg.RGdiezTueMdB3etKBFv4X-JwonEyiz9rlRT4kdalcLgg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 21](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfODUg/MDAxNjM5NTcwNjYwNTMy.8PpXzvR8nE-DLWGqvtb39_YQR7Mslzm1FEU6teQjmmEg.XwG-E743m_w_RuGBCBZTOBnCF9DWrxAYjPhn_VD4x-og.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 22](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjU3/MDAxNjM5NTcwNzAyMDE3.BuDdvxz5MWuiSdQSWUGG8--7UWq0Z3siL_lSG6A3HmEg.peH0QJg8zeFrw839nPiVL6aLssuSb57T9v4aRLB9afgg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 23](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTE2/MDAxNjM5NTcwNzI4MTE1.mXa4AMD9Lyys30LVKalIUKftDEQUoee-l01aJ1CQaYMg._Pzk-crCkCrH5Ub_DV-0ELvmcoclUWDrmOnJFhX6ZI4g.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 24](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTE5/MDAxNjM5NTcwNzk1ODEy.n46-4vlkj2XOrfQC4PBhRzb0pSYiJGj3_dvJsk4z34Mg.5jmf96DIyImmAX35Sfp3NokNTxvT-tMguBwwRPHS2Kcg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 25](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTA5/MDAxNjM5NTcwODQxOTQ1.N1Gi0W61hsj6P_JmxOQ2svXK3nRG5KO0ETjRwqbA38gg.Lq2SUqAd_UTWihW9iogRPEizn8SCe8x7jEatDx9Zh0Ag.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 26](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjU1/MDAxNjM5NTcwODgzNzQw.5v9N4bXenDwM5JNQ1QUOpVG5x9bGb9NAFY_zl9TbnFkg.HIgDp5_Ia0RB1X1khT2H0lJdzz5zRDLOOg6f8yrgNqAg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 27](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMTUx/MDAxNjM5NTcwOTAzNTk0.ajNa0Ra3Q3KNe8cJIAEPfRFL8ZbDJ5gFsH-yBKMsDvAg.t74VprbQMyh7zmT6diVGbr-MIiZseKZqy-qJ2T2qLd8g.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 28](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjA2/MDAxNjM5NTcwOTgyMTEx.2a1GCoGala4jZcuAJRPsh6xy7yvjAsqNfKpyKKj86NQg.429hj5ZyTfkP1ll-DhDkm56fcXsHXPSr0NzVdP5XVTsg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 29](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMzEg/MDAxNjM5NTczMzIzOTc2.KQWa7vwD1c5JbuIoalOvYr2VKUoBhonYROozOoZlHfQg.tRDa0c9BJ1jlVsQqB22ThKZTcyigB8Ynl2E42RtPO5gg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n*   [![Image 30](https://mblogthumb-phinf.pstatic.net/MjAyMTEyMTVfMjgg/MDAxNjM5NTczNzA2MjYw.DnzRxnqer11_Scxh92Qdj96bMfrWCXIFrhOz15LUgQIg.1hIeZefaeOmvWTo2aOnsqVABlWopRrOclHNR9xPIolAg.PNG.dh0985/image.png?type=f100_webp)](https://m.blog.naver.com/dh0985/222596386636#) \n\n닫기\n\n![Image 31](https://m.blog.naver.com/dh0985/222596386636)\n"
    }
]