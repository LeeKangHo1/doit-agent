[
    {
        "url": "https://elice.io/ko/newsroom/elice-korean-qwen2.5",
        "title": "한국어 특화 LLM, 엘리스 Korean Qwen2.5 모델 리뷰 (32B/72B) - Elice",
        "content": "### 다른 한국어 특화 모델들과 비교해보면?\n\n유사한 서비스인 Exaone, SOLAR와 비교해보았을때도 엘리스의 Qwen2.5 모델은 단순한 “한국어 특화”를 넘어, 다목적 AI 성능에서도 두각을 나타냅니다.  \nElice Qwen2.5-32B 모델과 Exaone, SOLAR 모델의 영어 MMLU, 한국어 KMMLU, GSM8K, HumanEval, BBH 성능 비교  \nExaone, SOLAR도 우수한 서비스이나 엘리스 Qwen2.5는 영어와 한국어 모두에서 높은 일관성과 성능을 보여주고 있다는 것을 알 수 있습니다.\n\nElice Qwen2.5-32B 모델과 Exaone, SOLAR 모델의 영어 MMLU, 한국어 KMMLU, GSM8K, HumanEval, BBH 성능 비교\n\n### 실제 서비스에는 어떻게 활용되고 있을까?\n\n이미 엘리스는 해당 모델을 일부 제품 및 서비스에 직접 사용하고 있습니다.\n\n#### 실무 적용을 고려하는 개발자에게 중요한 포인트 [...] ### 마무리: 실험은 끝났고, 이제 실전이다\n\n지금까지 엘리스 Korean Qwen2.5 모델의 구조, 성능, 실제 적용 사례를 살펴봤습니다.\n\n이런 결과는 ‘한국어 AI는 영어 모델의 하위 옵션’이라는 인식을 넘어 한국어에 맞는 모델을 선택하는 시대가 되었다는 것을 보여주는 사례라고 생각합니다.\n\n엘리스 Korean Qwen2.5 모델(32B / 72B)은 개발자 누구나 엘리스클라우드 모델 라이브러리를 통해 직접 프롬프트를 입력해보고 결과를 확인할 수 있는 환경이 준비되어 있습니다.\n\n“한국어 LLM을 직접 만져보고 싶은데 어디서부터 시작하지?”  \n라는 고민이 있었다면, 지금이 가장 적절한 타이밍일지도 모릅니다.\n\n이 외에도 엘리스클라우드 모델 라이브러리에는 다양한 모델들이 준비되어 있으니, 관심 있는 분들은 무료로 사용해보셔도 좋을 것 같습니다.\n\n엘리스클라우드 모델 라이브러리\n\n엘리스클라우드 모델 라이브러리\n\n👉 엘리스클라우드에서 Qwen2.5 시작하기 [...] 많은 글로벌 AI 모델들이 다국어(Multilingual)을 표방하지만, 실제 사용에 있어서는 아쉬운 상황이 종종 발생하곤 합니다.  \n예를 들어 영어 중심으로 학습된 GPT나 Mistral 기반 모델들은 한국어로 질문을 해도 영어로 답변을 줄 때가 있죠.  \n이런 언어 전환 오류(language switching error)는 실제 챗봇 서비스나 검색 기반 QA 시스템에 있어서는 큰 장애가 될 수 있습니다.\n\n엘리스의 Korean Qwen2.5는 이 문제를 정면 돌파하여 실제로 약 10%까지 발생하던 언어 스위칭 오류를 0% 수준으로 감소시켰습니다.\n\n### Qwen2.5는 어떤 모델인가요?\n\nQwen2.5는 알리바바에서 오픈소스로 공개한 고성능 LLM 모델입니다. 엘리스는 이 모델을 한국어 특화 방향으로 커스터마이징하여 32B, 72B 두 가지 버전의 Instruct 모델을 최적화했습니다.\n\n### 모델 최적화 방법\n\n최적화를 위한 데이터는 아래와 같습니다.",
        "score": 0.6437107,
        "raw_content": "Hide for Today\n\nNVIDIA B200 사전예약 프로모션 OPEN\n\n극강 성능의 차세대 GPU, 지금 신청하세요!\n\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2795%27%20height=%2728%27/%3e)\n![Elice logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felice_logo.06b34994.png&w=256&q=75)\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2795%27%20height=%2728%27/%3e)\n![Elice logo](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Felice_logo.06b34994.png&w=256&q=75)\n\n# 한국어 특화 LLM, 엘리스 Korean Qwen2.5 모델 리뷰 (32B/72B)\n\nElice\n\n2025. 4. 2.\n\n### [**한국어에 특화된 LLM, 엘리스 Korean Qwen2.5 모델 리뷰 (32B/72B)**](#strong한국어에-특화된-llm-엘리스-korean-qwen25-모델-리뷰-32b72bstrong)\n\n혹시 GPT나 클로드 등을 사용하다 한글로 대화 중 영어로 답변을 받아 당황해본적이 있으신가요?  \n이처럼 오픈소스 LLM의 성능이 아무리 좋아도 한국어에 대한 이해가 부족하면 실서비스에 바로 활용하긴 어렵습니다.  \n그래서 이번에는 엘리스가 공개한 **한국어 특화 LLM, Korean Qwen2.5 Instruct** 모델의 성능을 리뷰해보고자 합니다.\n\n### [**왜 한국어 LLM이 따로 필요할까요?**](#strong왜-한국어-llm이-따로-필요할까요strong)\n\n많은 글로벌 AI 모델들이 다국어(Multilingual)을 표방하지만, 실제 사용에 있어서는 아쉬운 상황이 종종 발생하곤 합니다.  \n예를 들어 영어 중심으로 학습된 GPT나 Mistral 기반 모델들은 한국어로 질문을 해도 영어로 답변을 줄 때가 있죠.  \n이런 언어 전환 오류(language switching error)는 실제 챗봇 서비스나 검색 기반 QA 시스템에 있어서는 큰 장애가 될 수 있습니다.\n\n엘리스의 Korean Qwen2.5는 이 문제를 정면 돌파하여 실제로 약 10%까지 발생하던 **언어 스위칭 오류를 0% 수준으로 감소**시켰습니다.\n\n### [**Qwen2.5는 어떤 모델인가요?**](#strongqwen25는-어떤-모델인가요strong)\n\nQwen2.5는 알리바바에서 오픈소스로 공개한 고성능 LLM 모델입니다. 엘리스는 이 모델을 한국어 특화 방향으로 커스터마이징하여 32B, 72B 두 가지 버전의 Instruct 모델을 최적화했습니다.\n\n### [**모델 최적화 방법**](#strong모델-최적화-방법strong)\n\n최적화를 위한 데이터는 아래와 같습니다.\n\n그리고 파인튜닝은 최신 정렬 기법을 활용했습니다.\n\n이러한 다단계 정렬 과정 덕분에 모델은 실제 맥락에 맞는 유용하고 안전한 출력을 만들어낼 수 있었습니다.\n\n### [**8개의 H100 GPU로 단 2일 만에 학습**](#strong8개의-h100-gpu로-단-2일-만에-학습strong)\n\n엘리스는 이런 고성능 모델을 고작 8개의 H100 GPU로 단 이틀 만에 학습을 마칠 수 있었습니다.  \n단순히 하드웨어의 힘만이 아니라, 효율적인 엔지니어링과 탄탄한 AI 개발 파이프라인이 있었기에 가능했던 결과죠. 가격 역시 합리적이라 (시간당 33,600원 수준) 진행하는 프로젝트 규모에 맞춰 유연한 구성이 가능합니다.\n\n### [**성능은 어느 정도일까요? (벤치마크 포함)**](#strong성능은-어느-정도일까요-벤치마크-포함strong)\n\n지금부터는 엘리스 Korean Qwen2.5 모델의 주요 성능 수치를 벤치마크하여 실제 성능을 한 번 살펴보겠습니다.  \n![3_1x.webp](https://cdn-cms.elice.io/elice-strapi/3_1x_383171c28c.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)  \n모든 항목에서 상당히 높은 점수를 기록하고 있으며, 특히 코딩과 수학 분야에서 성능이 높게 나온다는 것을 알 수 있습니다.\n\n![3_1x.webp](https://cdn-cms.elice.io/elice-strapi/3_1x_383171c28c.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)\n\n### [**다른 한국어 특화 모델들과 비교해보면?**](#strong다른-한국어-특화-모델들과-비교해보면strong)\n\n유사한 서비스인 Exaone, SOLAR와 비교해보았을때도 엘리스의 Qwen2.5 모델은 단순한 “한국어 특화”를 넘어, 다목적 AI 성능에서도 두각을 나타냅니다.  \n![Elice Qwen2.5-32B 모델과 Exaone, SOLAR 모델의 영어 MMLU, 한국어 KMMLU, GSM8K, HumanEval, BBH 성능 비교](https://cdn-cms.elice.io/elice-strapi/4_1x_1585b14ded.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)  \nExaone, SOLAR도 우수한 서비스이나 엘리스 Qwen2.5는 영어와 한국어 모두에서 높은 일관성과 성능을 보여주고 있다는 것을 알 수 있습니다.\n\n![Elice Qwen2.5-32B 모델과 Exaone, SOLAR 모델의 영어 MMLU, 한국어 KMMLU, GSM8K, HumanEval, BBH 성능 비교](https://cdn-cms.elice.io/elice-strapi/4_1x_1585b14ded.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)\n\n### [**실제 서비스에는 어떻게 활용되고 있을까?**](#strong실제-서비스에는-어떻게-활용되고-있을까strong)\n\n이미 엘리스는 해당 모델을 일부 제품 및 서비스에 직접 사용하고 있습니다.\n\n#### [**실무 적용을 고려하는 개발자에게 중요한 포인트**](#strong실무-적용을-고려하는-개발자에게-중요한-포인트strong)\n\n### [**마무리: 실험은 끝났고, 이제 실전이다**](#strong마무리-실험은-끝났고-이제-실전이다strong)\n\n지금까지 엘리스 Korean Qwen2.5 모델의 구조, 성능, 실제 적용 사례를 살펴봤습니다.\n\n이런 결과는 ‘한국어 AI는 영어 모델의 하위 옵션’이라는 인식을 넘어 한국어에 맞는 모델을 선택하는 시대가 되었다는 것을 보여주는 사례라고 생각합니다.\n\n엘리스 Korean Qwen2.5 모델(32B / 72B)은 개발자 누구나 [엘리스클라우드 모델 라이브러리](https://elice.io/ko/products/cloud#inference)를 통해 **직접 프롬프트를 입력해보고 결과를 확인할 수 있는 환경**이 준비되어 있습니다.\n\n“한국어 LLM을 직접 만져보고 싶은데 어디서부터 시작하지?”  \n라는 고민이 있었다면, 지금이 가장 적절한 타이밍일지도 모릅니다.\n\n이 외에도 엘리스클라우드 모델 라이브러리에는 다양한 모델들이 준비되어 있으니, 관심 있는 분들은 무료로 사용해보셔도 좋을 것 같습니다.\n\n![엘리스클라우드 모델 라이브러리](https://cdn-cms.elice.io/elice-strapi/5_1x_f5da587055.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)\n\n![엘리스클라우드 모델 라이브러리](https://cdn-cms.elice.io/elice-strapi/5_1x_f5da587055.webp?sp=racwd&st=2022-07-11T09:43:29Z&se=2032-07-11T17:43:29Z&spr=https&sv=2021-06-08&sr=c&sig=XE8S5Wrx%2F6RCT1tL2PGNsACU1NvYYJAo7lDuH65zn1A%3D)\n\n**👉 [엘리스클라우드에서 Qwen2.5 시작하기](https://elice.io/ko/get-started/services)**\n\n**👉 [더 많은 오픈소스 모델 살펴보기](https://elice.io/ko/products/cloud#inference)**\n\n![](https://www.facebook.com/tr?id=1890947921413287&ev=PageView&noscript=1)"
    },
    {
        "url": "https://zdnet.co.kr/view/?no=20250322134718",
        "title": "LG의 새 AI '엑사원 딥', 수능서 94.5% 정답률...수학·코딩 능력 탁월",
        "content": "무료로 사용 가능한 EXAONE Deep, 상업용은 별도 라이선스 필요\n\nEXAONE Deep 모델은 연구 목적으로 모든 사람이 사용할 수 있도록 공개되어 있다. 이 모델들은 허깅페이스(Hugging Face)를 통해 다운로드할 수 있다. 그러나 이 모델은 추론 작업에 특화되어 있으므로, 넓은 범위의 실제 사용 사례에 적용하려면 EXAONE 3.5 Instruct 모델 사용을 권장한다. 또한, EXAONE AI 모델 라이선스 계약에 따르면, 이 모델은 상업적 용도로 사용할 수 없으며, 별도의 상업용 라이선스 계약이 필요하다.\n\nFAQ\n\nQ: EXAONE Deep 모델은 어떤 특징이 있나요?\n\nA: EXAONE Deep은 추론 능력에 특화된 AI 모델로, 단계적 사고 과정을 포함하는 특별한 데이터셋으로 학습되었습니다. 수학, 코딩 등 논리적 추론이 필요한 과제에서 뛰어난 성능을 보이며, 2.4B, 7.8B, 32B 세 가지 크기로 제공됩니다. [...] 성능 평가 결과에 따르면, 가장 작은 모델인 EXAONE Deep 2.4B는 DeepSeek-R1-Distill-Qwen-1.5B보다 우수한 성능을 보여주었다. 중간 크기인 7.8B 모델은 DeepSeek-R1-Distill-Qwen-7B와 DeepSeek-R1-Distill-Llama-8B 같은 오픈 웨이트 모델뿐만 아니라 상용 추론 모델인 OpenAI o1-mini보다도 뛰어난 성능을 입증했다. 가장 큰 모델인 32B는 QwQ-32B와 DeepSeek-R1 같은 최첨단 오픈 웨이트 추론 모델과 견줄 만한 성능을 보여주었으며, DeepSeek-R1-Distill-Qwen-32B와 DeepSeek-R1-Distill-Llama-70B를 능가했다.\n\nImage 11\n\n단계별 논리적 사고로 무장한 EXAONE Deep, 120억 토큰 데이터로 학습 [...] 수학 분야에서 EXAONE Deep 32B 모델은 MATH-500에서 95.7%, AIME 2024에서 72.1%, AIME 2025에서 65.8%, CSAT 2025에서 94.5%의 놀라운 정확도를 보여주었다. 특히 한국 수능 수학 영역의 세 가지 선택 과목인 미적분, 통계, 기하에서 각각 95.1%, 95.0%, 93.5%의 높은 성능을 보여 전체 평균 94.5%라는 인상적인 결과를 달성했다.\n\n과학 및 코딩 분야에서도 EXAONE Deep 32B는 GPQA Diamond에서 66.1%, LiveCodeBench에서 59.5%의 성능을 보여주었다. 일반 지식을 평가하는 MMLU와 MMLU-Pro에서는 각각 83.0%와 74.0%의 정확도를 달성했다.\n\n7.8B 모델 역시 동급의 모델들과 비교해 모든 분야에서 우수한 성능을 보여주었으며, 특히 수학 분야에서는 MATH-500 94.8%, AIME 2024 70.0%, CSAT 2025 89.9%의 높은 정확도를 기록했다.",
        "score": 0.6364215,
        "raw_content": "Published Time: 2025-03-22T13:47:18+09:00\n\nLG의 새 AI ‘엑사원 딥’, 수능서 94.5% 정답률...수학·코딩 능력 탁월 - ZDNet korea\n\n===============\n[![Image 1](https://menu.mt.co.kr/news/banner/image/2020/20200703160528.jpg)](https://ads.mtgroup.kr/RealMedia/ads/click_lx.ads/zdnet_pc/news/L13/1223256542/x96/moneytoday/Zdnet_PC_PV/Zdnet_PC_PV.html/496d417830576877765077414365384e)\n\nZDNet Korea 뉴스레터 구독신청 \n\n[구독신청](javascript:newsletter();)닫기\n\n[![Image 2](https://zdnet.co.kr/images/zdnet_logo.png?ver=20220830)](https://zdnet.co.kr/ \"ZDNetKore\")\n\n*   [ZDNet USA](https://www.zdnet.com/)\n*   [ZDNet China](https://www.zhiding.cn/)\n*   [ZDNet Japan](https://japan.zdnet.com/)\n\n*   [English](https://www.zdnet.com/topic/korea/)\n*   [지디넷 웨비나](https://itsight.zdnet.co.kr/)\n\n[](javascript:void(0))\n\n[](https://zdnet.co.kr/member/)\n\n뉴스\n\n*   [최신뉴스](https://zdnet.co.kr/news/?lstcode=0000&page=1)\n*   [방송/통신](https://zdnet.co.kr/news/?lstcode=0010&page=1)\n*   [컴퓨팅](https://zdnet.co.kr/news/?lstcode=0020&page=1)\n*   [홈&모바일](https://zdnet.co.kr/news/?lstcode=0030&page=1)\n*   [인터넷](https://zdnet.co.kr/news/?lstcode=0040&page=1)\n*   [반도체/디스플레이](https://zdnet.co.kr/news/?lstcode=0050&page=1)\n\n*   [카테크](https://zdnet.co.kr/news/?lstcode=0057&page=1)\n*   [헬스케어](https://zdnet.co.kr/news/?lstcode=0058&page=1)\n*   [게임](https://zdnet.co.kr/news/?lstcode=0060&page=1)\n*   [중기&스타트업](https://zdnet.co.kr/news/?lstcode=0045&page=1)\n*   [유통](https://zdnet.co.kr/news/?lstcode=0055&page=1)\n*   [금융](https://zdnet.co.kr/news/?lstcode=0073&page=1)\n\n*   [과학](https://zdnet.co.kr/news/?lstcode=0070&page=1)\n*   [디지털경제](https://zdnet.co.kr/news/?lstcode=0075&page=1)\n*   [취업/HR/교육](https://zdnet.co.kr/news/?lstcode=0110&page=1)\n*   [인터뷰](https://zdnet.co.kr/news/?lstcode=0100&page=1)\n*   [인사•부음](https://zdnet.co.kr/news/?lstcode=0090&page=1)\n*   [글로벌뉴스](https://zdnet.co.kr/news/?lstcode=0120&page=1)\n\n[인공지능](https://zdnet.co.kr/newskey/?lstcode=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5)\n\n[배터리](https://zdnet.co.kr/newskey/?lstcode=%EB%B0%B0%ED%84%B0%EB%A6%AC)\n\n[양자컴퓨팅](https://zdnet.co.kr/newskey/?lstcode=%EC%96%91%EC%9E%90%EC%BB%B4%ED%93%A8%ED%8C%85)\n\n[컨퍼런스](https://itsight.zdnet.co.kr/)\n\n[칼럼•연재](https://zdnet.co.kr/column/)\n\n[포토•영상](https://zdnet.co.kr/photo/)\n\nLG의 새 AI ‘엑사원 딥’, 수능서 94.5% 정답률...수학·코딩 능력 탁월\n=============================================\n\n[컴퓨팅](https://zdnet.co.kr/news/?lstcode=0020&page=1)입력 :2025/03/22 13:47\n\n![Image 3](https://zdnet.co.kr/Include2/user/pic/reporter/media1@zdnet.co.kr.jpg)\n\n**AI 에디터**[](mailto:media@zdnet.co.kr)[기자의 다른기사 보기](https://zdnet.co.kr/reporter/?lstcode=media)\n\n*   [![Image 4](https://zdnet.co.kr/images/f_on.png)](https://www.facebook.com/sharer/sharer.php?u=)\n*   [![Image 5](https://zdnet.co.kr/images/x_on.png)](https://twitter.com/intent/tweet?text=LG%EC%9D%98%20%EC%83%88%20AI%20%E2%80%98%EC%97%91%EC%82%AC%EC%9B%90%20%EB%94%A5%E2%80%99,%20%EC%88%98%EB%8A%A5%EC%84%9C%2094.5%%20%EC%A0%95%EB%8B%B5%EB%A5%A0...%EC%88%98%ED%95%99%C2%B7%EC%BD%94%EB%94%A9%20%EB%8A%A5%EB%A0%A5%20%ED%83%81%EC%9B%94&url=)\n*   [![Image 6](https://zdnet.co.kr/images/in_on.png)](https://www.linkedin.com/shareArticle?url=)\n*   [![Image 7](https://zdnet.co.kr/images/txt_bt1.gif)](javascript:increaseFontsize('20250322134718');)\n*   [![Image 8](https://zdnet.co.kr/images/txt_bt2.gif)](javascript:decreaseFontsize('20250322134718');)\n*   [![Image 9](https://zdnet.co.kr/images/print_bt.gif)](javascript:article_print('20250322134718'))\n\n![Image 10](https://image.zdnet.co.kr/2025/03/21/aic9b6deee93716d1058502b69c8c25eb6.jpg)\n\n**동급 최강 성능의 EXAONE Deep, 작은 모델도 오픈AI 추월**\n\nLG AI 연구소가 개발한 EXAONE Deep 시리즈가 수학과 코딩 등 다양한 추론 과제에서 뛰어난 성능을 보여주고 있다. EXAONE Deep 시리즈는 2.4B, 7.8B, 32B 세 가지 크기로 출시되었으며, 이 모델들은 기존 EXAONE 3.5 시리즈를 기반으로 추론 능력을 강화하기 위해 특별히 최적화된 버전이다.\n\nEXAONE Deep 모델은 단계적 사고 과정을 포함하는 특화된 데이터셋으로 학습되었다. 연구팀은 지도 학습(Supervised Fine-Tuning, SFT), 직접 선호도 최적화(Direct Preference Optimization, DPO), 온라인 강화학습(Online Reinforcement Learning, Online RL)과 같은 세 가지 주요 기법을 활용해 모델을 훈련시켰다.\n\n성능 평가 결과에 따르면, 가장 작은 모델인 EXAONE Deep 2.4B는 DeepSeek-R1-Distill-Qwen-1.5B보다 우수한 성능을 보여주었다. 중간 크기인 7.8B 모델은 DeepSeek-R1-Distill-Qwen-7B와 DeepSeek-R1-Distill-Llama-8B 같은 오픈 웨이트 모델뿐만 아니라 상용 추론 모델인 OpenAI o1-mini보다도 뛰어난 성능을 입증했다. 가장 큰 모델인 32B는 QwQ-32B와 DeepSeek-R1 같은 최첨단 오픈 웨이트 추론 모델과 견줄 만한 성능을 보여주었으며, DeepSeek-R1-Distill-Qwen-32B와 DeepSeek-R1-Distill-Llama-70B를 능가했다.\n\n![Image 11](https://image.zdnet.co.kr/2025/03/21/ai5014b6b4db3008aaec59f3a1581258d1.jpg)\n\n**단계별 논리적 사고로 무장한 EXAONE Deep, 120억 토큰 데이터로 학습**\n\nEXAONE Deep 모델의 추론 능력을 강화하기 위해 연구팀은 약 160만 건의 SFT 데이터, 2만 건의 선호도 데이터(DPO용), 그리고 1만 건의 온라인 RL 데이터를 활용했다. SFT 데이터셋은 약 120억 개의 토큰을 포함하며, 확장된 사고 연쇄(chain-of-thought) 과정을 통해 모델이 추론을 수행하도록 설계되었다.\n\n특히 눈에 띄는 점은 이 데이터셋의 구조이다. 각 학습 인스턴스는 구조화된 사고 과정과 최종 답변으로 구성되어 있다. EXAONE 3.5 모델은 &lt;thought> 태그 내에서 논리적 진행, 자기 반성, 자체 검사, 수정 등의 단계별 추론을 수행하도록 훈련되었다. 이렇게 추론 후 생성된 최종 답변은 자기 완결적이며, 사고 과정에서 도출된 핵심 통찰력을 명확하고 간결하게 요약한다.\n\n![Image 12](https://idm.skplanet.com/pixel?nid=29&uid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 13](https://cm.mman.kr/cm.mezzo?partnerkey=digitalcamp&buyerid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 14](https://idm.skplanet.com/pixel?nid=29&uid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 15](https://cm.mman.kr/cm.mezzo?partnerkey=digitalcamp&buyerid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)\n\n훈련 계산 리소스 면에서, EXAONE Deep 모델은 Google Cloud Platform과 NVIDIA NeMo FRAMEwork에서 제공하는 NVIDIA H100 GPU 클러스터를 사용하여 훈련되었다. 기본 모델의 사전 훈련과 추론 능력 향상을 위한 미세 조정에 사용된 계산량은 정밀하게 측정되어, 32B 모델의 경우 총 1.26 × 10^24 FLOP가 사용되었다.\n\n**수학 시험에서 빛난 EXAONE Deep, 한국 수능 수학 94.5% 정답률 달성**\n\nEXAONE Deep 모델은 MATH-500, 미국 수학 초청 시험(AIME) 2024/2025, 한국 대학수학능력시험(CSAT) 2025의 수학 영역, GPQA Diamond, LiveCodeBench, MMLU, MMLU-Pro 등 다양한 벤치마크에서 평가되었다.\n\n수학 분야에서 EXAONE Deep 32B 모델은 MATH-500에서 95.7%, AIME 2024에서 72.1%, AIME 2025에서 65.8%, CSAT 2025에서 94.5%의 놀라운 정확도를 보여주었다. 특히 한국 수능 수학 영역의 세 가지 선택 과목인 미적분, 통계, 기하에서 각각 95.1%, 95.0%, 93.5%의 높은 성능을 보여 전체 평균 94.5%라는 인상적인 결과를 달성했다.\n\n과학 및 코딩 분야에서도 EXAONE Deep 32B는 GPQA Diamond에서 66.1%, LiveCodeBench에서 59.5%의 성능을 보여주었다. 일반 지식을 평가하는 MMLU와 MMLU-Pro에서는 각각 83.0%와 74.0%의 정확도를 달성했다.\n\n7.8B 모델 역시 동급의 모델들과 비교해 모든 분야에서 우수한 성능을 보여주었으며, 특히 수학 분야에서는 MATH-500 94.8%, AIME 2024 70.0%, CSAT 2025 89.9%의 높은 정확도를 기록했다.\n\n**무료로 사용 가능한 EXAONE Deep, 상업용은 별도 라이선스 필요**\n\nEXAONE Deep 모델은 연구 목적으로 모든 사람이 사용할 수 있도록 공개되어 있다. 이 모델들은 허깅페이스(Hugging Face)를 통해 다운로드할 수 있다. 그러나 이 모델은 추론 작업에 특화되어 있으므로, 넓은 범위의 실제 사용 사례에 적용하려면 EXAONE 3.5 Instruct 모델 사용을 권장한다. 또한, EXAONE AI 모델 라이선스 계약에 따르면, 이 모델은 상업적 용도로 사용할 수 없으며, 별도의 상업용 라이선스 계약이 필요하다.\n\n**FAQ**\n\n**Q: EXAONE Deep 모델은 어떤 특징이 있나요?**\n\nA: EXAONE Deep은 추론 능력에 특화된 AI 모델로, 단계적 사고 과정을 포함하는 특별한 데이터셋으로 학습되었습니다. 수학, 코딩 등 논리적 추론이 필요한 과제에서 뛰어난 성능을 보이며, 2.4B, 7.8B, 32B 세 가지 크기로 제공됩니다.\n\n**Q: 이 모델은 어떻게 사용할 수 있나요?**\n\nA: EXAONE Deep 모델은 연구 목적으로 누구나 무료로 사용할 수 있으며, 허깅페이스를 통해 다운로드할 수 있습니다. 상업적 목적으로 사용하려면 별도의 라이선스가 필요합니다.\n\n**Q: EXAONE Deep과 다른 AI 모델과의 차이점은 무엇인가요?**\n\n관련기사\n----\n\n*   [\"챗GPT, 노벨상 연구는 불가\"… 생성형 AI의 과학적 한계, 뭐길래?](https://zdnet.co.kr/view/?no=20250322103343)2025.03.22\n*   [[Q&AI] '고공행진' 한화에어로, 주가 15% 폭락…왜?](https://zdnet.co.kr/view/?no=20250321173726)2025.03.21\n*   [[AI연구소] AI로 작성한 이력서, 채용 담당자들은 알아 차릴까](https://zdnet.co.kr/view/?no=20250320094753)2025.03.20\n*   [스테이블코인 대신 카드결제?…금융은 기회 포착했다](https://zdnet.co.kr/view/?no=20250709092316)2025.07.11\n\nA: EXAONE Deep은 추론에 특화된 모델로, 같은 크기의 다른 모델들보다 수학, 과학, 코딩 분야에서 우수한 성능을 보입니다. 특히 7.8B 모델은 상용 추론 모델인 OpenAI o1-mini보다도 더 나은 성능을 입증했습니다.\n\n■ 이 기사는 AI 전문 매체 ‘[AI 매터스](https://aimatters.co.kr/)’와 제휴를 통해 제공됩니다. 기사는 클로드 3.5 소네트와 챗GPT를 활용해 작성되었습니다. (☞ [기사 원문 바로가기](https://aimatters.co.kr/?p=17497))\n\n**AI 에디터**[media@zdnet.co.kr](mailto:media@zdnet.co.kr)\n\n[기자의 다른 기사 보기](https://zdnet.co.kr/reporter/?lstcode=media)\n\n[![Image 16](https://zdnet.co.kr/images/naver_bt3.gif?ver=20210515)](https://media.naver.com/channel/promotion.nhn?oid=092)\n\n[AI 에디터](https://search.zdnet.co.kr/?kwd=AI%20%EC%97%90%EB%94%94%ED%84%B0&area=4)\n\n지금 뜨는 기사\n--------\n\n### 이시각 헤드라인\n\n[![Image 17](https://image.zdnet.co.kr/2025/07/09/e6ecfd471423f8fceb12e03eb249be48-290x182.jpg)](https://zdnet.co.kr/view/?no=20250709092316)\n\n[#### 스테이블코인 대신 카드결제?…금융은 기회 포착했다](https://zdnet.co.kr/view/?no=20250709092316)\n\n[![Image 18](https://image.zdnet.co.kr/2025/07/10/869372f643f279088b7d331e01514ce0-290x182.jpg)](https://zdnet.co.kr/view/?no=20250710135202)\n\n[#### [타보고서] 고속도로가 도서관보다 적막해…더 정숙해진 볼보 XC90](https://zdnet.co.kr/view/?no=20250710135202)\n\n[![Image 19](https://image.zdnet.co.kr/2025/04/09/a0ddbfeefb9700a251224688b9b994d8-290x182.jpg)](https://zdnet.co.kr/view/?no=20250711104054)\n\n[#### 삼성전기·LG이노텍, 2분기 실적 부진…신성장 동력 확보에 기대](https://zdnet.co.kr/view/?no=20250711104054)\n\n[![Image 20](https://image.zdnet.co.kr/2025/07/11/640f8bc35ab2d5f6992afeb9328e565f-290x182.jpg)](https://zdnet.co.kr/view/?no=20250711142256)\n\n[#### 문체 최휘영·국토 김윤덕...이재명 정부 초대내각 인선 완료](https://zdnet.co.kr/view/?no=20250711142256)\n\n### ZDNet Power Center\n\n![Image 21](https://zdnet.co.kr/images/power_center_320x50.jpg)\n\n[![Image 22: TOP](https://zdnet.co.kr/images/top_button.png)](https://zdnet.co.kr/view/?no=20250322134718#)\n\n![Image 23](https://zdnet.co.kr/images/footer_logo2.png?ver=20220830)\n\nConnect with us\n\n[](https://www.facebook.com/zdnetkor)[](https://twitter.com/zdnetkorea)[](https://www.youtube.com/@techverse.)[](https://feeds.feedburner.com/zdkorea)\n\n ZDNET Korea is operated by Money Today Group under license from Ziff Davis. Global family site >>[CNET.com](https://www.cnet.com/) | [ZDNet.com](https://www.zdnet.com/)\n\nZDNet Korea Newsletter 구독 신청 [구독신청](javascript:newsletter();)\n\n*   [회사소개](https://zdnet.co.kr/corporation/)\n*   [광고문의](https://zdnet.co.kr/corporation/sub2_1.html)\n*   [DB마케팅문의](https://zdnet.co.kr/corporation/sub2_2.html)\n*   [제휴문의](https://zdnet.co.kr/corporation/sub3.html)\n*   [개인정보처리방침](https://zdnet.co.kr/member/privacy.php)\n*   [이용약관](https://zdnet.co.kr/member/teamservice.php)\n*   [청소년 보호정책](https://zdnet.co.kr/member/teenager.php)\n\n*   회사명 : (주)메가뉴스\n*   제호 : 지디넷코리아\n*   등록번호 : 서울아00665\n\n*   등록연월일 : 2008년 9월 23일\n*   사업자 등록번호 : 220-87-44355\n\n*   주소 : 서울시 마포구 양화로111 지은빌딩 3층\n*   대표전화 : (02)330-0100\n\n*   발행인 : 김경묵\n*   편집국장 : 김태진\n*   개인정보보호 책임자·청소년보호책임자 : 김익현\n\n*   COPYRIGHT © ZDNETKOREA ALL RIGHTS RESERVED.\n\n![Image 24](https://cm.g.doubleclick.net/pixel?google_nid=dable&google_cm)![Image 25](https://cm-exchange.toast.com/pixel?cm_mid=1440080439&cm_muid=30646173.1752218880285&toast_push)![Image 26](https://cs.gssprt.jp/yie/ld/cs?dspid=dable&uid=30646173.1752218880285)![Image 27](https://analytics.ad.daum.net/match?d=111&uid=30646173.1752218880285)![Image 28](https://dable-api.scupio.com/dable/v1/exc/?did=30646173.1752218880285)![Image 29](https://ib.adnxs.com/setuid?entity=563&code=30646173.1752218880285)\n"
    },
    {
        "url": "https://cloud.google.com/customers/intl/ko-kr/lgai",
        "title": "LG AI연구원 우수사례 - Google Cloud",
        "content": "다양한 전문 분야의 기반이 되는 EXAONE과 기업 사용자들의 업무 생산성을 혁신할 Enterprise AI Agent인 ChatEXAONE\\을 포함하는LLM(거대 언어 모델, Large Language Model) 기반의 AI 서비스는 현재 LG전자, LG이노텍, LG디스플레이 등 LG 그룹 내 계열사에 적용되었습니다. 또한  LG AI연구원은 전략적 파트너십을 체결한 국내/외 파트너사와 협업을 통해 LG그룹 내 AI 연구 및 기술 전문조직으로서 다양한 역할을 하고 있습니다.\n\n(\\ChatEXAONE은 사용자의 직무와 업무 전문성을 이해하고, 각자의 환경에 적합한 정보를 대화형으로 제공하는 LG그룹 계열사에서 사용 중인 AI 에이전트이며, 이를 통해서 업무에 필요한 데이터를 분석하고, Document QA 또는 소프트웨어 코딩까지 기능을 제공합니다.)\n\n# 엔터프라이즈 환경에 최적화된 LLM 구축 [...] “생성형 AI에 대한 수요는 빠르게 늘어나고 있습니다. 범용 LLM은 일반적으로 훌륭한 성능을 보여주기는 하지만 실제 업무 환경에서는 기대에 미치지 못하는 부분들이 많습니다. 필요한 환경, 데이터, 언어가 다르기 때문인데, 범용 모델을 입맛에 맞게 관리하는 것은 어려운 일입니다. 기업 환경에 최적화할 수 있는 전용 생성형 AI의 중요성이 EXAONE의 출발이었습니다.”\n\n– AI Business Development Unit 이화영 그룹장\n\n이제까지 EXAONE은 LG 계열사를 위해 만들어졌지만 LG AI연구원은 EXAONE을 3.5로 업데이트하고 Enterprise AI Agent ChatEXAONE 등 고객 사용 편의를 고려하여 각 기업과 업무 환경에 따라 데이터를 개별 학습하고 최적화할 수 있도록 했습니다.\n\n# 효율적이고 강력한 거대 언어 모델 구성\n\nEXAONE의 주요 특징: [...] “EXAONE 3.5는 구글 클라우드의 AIOps 환경에서 모든 부분이 모듈화를 바탕으로 설계되었으며, 일반적인 정보를 제공하는 수준을 넘어 각각의 도메인 및 특화 Task에서 전문성을 갖도록 설계되었습니다. 예를 들면 수요 예측, 물성 예측 등을 처리하는 각 모델은 독립적으로 운영되면서 서로 API로 연결될 수 있으며, 새로운 모델이 언제든 더해질 수도 있고, 필요에 따라서는 기업들이 직접 개발하거나 최적화한 모델을 덧붙여서 쓰는 것도 가능합니다.”\n\n이화영 그룹장은 EXAONE의 가장 큰 특징으로 전문 LLM 모듈을 통해 대다수의 기업이 LLM을 사용하고자 하는 요구사항을 반영하고자 하였으며, 일반적인 지식, 상식보다 특정 데이터를 더 잘 이해하고 그 안에서 가치를 만들어내는 모델이 기업 환경에 최적화된 모델 구성을 위해 구글 클라우드를 통해 효율적으로 인공지능 관련 서비스를 통합하고 다양한 모델을 개발할 수 있었다고 강조하였습니다.",
        "score": 0.62633044,
        "raw_content": "![LG AI logo](https://www.gstatic.com/bricks/image/95b258fa-fb94-4ad7-9c10-edca56fa4817.png)\n\n# LG AI연구원 EXAONE : 강력하고 유연한 구글 클라우드 AI 솔루션으로 \"Expert AI, 미래 기술과 비즈니스 모델의 방향성 제시\"\n\n학습, 추론, 운영, 배포로 이어지는 AIOPS\n\n테넌트 독립성 확보된 개방형 범용 서비스\n\n##### EXAONE 이전 버전 대비 성능 56%, 비용 효율 72% 높아진 생성형 AI 모델 구축\n\nEXAONE 이전 버전 대비 성능 56%, 비용 효율 72% 높아진 생성형 AI 모델 구축\n\nLG AI연구원은 기업용 AI 모델 EXAONE 3.5를 발표했습니다. EXAONE은 LG AI연구원이 자체 개발한 거대 언어 모델입니다. Gemini를 비롯한 일반 언어 모델이 범용적인 정보를 바탕으로 언어를 학습하고 지식 정보를 풀어내는 것에 비해 EXAONE 3.5는 도메인 특화 데이터를 기반으로 정보를 학습하고 업무에 활용할 수 있는 형태의 다양한 모델을 통해 기업 데이터를 다시 새로운 가치로 만들어내는AI 모델입니다.\n\n다양한 전문 분야의 기반이 되는 EXAONE과 기업 사용자들의 업무 생산성을 혁신할 Enterprise AI Agent인 ChatEXAONE\\*을 포함하는LLM(거대 언어 모델, Large Language Model) 기반의 AI 서비스는 현재 LG전자, LG이노텍, LG디스플레이 등 LG 그룹 내 계열사에 적용되었습니다. 또한  LG AI연구원은 전략적 파트너십을 체결한 국내/외 파트너사와 협업을 통해 LG그룹 내 AI 연구 및 기술 전문조직으로서 다양한 역할을 하고 있습니다.\n\n(\\*ChatEXAONE은 사용자의 직무와 업무 전문성을 이해하고, 각자의 환경에 적합한 정보를 대화형으로 제공하는 LG그룹 계열사에서 사용 중인 AI 에이전트이며, 이를 통해서 업무에 필요한 데이터를 분석하고, Document QA 또는 소프트웨어 코딩까지 기능을 제공합니다.)\n\n# 엔터프라이즈 환경에 최적화된 LLM 구축\n\n생성형 AI는 단순히 글이나 이미지를 만들어내고, 정보를 검색하는 수준을 넘어서고 있습니다. 특히, 거대 언어 모델은 그 어떤 기술보다도 빠르게 진화하면서 언어의 맥락을 더 정확히 이해해서 원하는 결과물을 빠르고 정확하게 생성합니다. 많은 기업들이 이를 업무에 적극적으로 활용하면서 업무 방법의 변화를 이끌어내기도 합니다.\n\nLG AI연구원은 한국 최초로 Multimodal AI를 자체 연구 개발하며, 인공지능과 업무의 결합을 중요한 요건으로 고려하였고, 안전하게 범용 생성형 AI를 이용하는 방법을 고민해 왔습니다. 그와 동시에 자체적으로 생성형 AI를 만들어 내부적으로 업무에 활용하는 것 뿐 아니라 인공지능에 대한 기술 주도권을 확보해서 LG 계열사가 만드는 상품과 서비스 적용을 최우선하는 목표를 세웠습니다. LG AI연구원은 그 중심에서 EXAONE 모델을 개발했고, 다양한 과제 수행과 고도화를 통해 엔터프라이즈 환경에 최적화된 생성형 AI 플랫폼으로 성장시켰습니다.\n\n“생성형 AI에 대한 수요는 빠르게 늘어나고 있습니다. 범용 LLM은 일반적으로 훌륭한 성능을 보여주기는 하지만 실제 업무 환경에서는 기대에 미치지 못하는 부분들이 많습니다. 필요한 환경, 데이터, 언어가 다르기 때문인데, 범용 모델을 입맛에 맞게 관리하는 것은 어려운 일입니다. 기업 환경에 최적화할 수 있는 전용 생성형 AI의 중요성이 EXAONE의 출발이었습니다.”\n\n– AI Business Development Unit 이화영 그룹장\n\n이제까지 EXAONE은 LG 계열사를 위해 만들어졌지만 LG AI연구원은 EXAONE을 3.5로 업데이트하고 Enterprise AI Agent ChatEXAONE 등 고객 사용 편의를 고려하여 각 기업과 업무 환경에 따라 데이터를 개별 학습하고 최적화할 수 있도록 했습니다.\n\n# 효율적이고 강력한 거대 언어 모델 구성\n\n**EXAONE의 주요 특징:**\n\nEXAONE 3.5 언어 모델은 78억 개(7.8B) 파라미터, 8T 이상의 토큰으로 학습이 이뤄진 경량 LLM입니다. 범용 데이터 검색보다는 여러 산업 현장에서 활용될 수 있도록 높은 수준의 전문가 AI를 목표로 구성되었습니다. 이를 통해 EXAONE은 단순한 데이터 처리 능력을 넘어 복잡한 문제 해결과 예측까지 가능하게 하여, 기업들이 마주하는 다양한 도전 과제를 해결할 수 있는 도구로 자리 잡고 있습니다.\n\n외부에 공개된 7.8B 모델은 가장 범용적으로 많이 쓰이는 효율적인 모델일 뿐 아니라 EXAONE 3.5 모델이 추구하는 방향은 전문 산업 분야에 집중하는 것이기 때문에 결과적으로 EXAONE이 역할을 하는 분야에서는 뛰어난 성능을 보여줍니다. 이화영 그룹장은 우수한 수준을 꼽히는 여느 범용 LLM 이상의 성능을 내면서도 성능과 비용 면에서도 뛰어나다고 설명합니다.\n\n모델의 경량화와 효율성에 대해 집중한 결과 기존 EXAONE 2.0에 비해 메모리 사용량이 3분의 1 만큼 줄이면서도 추론 처리 시간은 절반으로 낮췄습니다. 자연스럽게 비용은 72%를 줄였고, EXAONE 1.0에 비해서는 6%에 불과합니다. 더 작은 인프라에서 가볍게 구동되면서도 비용을 줄일 수 있기 때문에 활용에 대한 부담을 덜 수 있었고, LG 계열사를 넘어 모두에게 활짝 열린 범용 서비스를 기대할 수도 있게 되었습니다.\n\nEXAONE의 생성형 AI 모델 학습과 운영 등의 대부분은 구글 클라우드에서 이뤄집니다. 모든 부분은 모듈 설계가 되어 있고 모델과 데이터는 각각의 테넌트 안에서 독립적으로 운영되는 방식입니다. LG AI연구원은 더 많은 고객이 EXAONE 3.5을 하나의 완성된 서비스 형태로 편리하게 사용하실 수 있도록 구글 클라우드 기반의 Vertex AI를 통해 서비스를 구성하고 배포할 예정입니다.\n\n# 효율적인 모델, 넉넉한 GPU 환경 더해 최고 수준의 LLM 성능 확보\n\n이화영 그룹장은 모델 자체가 구글 클라우드를 기반으로 학습, 추론되고, 서비스까지 하나의 환경에서 이뤄지는 것에 큰 의미를 두었습니다. 특히 LG AI연구원은 EXAONE 3.5의 강점으로 여러 생성형 AI와 머신러닝 모델, 검색 증강 생성 RAG(Retrieval-Augmented Generation)과 데이터 분석 등 EXAONE의 기능 확장과 최적화를 위한 모듈화를 중심에 두고 있기 때문에 데이터와 인공지능 등이 모두 하나의 서비스 안에서 유기적으로 작동하는 것을 중요하게 여겼습니다.\n\n“EXAONE 3.5는 구글 클라우드의 AIOps 환경에서 모든 부분이 모듈화를 바탕으로 설계되었으며, 일반적인 정보를 제공하는 수준을 넘어 각각의 도메인 및 특화 Task에서 전문성을 갖도록 설계되었습니다. 예를 들면 수요 예측, 물성 예측 등을 처리하는 각 모델은 독립적으로 운영되면서 서로 API로 연결될 수 있으며, 새로운 모델이 언제든 더해질 수도 있고, 필요에 따라서는 기업들이 직접 개발하거나 최적화한 모델을 덧붙여서 쓰는 것도 가능합니다.”\n\n이화영 그룹장은 EXAONE의 가장 큰 특징으로 전문 LLM 모듈을 통해 대다수의 기업이 LLM을 사용하고자 하는 요구사항을 반영하고자 하였으며, 일반적인 지식, 상식보다 특정 데이터를 더 잘 이해하고 그 안에서 가치를 만들어내는 모델이 기업 환경에 최적화된 모델 구성을 위해 구글 클라우드를 통해 효율적으로 인공지능 관련 서비스를 통합하고 다양한 모델을 개발할 수 있었다고 강조하였습니다.\n\n또한, 구글 클라우드는 여러 형태의 모델을 매끄럽게 운영할 수 있는 컴퓨팅을 제공하기에 LG AI연구원의 EXAONE 3.5는 구글 클라우드의 GPU를 통해 학습과 추론 및 모델과 데이터 셋의 특성에 따라 엔비디아의 H100과 A100을 적절하게 골라 쓸 수 있었으며, 구글 클라우드는 넉넉하고 안정된 GPU 성능을 제공하여 적절한 순간에 필요한 만큼의 컴퓨팅 자원을 매끄럽게 할당하여 사용할 수 있었습니다.\n\nLG AI연구원은 TPU의 상용화 초기부터 TPU를 활용했고, EXAONE 2.0까지는 TPU를 통해 모델을 운영하기도 했습니다. EXAONE 3.5는 구글 클라우드의 AI 서비스들과 맞물려 GPU로도 높은 효율을 바탕으로 뛰어난 성능을 낼 수 있도록 설계됐기 때문에 GPU를 중심으로 운영되지만 기존 TPU에 대한 경험과 만족도가 높고, EXAONE과 구글 클라우드의 유연성이 높기 때문에 언제든 확장할 가능성도 갖고 있습니다.\n\n이화영 그룹장은 EXAONE 오픈소스 모델 공개와 엔터프라이즈 모델의 개방성과 독립성을 강조했습니다.\n\n# “구글 클라우드는 다음 단계의 인공지능 도약을 함께 하는 파트너”\n\n생성형 AI의 등장 이후 인공지능의 역할과 의미는 그 어느 때보다 빠르게 변화하고 있습니다. 그 중심에는 기업이 갖고 있는 지식 정보에서 가치를 만들어내는 RAG가 있습니다. LG AI연구원이 EXAONE 3.5 개발 과정에서도 고객의 요구사항 기반으로 RAG를 중요한 기술로 고려하였으며, EXAONE은 RAG 기술을 통해 각 기업의 지식과 경험이 담긴 문헌을 학습해 새로운 정보를 생성해 냅니다.\n\n예를 들면 제품의 품질 관리에 대한 대응 방법을 처리한다고 하면 수 십 년 동안 일어난 사례와 방법들을 정리한 논문, 특허, 백서 또는 문헌 등의 기업 데이터를 기반으로 품질에 문제가 생겼을 때 어떻게 대응해야 할지 곧바로 답을 제시할 수 있습니다. 명확한 Reasoning을 통해 대화의 주제가 좁혀지면서 전문성은 높아지고 환각 현상(Hallucination)에 대한 우려를 최소화하고자 하였습니다.\n\n“생성형 AI를 비롯한 인공지능은 묻는 말에 대답만 하는 단계를 뛰어넘고 있습니다. RAG를 바탕으로 정확도와 신뢰도가 높아지면서 인공지능이 판단한 결과에 대해 직접 적절한 행동을 하고 그 실행 결과를 주는 하나의 에이전트 역할로 진화해야 합니다. 특히 기업용 인공지능은 정보 제공만 하는 것이 아니라 먼저 적극적으로 움직이는 사용자 친화적 서비스로 진화해야 합니다.”\n\n또한 이화영 그룹장은 LG AI연구원은 신뢰성과 안전성을 확보한 AI 모델 개발을 AI 라이프 사이클의 전 과정에서 윤리적 측면의 관리를 위한 절차를 갖추고 있으며, 자체 Compliance 체계를 확보하고 준수하고 있습니다. 하지만 실제 이러한 모델을 제공할 때는 개발부터 제공/배포 단계까지 잘 갖춰진 보안 체계가 필요합니다. 구글 클라우드는 이러한 기본적인 보안에 대한 기술과 권한 관리가 탄탄하면서도 매끄럽고, 데이터가 오가는 과정의 암호화도 아주 잘 갖춰져 있어 고객이 안전하게 사용 가능한 환경을 제공한다고 합니다.\n\nLG AI연구원은 인공지능이 전문성을 가지고, 각 분야의 필드 전문가들이 이제까지 쌓은 기술과 경험을 바탕으로 한 단계 높은 수준의 일을 해낼 수 있도록 돕는 것을 목표로 하고 있습니다.\n\n[**LG AI연구원**](https://www.lgresearch.ai/)\n\nLG AI연구원은 LG그룹의 AI 싱크탱크로 최신의 AI 기술 확보와 다양한 AI 난제 해결을 목표로 다양한 산업 분야에서 AI의 가능성을 보여주고 있습니다. 특히, LG전자, LG화학 등 계열사들과 협력해 현장의 AI 기술을 증명하고, 글로벌 AI 연구 생태계와의 협력을 통해 다음 세대의 AI 비전을 제시합니다.\n\n**산업 분야：**전자, 화학/에너지, 의료/헬스케어, 법률, 금융/공공, 제조 등\n\n**위치:** 대한민국\n\n**사용된 제품 :**[Vertex AI](https://cloud.google.com/vertex-ai), [Compute Engine](https://cloud.google.com/products/compute)\n\n![Google Cloud](https://www.gstatic.com/cgc/google-cloud-logo.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/retail.svg)\n![](https://www.gstatic.com/cloud/images/navigation/cpg.svg)\n![](https://www.gstatic.com/cloud/images/navigation/finance.svg)\n![](https://www.gstatic.com/cloud/images/navigation/hcls.svg)\n![](https://www.gstatic.com/cloud/images/navigation/media.svg)\n![](https://www.gstatic.com/cloud/images/navigation/telecommunications.svg)\n![](https://www.gstatic.com/cloud/images/navigation/gaming.svg)\n![](https://www.gstatic.com/cloud/images/navigation/manufacturing.svg)\n![](https://www.gstatic.com/cloud/images/navigation/supply-chain.svg)\n![](https://www.gstatic.com/cloud/images/navigation/government.svg)\n![](https://www.gstatic.com/cloud/images/navigation/icon-sprite.svg#education)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/compute-engine.png)\n![](https://www.gstatic.com/cloud/images/navigation/cloud-storage.png)\n![](https://www.gstatic.com/cloud/images/navigation/bigquery.png)\n![](https://www.gstatic.com/cloud/images/navigation/cloud-run.png)\n![](https://www.gstatic.com/cloud/images/navigation/kubernetes-engine.png)\n![](https://www.gstatic.com/cloud/images/navigation/vertex-ai.png)\n![](https://www.gstatic.com/cloud/images/navigation/looker.png)\n![](https://www.gstatic.com/cloud/images/navigation/apigee.png)\n![](https://www.gstatic.com/cloud/images/navigation/cloud-sql.png)\n![](https://www.gstatic.com/cloud/images/navigation/gemini.png)\n![](https://www.gstatic.com/cloud/images/navigation/networking.png)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![](https://www.gstatic.com/cloud/images/navigation/forward.svg)\n![Google Cloud](https://www.gstatic.com/cgc/google-cloud-logo.svg)"
    },
    {
        "url": "https://www.msap.ai/blog/exaone-lg-llm/",
        "title": "Exaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP.ai",
        "content": "활용 목적 측면에서도 Exaone은 기존 오픈소스 모델들과 확연히 구분됩니다. Gemma 3, LLaMA 3, DeepSeek R1 등의 모델은 연구자와 개발자 커뮤니티를 겨냥해 공개되었으며, 대부분 상업적 사용까지 허용하는 유연한 라이선스를 제공합니다. 반면, Exaone은 처음부터 기업 내부 환경에서의 실질적 배치를 전제로 개발된 모델입니다. 실제로 LG 계열사의 스마트팩토리 운영, 고객 응대 자동화, 기술 문서 요약, 품질 분석 등 다양한 산업 분야에서 이미 활용되고 있으며, 단순한 생성 성능을 넘어서 데이터 보안, 책임 추적성, 커스터마이징 가능성 등 엔터프라이즈 환경에 필요한 요소들을 포괄하고 있습니다. 이로 인해Exaone은 오픈소스로 공개되어 있음에도 불구하고 라이선스 조건이 연구 목적에 한정되며, 상업적 사용을 원할 경우에는 반드시 LG와 별도의 상업용 라이선스를 체결해야 합니다. [...] Exaone은 멀티모달 처리 능력과 산업 특화 성능을 바탕으로 다양한 분야에서의 활용이 기대됩니다. 특히, 의료, 법률, 금융 등 전문 지식이 요구되는 분야에서의 적용이 예상되며, LG AI 연구원은 Exaone의 성능 향상과 적용 범위 확대를 위해 지속적인 연구와 협력을 진행하고 있습니다. 또한, 글로벌 AI 생태계와의 협력을 통해 Exaone의 활용성을 더욱 높이고, 다양한 산업 분야에서의 혁신을 주도할 것으로 전망됩니다.\n\nReferences & Related Links\n-------------------------- [...] Published Time: 2025-04-04T08:47:30+00:00\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP\n\n===============\nSkip to content\n\nSearch for:     로, 텍스트뿐만 아니라 이미지 등 다양한 입력을 동시에 이해하고 처리할 수 있는 모델입니다. “Exaone”이라는 이름은 “Exascale AI for Everyone”의 약어로, 누구나 활용할 수 있는 엑사급 인공지능이라는 비전을 담고 있습니다.\n\nExaone은 단순한 기술 실험이 아닌, 국내 대기업이 직접 개발하고 실사용 사례에 적용하는 LLM이라는 점에서 매우 중요한 모델입니다. OpenAI나 Meta, Google과 같은 글로벌 빅테크가 개발한 LLM에만 의존하지 않고, 한국어와 산업 현장에 최적화된 독자 생태계를 구축하려는 LG의 전략적 움직임이기도 합니다.",
        "score": 0.61668247,
        "raw_content": "Published Time: 2025-04-04T08:47:30+00:00\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델 - MSAP\n\n===============\n[Skip to content](https://www.msap.ai/blog/exaone-lg-llm/#content)\n\n[](https://www.msap.ai/)\n\n[![Image 1: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)![Image 2: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)![Image 3: MSAP Logo](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_white_h40.webp)](https://www.msap.ai/)\n\nSearch for: \n\n[](https://www.msap.ai/blog/exaone-lg-llm/#)\n\nToggle Navigation\n*   [MSAP.ai](https://www.msap.ai/msap-ai/)\n    *   [MSA Accelerator](https://www.msap.ai/msap-ai/msa-accelerator/)\n        *   [DDD Designer](https://www.msap.ai/msap-ai/msa-accelerator/ddd-designer/)\n        *   [Application Designer](https://www.msap.ai/msap-ai/msa-accelerator/application-designer/)\n        *   [MSA Framework](https://www.msap.ai/msap-ai/msa-accelerator/msa-framework/)\n\n    *   [PLATFORM](https://www.msap.ai/msap-ai/platform/)\n        *   [Container Platform](https://www.msap.ai/msap-ai/platform/container-platform/)\n        *   [Observability & APM](https://www.msap.ai/msap-ai/platform/observability-apm/)\n        *   [POD Cluster](https://www.msap.ai/msap-ai/platform/pod-cluster/)\n\n    *   [AI](https://www.msap.ai/msap-ai/ai-as-a-service/)\n        *   [LLM](https://www.msap.ai/msap-ai/ai-as-a-service/large-language-model/)\n        *   [RAG](https://www.msap.ai/msap-ai/ai-as-a-service/retrieval-augmented-generation/)\n        *   [AI Framework](https://www.msap.ai/msap-ai/ai-as-a-service/ai-framework/)\n\n    *   [HARDWARE](https://www.msap.ai/msap-ai/hardware/)\n    *   [MSAP.ai 제품문의](https://www.msap.ai/msap-ai/solution-contact/)\n\n*   [컨설팅](https://www.msap.ai/consulting/)\n    *   [MSA 특화 컨설팅](https://www.msap.ai/consulting/msa-special-consulting/)\n    *   [MSA 설계 및 플랫폼 구축](https://www.msap.ai/consulting/msa-design-platform-deployment/)\n    *   [클라우드 네이티브 전환 진단 컨설팅](https://www.msap.ai/consulting/cloud-native-transition-diagnostic-consulting/)\n    *   [MSA 전환, IT 현황 진단 서비스](https://www.msap.ai/consulting/msa-it-assessment/)\n    *   [MSA Conveyor Belt Workshop 신청](https://www.msap.ai/consulting/msa-workshop/)\n\n*   [교육](https://www.msap.ai/training/)\n    *   [MSA 특화 교육](https://www.msap.ai/training/msa-special-training/)\n    *   [MSA 개념과 패턴 교육](https://www.msap.ai/training/msa-concept-pattern-training/)\n    *   [찾아가는 MSA & 클라우드 네이티브 세미나](https://www.msap.ai/training/free-cloud-native-seminar/)\n\n*   [이벤트 & 세미나](https://www.msap.ai/event-seminar/)\n    *   [세미나](https://www.msap.ai/event-seminar/seminar/)\n    *   [이벤트](https://www.msap.ai/event-seminar/event/)\n\n*   [블로그](https://www.msap.ai/msap-blog/)\n    *   [전체 블로그](https://www.msap.ai/msap-blog/msap-all-blog/)\n    *   [AI 블로그](https://www.msap.ai/msap-blog/msap-ai-blog/)\n    *   [MSA 블로그](https://www.msap.ai/msap-blog/msap-msa-blog/)\n    *   [Platform 블로그](https://www.msap.ai/msap-blog/msap-platform-blog/)\n\n*   [자료실](https://www.msap.ai/resource/)\n    *   [공지사항](https://www.msap.ai/resource/notice/)\n    *   [eBook](https://www.msap.ai/docs/msa-expert-from-concepts-to-practice/)\n    *   [Datasheet](https://www.msap.ai/resource/datasheet/)\n    *   [Whitepaper](https://www.msap.ai/resource/whitepaper/)\n    *   [Solution Briefs](https://www.msap.ai/resource/solution-briefs/)\n    *   [Case Studies](https://www.msap.ai/resource/case-studies/)\n    *   [Presentation](https://www.msap.ai/resource/presentation/)\n    *   [Webinars](https://www.msap.ai/resource/webinars/)\n\n*   [기술지원](https://www.msap.ai/support/)\n    *   [기술지원 요청](https://www.msap.ai/support/%ea%b8%b0%ec%88%a0%ec%a7%80%ec%9b%90-%ec%9a%94%ec%b2%ad/)\n    *   [기술지원 소개](https://www.msap.ai/support/%ea%b8%b0%ec%88%a0%ec%a7%80%ec%9b%90-%ec%86%8c%ea%b0%9c/)\n\n*   [회사](https://www.msap.ai/company/)\n    *   [사업영역](https://www.msap.ai/company/business-domain/)\n    *   [기업연혁](https://www.msap.ai/company/history/)\n    *   [BI 소개](https://www.msap.ai/company/msap-ai-bi-introduce/)\n    *   [오시는길](https://www.msap.ai/company/location/)\n    *   [MSAP.ai 굿즈 스토어](https://www.msap.ai/goods/)\n\n*   [](https://www.msap.ai/blog/exaone-lg-llm/# \"Search\")Search for:     [](https://www.msap.ai/blog/exaone-lg-llm/#) \n\nMSAP.ai 블로그\n===========\n\nMSAP.ai 블로그에서 최신 정보와 유용한 팁을 만나보세요. 다양한 콘텐츠와 전문 지식을 통해 더 나은 경험을 제공합니다.\n\nAI Blog,Blog\n\nExaone 은 무엇인가? LG가 개발한 LLM 모델\n=============================\n\n이 글은 LG가 개발한 LLM 모델 Exaone의 특성과 활용 조건, 라이선스 주의사항까지 한눈에 정리한 콘텐츠입니다.\n\n2025년 04월 04일\n\n![Image 4: Exaone 은 무엇인가? LG가 개발한 LLM 모델](https://www.msap.ai/wp-content/uploads/2025/04/msap-body-exaone-lg-llm.webp)\n\nExaone 이란 무엇인가?\n---------------\n\nExaone은 LG AI Research에서 개발한 **초거대 멀티모달 언어 모델**(large-scale multimodal language model)로, 텍스트뿐만 아니라 이미지 등 다양한 입력을 동시에 이해하고 처리할 수 있는 모델입니다. “Exaone”이라는 이름은 “Exascale AI for Everyone”의 약어로, **누구나 활용할 수 있는 엑사급 인공지능**이라는 비전을 담고 있습니다.\n\nExaone은 단순한 기술 실험이 아닌, **국내 대기업이 직접 개발하고 실사용 사례에 적용하는** LLM이라는 점에서 매우 중요한 모델입니다. OpenAI나 Meta, Google과 같은 글로벌 빅테크가 개발한 LLM에만 의존하지 않고, 한국어와 산업 현장에 최적화된 독자 생태계를 구축하려는 **LG의 전략적 움직임**이기도 합니다.\n\n특히, 언어뿐 아니라 **멀티모**달 처리 능력까지 제공하면서, 단순한 텍스트 생성기를 넘어 **기업용 지식 처리, 문서 자동화, 스마트 분석, 비전 기반 응용 분야까지 확장성 있는 LLM으로 진화**하고 있다는 점이 주목할 만합니다.\n\n### Exaone 은 언제 시작되었는가?\n\nExaone 프로젝트는 2021년부터 LG AI Research에 의해 본격적으로 시작되었습니다. 공식 발표는 2021년 12월, LG AI Research가 출범 1년 만에 공개한 결과물이었습니다. LG는 그때 이미 자체 개발한 130억 파라미터 규모의 멀티모달 초거대 AI Exaone을 통해 “기업용 LLM 개발의 시대”를 선언한 셈이었습니다.\n\n##### LG의 공식 발표 당시 메시지에서 읽을 수 있는 의도\n\n> “우리가 필요한 AI는 직접 만들어야 합니다. Exaone은 우리 산업과 언어를 이해하고, 우리 조직의 문제를 함께 해결할 수 있는 AI입니다.”\n> \n> \n> – LG AI Research, 2021\n\n##### Exaone 개발 목적\n\n**1. 한국어 및 영어 지원**: Exaone은 한국어와 영어를 모두 이해하고 처리할 수 있도록 설계되어, 국내외 다양한 환경에서 활용될 수 있습니다.\n\n**2. 멀티모달 처리 능력**: 텍스트뿐만 아니라 이미지 등 다양한 형태의 데이터를 동시에 처리할 수 있는 멀티모달 능력을 갖추어, 예술, 패션 등 다양한 분야에서 활용될 수 있습니다.\n\n**3. 산업별 맞춤형 AI 개발**: LG는 Exaone을 통해 자사 제품과 서비스에 AI를 통합하여 고객 경험을 향상시키고, 산업별 과제를 해결하고자 했습니다.\n\n**4. AI 생태계 확장**: Exaone을 오픈소스로 공개함으로써 연구 기관과 스타트업이 최신 기술을 활용할 수 있도록 지원하고, AI 생태계를 확장하고자 했습니다.\n\n이러한 목적을 통해 LG AI 연구원은 Exaone을 개발하여 다양한 산업 분야에서 AI 기술을 활용하고, 글로벌 시장에서의 경쟁력을 강화하고자 했습니다.\n\n### Exaone 라이선스 알고 사용해야 합니다.\n\n아래는 EXAONE 3.0 라이선스에 포함된 영문 원문을 그대로 인용하면서, 기업이 영리 목적으로 사용하는 경우 문제가 되는 조항을 하나씩 근거와 함께 설명드리겠습니다.\n\n##### 문제 1: 상업적 사용 금지 (Commercial Use Prohibited)\n\n기업이 Exaone 모델 또는 출력물을 자체 서비스에 활용하여 수익을 창출하거나 제품/서비스로 제공하는 행위는 명시적으로 금지되어 있습니다. 단순히 “판매”뿐 아니라 “서비스화”, “라이선싱”, “앱에 통합”하는 것도 포함됩니다.\n\n**라이선스 원문 인용**\n\n> 3.1 Restrictions\n> \n> \n> Licensee shall not use the Model, Derivatives, or Output for any Commercial Purposes.\n> \n> \n> “Commercial Purposes” means the use of the Model, Derivatives, or Output for commercial advantage or monetary compensation, including but not limited to:\n> \n> \n> (a) selling, licensing, or distributing the Model, Derivatives, or Output;\n> \n> \n> (b) using the Model, Derivatives, or Output in connection with a product, service, or application offered for sale, license, or other commercial distribution;\n> \n> \n> (c) incorporating the Model, Derivatives, or Output into a product or service that is sold or licensed to third parties.\n\n**해석**\n\n*   수익 창출을 위한 모든 활용은 금지됩니다.\n*   특히 b항은 “모델을 제품, 서비스, 애플리케이션에 결합하여 판매, 라이선스, 배포하는 것”까지 포함하므로, 기**업이 모델을 API 서비스로 내놓거나 SaaS로 구성해 판매하는 것조차도 위반**이 됩니다.\n\n##### 문제 2: 연구 목적에 한정된 사용 허가 (License Scope)\n\nExaone 3.0은 ‘연구 목적(research purposes)’으로만 사용이 허용됩니다. 연구 이외의 모든 목적은 허용되지 않으며, 이는 기업의 상용화 또는 **제품화**를 포함합니다\n\n**라이선스 원문 인용**\n\n> 2.1 Grant of License\n> \n> \n> Subject to the terms and conditions of this Agreement, Licensor hereby grants Licensee a limited, non-exclusive, non-transferable, non-sublicensable license to use the Model solely for research purposes.\n\n**해석**\n\n*   사용 허가 범위가 “연구 목적에 한해서만” 제한되어 있기 때문에 기업이 이를 자사 서비스에 통합하거나 제품에 적용하는 것은 라이선스 위반입니다.\n\n##### 문제 3: 출력물(Output)의 소유권 및 활용 제한\n\nExaone을 사용하여 생성된 출력물도 기업의 자산으로 자유롭게 활용하거나 판매할 수 없습니다. 출력물(Output)의 권리 역시 라이선스 제공자에게 귀속됩니다.\n\n**라이선스 원문 인용**\n\n> 4.2 Ownership\n> \n> \n> All rights, title, and interest in and to the Model, Derivatives, and Output shall remain with the Licensor.\n> \n> \n> Licensee shall not claim ownership or any other rights in the Model, Derivatives, or Output.\n\n**해석**\n\n*   기업은 출력 결과물에도 **소유권이나 지적재산권을 주장할 수 없으며**, 이를 자유롭게 수익화하거나 공개할 수 없습니다.\n*   이는 **서비스 결과물로 사용자에게 제공하는 형태**도 제한될 수 있음을 의미합니다.\n\n##### 문제 4: 위반 시 라이선스 자동 종료\n\n위의 조건을 위반하면 라이선스는 즉시 종료되며, 법적 책임까지 따를 수 있습니다.\n\n**라이선스 원문 인용**\n\n> 6.2 Termination for Breach\n> \n> \n> Licensor may terminate this Agreement immediately if Licensee breaches any of the terms or conditions of this Agreement.\n\n**해석**\n\n*   만약 상업적 사용 등 금지된 행위를 할 경우, 라이선스 자체가 **자동으로 무효**가 되며, **법적 조치 또는 손해배상 청구**로 이어질 가능성도 있습니다.\n\n### 기업이 주의해야 할 핵심 포인트\n\n| 구분 | 금지된 행위 | 라이선스 조항 근거 |\n| :--- | :--- | :--- |\n| 영리 목적 사용 | 모델을 사용한 제품/서비스/API 제공 | 3.1 Restrictions (a), (b), (c) |\n| 연구 목적 외 사용 | 실서비스 통합, 데이터 분석 상용화 등 | 2.1 Grant of License |\n| 출력물 소유권 주장 | 생성된 결과물의 자유로운 사용/배포 | 4.2 Ownership |\n| 라이선스 위반 시 조치 | 자동 종료 및 법적 책임 | 6.2 Termination for Breach |\n\n기업이 **EXAONE 3.0을 상업적 서비스에 사용하려면** , 현재의 공개 라이선스 하에서는 **불가능**하며, 반드시 **LG AI Research와 별도의 상업용 라이선스 계약을 체결**해야 합니다.\n\n### Exaone 의 특징\n\nExaone은 범용 LLM과는 전혀 다른 출발점과 목적, 그리고 활용 환경을 고려해 설계된 모델입니다. 한국어와 산업별 특화된 이해 능력, 텍스트와 이미지를 함께 처리할 수 있는 멀티모달 기능, 그리고 실사용을 전제로 한 아키텍처 설계는 Exaone을 단순한 기술 데모 수준을 넘어선, 실제 산업 현장에서 작동 가능한 인공지능으로 자리매김하게 만듭니다. 여기에 제한적 라이선스를 통한 보안성과 책임성까지 더해지면서, Exaone은 독자적인 가치를 갖는 실전형 LLM으로 평가받고 있습니다.\n\n활용 목적 측면에서도 Exaone은 기존 오픈소스 모델들과 확연히 구분됩니다. Gemma 3, LLaMA 3, DeepSeek R1 등의 모델은 연구자와 개발자 커뮤니티를 겨냥해 공개되었으며, 대부분 상업적 사용까지 허용하는 유연한 라이선스를 제공합니다. 반면, Exaone은 처음부터 **기업 내부 환경에서의 실질적 배치를 전제로 개발된 모델**입니다. 실제로 LG 계열사의 스마트팩토리 운영, 고객 응대 자동화, 기술 문서 요약, 품질 분석 등 다양한 산업 분야에서 이미 활용되고 있으며, 단순한 생성 성능을 넘어서 데이터 보안, 책임 추적성, 커스터마이징 가능성 등 엔터프라이즈 환경에 필요한 요소들을 포괄하고 있습니다. 이로 인해**Exaone은 오픈소스로 공개되어 있음에도 불구하고 라이선스 조건이 연구 목적에 한정되며, 상업적 사용을 원할 경우에는 반드시 LG와 별도의 상업용 라이선스를 체결**해야 합니다.\n\n이와 같은 특성은 Exaone의 생태계 운영 전략에도 그대로 반영되어 있습니다. 예를 들어 Gemma 3나 DeepSeek R1은 Hugging Face, Colab 등과 연동되며 오픈소스 커뮤니티에서 빠르게 확산되고 있고, 다양한 파생 모델과 실험이 활발하게 이루어지고 있습니다. 하지만 Exaone은 그러한 개방형 생태계 확장보다는, **내부 활용을 중심으로 안정성과 실효성을 확보하는 방향**을 택하고 있습니다. 다시 말해, Exaone은 불특정 다수를 위한 범용 AI 플랫폼이 아니라, 특정 산업 도메인에 최적화된 실용 중심의 AI로서, 명확한 정체성과 방향성을 갖고 있는 모델이라 할 수 있습니다.\n\n마무리\n---\n\nExaone은 멀티모달 처리 능력과 산업 특화 성능을 바탕으로 다양한 분야에서의 활용이 기대됩니다. 특히, 의료, 법률, 금융 등 전문 지식이 요구되는 분야에서의 적용이 예상되며, LG AI 연구원은 Exaone의 성능 향상과 적용 범위 확대를 위해 지속적인 연구와 협력을 진행하고 있습니다. 또한, 글로벌 AI 생태계와의 협력을 통해 Exaone의 활용성을 더욱 높이고, 다양한 산업 분야에서의 혁신을 주도할 것으로 전망됩니다.\n\nReferences & Related Links\n--------------------------\n\n*   [LG AI Research EXAONE 공식 페이지](https://www.lgresearch.ai/project/exaone)\n*   [EXAONE 3.0 GitHub 저장소](https://github.com/LG-AI-EXAONE/EXAONE-3.0)\n*   [EXAONE 3.0 라이선스 원문](https://github.com/LG-AI-EXAONE/EXAONE-3.0/blob/main/LICENSE)\n*   [LG, AI연구원 공식 출범…“AI가 LG의 미래를 주도할 것”](https://www.lgcorp.com/media/release/28482)\n*   [LG AI연구원, 초거대 멀티모달 AI ‘EXAONE’ 공개](https://www.lgcorp.com/media/release/27378)\n*   [LG AI Research Builds Multimodal AI Model “Exaone” on AWS to Accelerate Innovation](https://aws.amazon.com/solutions/case-studies/lg-ai-research-case-study/)\n\nBy [MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")Published On: 2025년 04월 04일 Categories: [AI Blog](https://www.msap.ai/category/blog-home/ai-blog/), [Blog](https://www.msap.ai/category/blog-home/blog/)[0 Comments on Exaone 은 무엇인가? LG가 개발한 LLM 모델](https://www.msap.ai/blog-home/blog/exaone-lg-llm/#respond)Tags: [AI](https://www.msap.ai/tag/ai/), [AI 플랫폼](https://www.msap.ai/tag/ai-%ed%94%8c%eb%9e%ab%ed%8f%bc/), [AI라이선스](https://www.msap.ai/tag/ai%eb%9d%bc%ec%9d%b4%ec%84%a0%ec%8a%a4/), [EXAONE](https://www.msap.ai/tag/exaone/), [LLM](https://www.msap.ai/tag/llm/), [LLM 플랫폼](https://www.msap.ai/tag/llm-%ed%94%8c%eb%9e%ab%ed%8f%bc/), [OpenAI](https://www.msap.ai/tag/openai/), [대규모 언어 모델](https://www.msap.ai/tag/%eb%8c%80%ea%b7%9c%eb%aa%a8-%ec%96%b8%ec%96%b4-%eb%aa%a8%eb%8d%b8/), [인공지능](https://www.msap.ai/tag/%ec%9d%b8%ea%b3%b5%ec%a7%80%eb%8a%a5/)\n\n#### Share This Story, Choose Your Platform!\n\n[](https://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&t=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8 \"Facebook\")[](https://x.com/intent/post?text=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"X\")[](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&title=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&summary=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"LinkedIn\")[](https://api.whatsapp.com/send?text=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"WhatsApp\")[](https://www.tumblr.com/share/link?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&name=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"Tumblr\")[](https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC&media= \"Pinterest\")[](https://vkontakte.ru/share.php?url=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F&title=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&description=Your%20Content%20Goes%20Here%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%0D%0A%0D%0A%EC%9D%B4%20%EA%B8%80%EC%9D%80%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8%20Exaone%EC%9D%98%20%ED%8A%B9%EC%84%B1%EA%B3%BC%20%ED%99%9C%EC%9A%A9%20%EC%A1%B0%EA%B1%B4%2C%20%EB%9D%BC%EC%9D%B4%EC%84%A0%EC%8A%A4%20%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD%EA%B9%8C%EC%A7%80%20%ED%95%9C%EB%88%88%EC%97%90%20%EC%A0%95%EB%A6%AC%ED%95%9C%20%EC%BD%98%ED%85%90%EC%B8%A0%EC%9E%85%EB%8B%88%EB%8B%A4.%20%20%0D%0A%0D%0AYour%20Content%20Goes%20Here%20%20%20%20%20%20%20%20%20%0D%0A%0D%0AExaone%20%EC%9D%B4%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20%20%0D%0A%0D%0AExaone%EC%9D%80%20LG%20AI%20Research%EC%97%90%EC%84%9C%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20%EC%B4%88%EA%B1%B0%EB%8C%80%20%EB%A9%80%ED%8B%B0%EB%AA%A8%EB%8B%AC%20%EC%96%B8%EC%96%B4%20%EB%AA%A8%EB%8D%B8%28large-scale%20multimodal%20language%20model%29%EB%A1%9C%2C%20%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%BF%90%EB%A7%8C%20%EC%95%84%EB%8B%88%EB%9D%BC \"Vk\")[](mailto:?subject=Exaone%20%EC%9D%80%20%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%3F%20LG%EA%B0%80%20%EA%B0%9C%EB%B0%9C%ED%95%9C%20LLM%20%EB%AA%A8%EB%8D%B8&body=https%3A%2F%2Fwww.msap.ai%2Fblog-home%2Fblog%2Fexaone-lg-llm%2F \"Email\")\n\n*   ![Image 5: AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/wp-content/uploads/2025/04/msap-title-ai-accelerators.webp)[AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/blog-home/blog/ai-accelerators/)[](https://www.msap.ai/blog-home/blog/ai-accelerators/)   \n\n[AI 가속기란 무엇인가? GPU, NPU, TPU 대세는?](https://www.msap.ai/blog-home/blog/ai-accelerators/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T14:43:37+09:00 2025년 04월 04일|\n\n[Read More](https://www.msap.ai/blog-home/blog/ai-accelerators/)\n\n*   ![Image 6: LLM](https://www.msap.ai/wp-content/uploads/2025/03/250326-ChatGPT%EB%8A%94%EC%95%84%EB%8A%94%EB%8D%B0LLM%EC%9D%80.webp)[ChatGPT는 아는데, LLM은 무엇인가요?](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)[](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)   \n\n[ChatGPT는 아는데, LLM은 무엇인가요?](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T15:09:19+09:00 2025년 03월 26일|\n\n[Read More](https://www.msap.ai/blog-home/blog/llm-and-chatgpt/)\n\n*   ![Image 7: LLM ( Chatgpt ) 을 효과적으로 활용하기 위한 26가지 프롬프트 원칙](https://www.msap.ai/wp-content/uploads/2025/03/msap-title-llm-chatgpt-prompt.webp)[LLM ( Chatgpt )을 효과적으로 활용하는 26가지 프롬프트 원칙](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)[](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)   \n\n[LLM ( Chatgpt )을 효과적으로 활용하는 26가지 프롬프트 원칙](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T15:08:01+09:00 2025년 03월 27일|\n\n[Read More](https://www.msap.ai/blog-home/blog/llm-chatgpt-prompt/)\n\n*   ![Image 8: workshop](https://www.msap.ai/wp-content/uploads/2025/05/250520-MSA-Conveyor-Belt-1-Day-Workshop_title.webp)[MSA 도입, AI로 혁신을 경험하세요: MSA Conveyor Belt 1 Day Workshop](https://www.msap.ai/blog-home/blog/msa-1day-ws/)[](https://www.msap.ai/blog-home/blog/msa-1day-ws/)   \n\n[MSA 도입, AI로 혁신을 경험하세요: MSA Conveyor Belt 1 Day Workshop](https://www.msap.ai/blog-home/blog/msa-1day-ws/)\n\n[MSAP.ai](https://www.msap.ai/author/msapadm/ \"MSAP.ai 작성 글\")2025-07-09T14:35:10+09:00 2025년 05월 20일|\n\n[Read More](https://www.msap.ai/blog-home/blog/msa-1day-ws/)\n\n![Image 9: MSAP.ai](https://www.msap.ai/wp-content/uploads/2025/01/msap_ci_gray_h40.webp)\n\n엠에스에이피닷에이아이 | MSAP.ai\n\n주소: 경기 성남 분당 성남대로 331번길 11-3, 5층\n\n (정자동, 여민빌딩)\n\n 메일: [hello@msap.ai](mailto:hello@msap.ai)\n\n[MSAP.ai](https://www.msap.ai/msap-ai/)\n\n[MSA Accelerator](https://www.msap.ai/msap-ai/msa-accelerator/)\n\n[PLATFORM](https://www.msap.ai/msap-ai/platform/)\n\n[AI](https://www.msap.ai/msap-ai/ai-as-a-service/)\n\n[HARDWARE](https://www.msap.ai/msap-ai/hardware/)\n\n[MSAP.ai 제품문의](https://www.msap.ai/msap-ai/solution-contact/)\n\n[컨설팅](https://www.msap.ai/consulting/)\n\n[MSA 특화 컨설팅](https://www.msap.ai/consulting/msa-special-consulting/)\n\n[MSA 설계 및 플랫폼 구축](https://www.msap.ai/consulting/msa-design-platform-deployment/)\n\n[클라우드 네이티브 전환 진단 컨설팅](https://www.msap.ai/consulting/cloud-native-transition-diagnostic-consulting/)\n\n[MSA 전환, IT 현황 진단 서비스](https://www.msap.ai/consulting/msa-it-assessment/)\n\n[MSA Conveyor Belt Workshop 신청](https://www.msap.ai/consulting/msa-workshop/)\n\n[교육](https://www.msap.ai/training/)\n\n[MSA 특화 교육](https://www.msap.ai/training/msa-special-training/)\n\n[MSA 개념과 패턴 교육](https://www.msap.ai/training/msa-concept-pattern-training/)\n\n[찾아가는 MSA & 클라우드 네이티브 세미나](https://www.msap.ai/training/free-cloud-native-seminar/)\n\n[이벤트 & 세미나](https://www.msap.ai/event-seminar/)\n\n[이벤트](https://www.msap.ai/event-seminar/event/)\n\n[세미나](https://www.msap.ai/event-seminar/seminar/)\n\n[블로그](https://www.msap.ai/blog/)\n\n[자료실](https://www.msap.ai/resource/)\n\n[공지사항](https://www.msap.ai/resource/notice/)\n\n[eBooks](https://www.msap.ai/docs/msa-expert-from-concepts-to-practice/)\n\n[Datasheet](https://www.msap.ai/resource/datasheet/)\n\n[Whitepaper](https://www.msap.ai/resource/whitepaper/)\n\n[Solution Briefs](https://www.msap.ai/resource/solution-briefs/)\n\n[Case Studies](https://www.msap.ai/resource/case-studies/)\n\n[Presentation](https://www.msap.ai/resource/presentation/)\n\n[Webinars](https://www.msap.ai/resource/webinars/)\n\n[기술지원](https://www.msap.ai/support/)\n\n[회사](https://www.msap.ai/company/)\n\n[사업영역](https://www.msap.ai/company/business-domain/)\n\n[기업연혁](https://www.msap.ai/company/history/)\n\n[BI 소개](https://www.msap.ai/company/msap-ai-bi-introduce/)\n\n[오시는길](https://www.msap.ai/company/location/)\n\n[MSAP.ai 굿즈 스토어](https://www.msap.ai/goods/)\n\nCopyright 2023 – 2024 MSAP.ai All rights reserved.\n\nCreated by Danny\n\n[Page load link](https://www.msap.ai/blog/exaone-lg-llm/#)[Go to Top](https://www.msap.ai/blog/exaone-lg-llm/#)![Image 10](https://pixel.wp.com/g.gif?v=ext&blog=240426082&post=5690&tz=9&srv=www.msap.ai&j=1%3A14.7&host=www.msap.ai&ref=&fcp=1868&rand=0.40940295582559827)\n"
    },
    {
        "url": "https://changgeun-sql.tistory.com/152",
        "title": "EXAONE 사용 후기 - 돌돌 - 티스토리",
        "content": "# 돌돌\n\n돌돌\n\nLLM\n\n## EXAONE 사용 후기\n\nLG AI 연구원에서 만든 EXAONE이 공개되었다고해서 한번 사용해보았다.\n\n예제 코드가 잘 되어있으니 바로 쓸 수 있었다.\n\n참고 사항\n\n- 개인 계정의 토큰으로 로그인이 필요했다.\n\n### 실행 결과\n\n(서버컴으로 할때는 되었는데, 예시를 보여줄려고 집컴으로 했더니 안된다..ㅠ)\n\n내가 서버컴으로 했을때의 경험을 이야기하면,\n\n1. 말을 잘 생성한다는 느낌을 받았다.\n\n2. 같은 질문을 입력하면 똑같은 대답이 나온다.\n\n- chatgpt같은 다른 LLM 모델과 다른 이질적인 느낌이 들었다.\n\n- 질문에 마침표 몇개만 추가해도 비슷하지만 다른 결과가 나옴\n\n-(추가) 아마도 LLM 캐시로 인해서 같은 답이 나오는 것 같음\n\n3. 할루시네이션을 막기위해 노력한 것은 보임\n\n- 특정 잘못된 질문을 해봐도 사실과 거짓을 잘 분류해서 알려줌\n\n- 그러나 어떤 사건이 발생한 연도를 물어보았을때는 잘 틀리기도 함\n\n### 종합 평가 [...] 말을 생성하는 기본적인 성능에는 만족감을 느낌.\n\n그러나 아직 chatgpt를 대신할 수 있다는 생각은 들지않았음\n\n#### 'LLM' 카테고리의 다른 글\n\n|  |  |\n| --- | --- |\n| LMStudio로 오픈소스 LLM 시작하기  (0) | 2025.01.12 |\n| 알리바바 큐원(Qwen) 2.5: 새로운 오픈소스 LLM  (0) | 2024.12.15 |\n| 라마 3.3 출시: 3.1, 3.2와의 차이점과 새로운 가능성  (0) | 2024.12.15 |\n| ChatGPT o1: 새로운 AI 모델의 등장과 그 의미  (2) | 2024.10.14 |\n| LLama 3.2의 출시: 가정용 PC에서도 가능해진 LLM  (0) | 2024.09.30 |\n\n### Tag\n\n### 'LLM'의 다른글\n\n### 관련글\n\n프로필사진\n\n### Tag\n\n### 최근글과 인기글\n\n### 최근댓글\n\n돌돌55\n\n초록E\n\n### 공지사항\n\n### 페이스북 트위터 플러그인 [...] ### Archives\n\n### Calendar\n\n«   2025/07   »\n\n| 일 | 월 | 화 | 수 | 목 | 금 | 토 |\n| --- | --- | --- | --- | --- | --- | --- |\n|  |  | 1 | 2 | 3 | 4 | 5 |\n| 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n| 13 | 14 | 15 | 16 | 17 | 18 | 19 |\n| 20 | 21 | 22 | 23 | 24 | 25 | 26 |\n| 27 | 28 | 29 | 30 | 31 |  |  |\n\n### 방문자수Total\n\n30,623\n\n## 티스토리툴바",
        "score": 0.44956237,
        "raw_content": "# [돌돌](https://changgeun-sql.tistory.com/ \"돌돌\")\n\n![돌돌](https://tistory1.daumcdn.net/tistory/5354706/skinSetting/4aa59a19cbd5416388219624c3037866)\n\nLLM\n\n## EXAONE 사용 후기\n\nLG AI 연구원에서 만든 EXAONE이 공개되었다고해서 한번 사용해보았다.\n\n![](https://blog.kakaocdn.net/dna/c5D9QE/btsI3dITehj/AAAAAAAAAAAAAAAAAAAAAKKg0BIjUoPb2Z3pKVYH6znBFzt7GfBk0Fni73LN_ZKz/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=n5qwBvE3oHBuRBo%2FZ5JlZ3i7GiE%3D)\n\n![](https://blog.kakaocdn.net/dna/c5D9QE/btsI3dITehj/AAAAAAAAAAAAAAAAAAAAAKKg0BIjUoPb2Z3pKVYH6znBFzt7GfBk0Fni73LN_ZKz/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=n5qwBvE3oHBuRBo%2FZ5JlZ3i7GiE%3D)\n\n예제 코드가 잘 되어있으니 바로 쓸 수 있었다.\n\n참고 사항\n\n- 개인 계정의 토큰으로 로그인이 필요했다.\n\n![](https://blog.kakaocdn.net/dna/csFCYi/btsI4oQeqUW/AAAAAAAAAAAAAAAAAAAAAA_mIfXj7BUv-JXQxNQcTKN7u3NXXTH5k-3HN2foRDhn/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=Jvv4Hu4EVROsy5Mo6sPJhmy%2B2HQ%3D)\n![](https://blog.kakaocdn.net/dna/b2ew3J/btsI4TPYk0s/AAAAAAAAAAAAAAAAAAAAAI6fibBk-6nXkHfe2vCqfL13lNq2EbgduWtf659rCht9/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=1xpWZimJ%2FBqunHzKa2QgCWG1S0g%3D)\n\n![](https://blog.kakaocdn.net/dna/csFCYi/btsI4oQeqUW/AAAAAAAAAAAAAAAAAAAAAA_mIfXj7BUv-JXQxNQcTKN7u3NXXTH5k-3HN2foRDhn/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=Jvv4Hu4EVROsy5Mo6sPJhmy%2B2HQ%3D)\n![](https://blog.kakaocdn.net/dna/b2ew3J/btsI4TPYk0s/AAAAAAAAAAAAAAAAAAAAAI6fibBk-6nXkHfe2vCqfL13lNq2EbgduWtf659rCht9/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1753973999&allow_ip=&allow_referer=&signature=1xpWZimJ%2FBqunHzKa2QgCWG1S0g%3D)\n\n### 실행 결과\n\n(서버컴으로 할때는 되었는데, 예시를 보여줄려고 집컴으로 했더니 안된다..ㅠ)\n\n내가 서버컴으로 했을때의 경험을 이야기하면,\n\n1. 말을 잘 생성한다는 느낌을 받았다.\n\n2. 같은 질문을 입력하면 똑같은 대답이 나온다.\n\n- chatgpt같은 다른 LLM 모델과 다른 이질적인 느낌이 들었다.\n\n- 질문에 마침표 몇개만 추가해도 비슷하지만 다른 결과가 나옴\n\n-(추가) 아마도 LLM 캐시로 인해서 같은 답이 나오는 것 같음\n\n3. 할루시네이션을 막기위해 노력한 것은 보임\n\n- 특정 잘못된 질문을 해봐도 사실과 거짓을 잘 분류해서 알려줌\n\n- 그러나 어떤 사건이 발생한 연도를 물어보았을때는 잘 틀리기도 함\n\n### 종합 평가\n\n말을 생성하는 기본적인 성능에는 만족감을 느낌.\n\n그러나 아직 chatgpt를 대신할 수 있다는 생각은 들지않았음\n\n#### '[LLM](/category/LLM)' 카테고리의 다른 글\n\n|  |  |\n| --- | --- |\n| [LMStudio로 오픈소스 LLM 시작하기](/166)  (0) | 2025.01.12 |\n| [알리바바 큐원(Qwen) 2.5: 새로운 오픈소스 LLM](/159)  (0) | 2024.12.15 |\n| [라마 3.3 출시: 3.1, 3.2와의 차이점과 새로운 가능성](/158)  (0) | 2024.12.15 |\n| [ChatGPT o1: 새로운 AI 모델의 등장과 그 의미](/156)  (2) | 2024.10.14 |\n| [LLama 3.2의 출시: 가정용 PC에서도 가능해진 LLM](/154)  (0) | 2024.09.30 |\n\n### Tag\n\n### 'LLM'의 다른글\n\n### 관련글\n\n![프로필사진](https://tistory1.daumcdn.net/tistory/5354706/attach/da5774a6e9ab43d69b54bb24dd127826)\n\n### Tag\n\n### 최근글과 인기글\n\n### 최근댓글\n\n돌돌55\n\n초록E\n\n### 공지사항\n\n### 페이스북 트위터 플러그인\n\n### Archives\n\n### Calendar\n\n[«](/archive/202506 \"1개월 앞의 달력을 보여줍니다.\")   [2025/07](/archive/202507 \"현재 달의 달력을 보여줍니다.\")   [»](/archive/202508 \"1개월 뒤의 달력을 보여줍니다.\")\n\n| 일 | 월 | 화 | 수 | 목 | 금 | 토 |\n| --- | --- | --- | --- | --- | --- | --- |\n|  |  | 1 | 2 | 3 | 4 | [5](/archive/20250705) |\n| 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n| 13 | 14 | 15 | 16 | 17 | 18 | 19 |\n| 20 | 21 | 22 | 23 | 24 | 25 | 26 |\n| 27 | 28 | 29 | 30 | 31 |  |  |\n\n### 방문자수Total\n\n30,623\n\n## 티스토리툴바"
    }
]