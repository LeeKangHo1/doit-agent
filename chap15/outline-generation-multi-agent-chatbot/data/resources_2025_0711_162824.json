[
    {
        "url": "https://www.lgresearch.ai/data/upload/EXAONE_Deep__Model_Card.pdf",
        "title": "[PDF] EXAONE Deep: Reasoning Enhanced Language Models",
        "content": "63.6 54.8 60.0 53.8 84.4 52.5 47.9 54.3 46.6 79.2 28.9 23.9 33.8 16.9 65.6 83.3 76.7 83.3 56.7 80.0 53.3 80.0 66.7 76.7 73.3 52.7 36.7 EXAONE-Deep-7.8B DeepSeek-R1-Qwen-7B DeepSeek-R1-Llama-8B OpenAI-o1-mini EXAONE-Deep-2.4B DeepSeek-R1-Qwen-1.5B Figure 1: Overall performance comparison. EXAONE Deep 32B model demonstrates competitive performance com-pared to leading open-weight reasoning models such as QwQ-32B and DeepSeek-R1. It also outperforms both DeepSeek-R1-Distill-Qwen-32B and [...] Furthermore, the EXAONE Deep 7.8B model demonstrates superior performance compared to models of similar scale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B. It also outperforms the proprietary reasoning model: OpenAI o1-mini.\nRegarding the EXAONE Deep 2.4B, it outperforms the DeepSeek-R1-Distill-Qwen-1.5B. Our experimental results highlight the EXAONE Deep models demonstrate enhanced reasoning capabilities across different model sizes. [...] The performance evaluation of the models indicates that, for the 2.4B variant, it demonstrates superior performance compared to DeepSeek-R1-Distill-Qwen-1.5B . For the 7.8B variant, it outperforms not only open-weight models of comparable scale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B  but also a proprietary reasoning model OpenAI o1-mini . In the case of the 32B model, its performance is competitive to that of the leading open-weight reasoning models such as QwQ-32B",
        "score": 0.80625874,
        "raw_content": "EXAONE Deep: Reasoning Enhanced Language Models LG AI Research∗ Abstract We present EXAONE Deep series, which exhibits superior capabilities in various reasoning tasks, including math and coding benchmarks. We train our models mainly on the reasoning-specialized dataset that incorporates long streams of thought processes. Evaluation results show that our smaller models, EXAONE Deep 2.4B and 7.8B, outperform other models of comparable size, while the largest model, EXAONE Deep 32B, demonstrates competitive performance against leading open-weight models. All EXAONE Deep models are openly available for research purposes and can be downloaded from https://huggingface.co/LGAI-EXAONE.\nAIME 2024 AIME 2025 GPQA Diamond LiveCodeBench CSAT Math 2025 50 60 70 80 90 100 72.1 65.8 66.1 59.5 94.5 72.6 55.2 62.1 57.2 84.1 79.5 67.1 63.3 63.4 94.4 70.0 53.9 65.2 57.5 88.8 79.8 66.8 71.5 65.9 89.9 90.0 80.0 83.3 73.3 86.7 76.7 86.7 66.7 86.7 80.0 EXAONE-Deep-32B DeepSeek-R1-Qwen-32B QwQ-32B DeepSeek-R1-Llama-70B DeepSeek-R1 (671B) AIME 2024 AIME 2025 GPQA Diamond LiveCodeBench CSAT Math 2025 0 20 40 60 80 100 70.0 59.6 62.6 55.2 89.9 55.5 38.5 49.1 37.6 79.7 50.4 33.6 49.0 39.6 74.1 63.6 54.8 60.0 53.8 84.4 52.5 47.9 54.3 46.6 79.2 28.9 23.9 33.8 16.9 65.6 83.3 76.7 83.3 56.7 80.0 53.3 80.0 66.7 76.7 73.3 52.7 36.7 EXAONE-Deep-7.8B DeepSeek-R1-Qwen-7B DeepSeek-R1-Llama-8B OpenAI-o1-mini EXAONE-Deep-2.4B DeepSeek-R1-Qwen-1.5B Figure 1: Overall performance comparison. EXAONE Deep 32B model demonstrates competitive performance com-pared to leading open-weight reasoning models such as QwQ-32B and DeepSeek-R1. It also outperforms both DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B. The lightly colored regions in AIME 2024 and 2025 show the performance of majority vote (consensus).\n∗The complete list of authors who contributed to this work can be found in Appendix A.\n1 Introduction Recently, there has been a growing trend in research to enhance reasoning performance by adjusting computing resources during the testing phase [16]. In response to this trend, LG AI Research is introducing a new model lineup called EXAONE Deep 2.4B, 7.8B, and 32B. These models are fine-tuned versions of the EXAONE 3.5 series [7], specifically optimized for reasoning tasks. We have trained these models using three prominent techniques widely employed for fine-tuning: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Online Reinforcement Learning (Online RL).\nThe performance evaluation of the models indicates that, for the 2.4B variant, it demonstrates superior performance compared to DeepSeek-R1-Distill-Qwen-1.5B [3]. For the 7.8B variant, it outperforms not only open-weight models of comparable scale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B [3] but also a proprietary reasoning model OpenAI o1-mini [13]. In the case of the 32B model, its performance is competitive to that of the leading open-weight reasoning models such as QwQ-32B [14] and DeepSeek-R1 [3], and is superior to that of DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B [3] as illustrated in Figure 1.\nThoughts become words, words become deeds, deeds become habits, habits become character, and character becomes destiny. Therefore watch the <thought>s of your mind with the sleepless eye of your mind.\n- TRYON EDWARDS 2 Modeling 2.1 Data To enhance the reasoning capabilities of language models, we have utilized 1.6M instances for SFT, 20K instances of preference data for DPO, and an additional 10K instances for Online RL. The SFT dataset contains approximately 12B tokens, with its length distribution illustrated in Figure 2. The dataset is designed to guide models in performing reasoning through an extended chain-of-thought (CoT) process, as illustrated in Figure 3.\n0 10000 20000 Token Count 0 20000 40000 60000 80000 Frequency Overall science code math others 0 10000 20000 Token Count 0 10000 20000 30000 Math 0 10000 20000 Token Count 0 10000 20000 30000 Code 0 10000 20000 Token Count 0 5000 10000 15000 20000 25000 Science 0 10000 20000 Token Count 0 2500 5000 7500 10000 12500 Others Figure 2: Distribution of token counts of the SFT dataset. Data points in the Code domain are notably longer on average, whereas those in the Others domain tend to be shorter.\n2.2 Training The base models of EXAONE Deep are EXAONE 3.5 Instruct models [8, 9, 10], which are instruction-tuned models possessing instruction-following capabilities. To enhance the reasoning abilities of EXAONE Deep, we structured SFT and DPO data in a templated format as illustrated in Figure 3. Each training instance consists of a structured thought process followed by a final answer that synthesizes the reasoning steps into a coherent and precise response. Specifically, the EXAONE 3.5 Instruct models are trained to engage in reasoning within the <thought> and </thought> tags, performing step-by-step logical progression along with reflection, self-checking, and correction. The final answer, generated after reasoning, is designed to be self-contained, summarizing the key insights derived from the thought process in a clear and concise manner. This structured approach enables EXAONE Deep to engage in robust reasoning and deliver well-founded answers to a given query. We utilize SimPER [19] as the training algorithm for DPO and our designed GRPO [2] variant for Online RL.\nIn terms of training compute, the EXAONE Deep models are trained using NVIDIA H100 GPU clusters provided by Google Cloud Platform and NVIDIA NeMo Framework. The amount of computation used for pretraining of base models and fine-tuning of enhancing reasoning is presented in Table 1.\n2 SFT Dataset Example Query: Given the complex numbers u, v, and w such that uv = 12+16i, vw = 20−15i, and wu = −30+40i, find real numbers p and q such that u + v + w = p + qi. Determine the value of p2 + q2.\nResponse: <thought> Okay, so I need to find real numbers p and q such that u + v + w = p+ qi, and then compute p2 + q2. The given information is the products of the complex numbers: uv = 12 + 16i, vw = 20 −15i, and wu = −30 + 40i.\nHmm, complex numbers can sometimes be tricky because of their real and imaginary parts, but maybe I can find expressions for u, v, w individually?\nLet me think. If I have three equations involving the products of pairs of these complex numbers, maybe I can multiply all three equations together? Let’s see: uv × vw × wu = (uvw)2. So (uvw)2 = (12 + 16i)(20 −15i)(−30 + 40i). If I compute that product, I can then take the square root to find uvw. But taking the square root of a complex number might give multiple values, but since we’re dealing with complex numbers u, v, w, maybe we can choose a principal root or something. Wait, but maybe there’s a better way.\nAlternatively, if I can express each variable in terms of another. For example, from uv = 12 + 16i, maybe u = (12+16i)/v. Similarly, from vw = 20−15i, w = (20−15i)/v. Then from wu = −30+40i, substituting the expressions for u and w in terms of v, we get [(20 −15i)/v] × [(12 + 16i)/v] = −30 + 40i. That simplifies to (20−15i)(12+16i)/(v2) = −30+40i. Then solving for v2, we get v2 = (20−15i)(12+16i)/(−30+40i).\nThen once we find v2, we can take square roots to find v, and subsequently find u and w.\n... (thought process continues) </thought> For each v, we compute u and w: Case 1: v = 9−13i 5 • u = −2 + 6i • w = 15+5i 2 Case 2: v = −9+13i 5 • u = 2 −6i • w = −15−5i 2 Summing u, v, and w in both cases: Case 1: u + v + w = 73 10 + 59 10i Case 2: u + v + w = −73 10 −59 10i In both cases, p2 + q2 is: \u001273 10 \u00132 + \u001259 10 \u00132 = 732 + 592 100 = 5329 + 3481 100 = 8810 100 = 881 10 Thus, the value of p2 + q2 is: 881 10 Figure 3: An example of SFT dataset. The dataset is specifically designed to facilitate models in conducting reasoning tasks through an extended chain-of-thought methodology.\n3 Model size Pretraining Fine-tuning Total 32B 1.25 × 1024 7.04 × 1021 1.26 × 1024 7.8B 4.21 × 1023 1.71 × 1021 4.23 × 1023 2.4B 9.36 × 1022 5.27 × 1020 9.41 × 1022 Table 1: Amount of computation (FLOPs) for model training.\n3 Evaluation 3.1 Benchmarks We evaluate models on MATH-500 [11], American Invitational Mathematics Examination (AIME) 2024 and 2025 [12], the mathematics sections of South Korea’s College Scholastic Ability Test (CSAT) 2025 [6], GPQA Diamond [15], LiveCodeBench (24.08-25.02) [5], MMLU [4], and MMLU-Pro [18].\nIn the case of CSAT, which includes textual problems and supplementary graphical information, the graphical content is excluded when evaluating the performance. Since most of this graphical information is also available in textual descriptions, its impact on results is considered minimal. In addition, students can choose from three elective subjects — calculus, statistics, and geometry — in the mathematics section. The final score is calculated as the average of the scores obtained in these three elective subjects.\n3.2 Baselines We have conducted comprehensive evaluations against strong baseline such as DeepSeek-R1 as well as comparable-scale baselines such as QwQ-32B, DeepSeek-R1-Distill-Qwen-32B, 7B, 1.5B, DeepSeek-R1-Distill-Llama-70B, 8B, and OpenAI o1-mini (2024-09-12).\n3.3 Evaluation Setup Following the setup described in the DeepSeek-R1 technical report [3], the maximum length of model generations is set to 32K tokens. Additionally, since the lengthy outputs of the reasoning models can vary greatly, as noted in the report, we adopt the pass@k metric [1] to ensure the reliability of model performances. Specifically, we generate k responses for each test case using a sampling temperature of 0.6 and a top-p value of 0.951, and calculate pass@1 as followed: pass@1 = 1 k k X i=1 pi, (1) where pi denotes the correctness of the i-th response. We also report cons@k [3] where the model generates k answers and the final answer is the one generated the most frequently [17].\nThe evaluation prompts used for assessing EXAONE Deep models are shown in Figure 4 and 5. For the CSAT benchmark, both prompts are employed, as it includes short-answer and multiple-choice questions. For baseline models, we report scores from official reports if available; otherwise, we measure performance ourselves. Specifically, for multiple-choice question answering types, we adopt prompts from OpenAI simple-evals framework2. When evaluating short-answer questions, we utilize the MATH-500 prompt from simple-evals for OpenAI o-series models, but use the same prompt with ours (Figure 4) for others, as it aligns with their recommended prompt.\n3.4 Experimental Results The performance comparison between EXAONE Deep and baseline models is conducted across four categories: mathematics, science, coding, and general knowledge. The evaluation results for the mathematics category are presented in Table 2, while those for the other categories are given in Table 3.\n1For QwQ-32B, we additionally applied the recommended top-k = 40 during evaluation. For OpenAI o1-mini, we were unable to adjust sampling parameters to our desired settings; thus, we used temperature = 1 and top-p = 1.\n2https://github.com/openai/simple-evals 4 Prompt for Short-Answer Questions {{question}} Please reason step by step, and put your final answer within \\boxed{}.\nFigure 4: Prompt for evaluating models on short-answer questions. We apply the prompt to the MATH-500, AIME 2024/2025, and CSAT 2025 benchmarks.\nPrompt for Multiple-Choice Questions Question : {{question}} Options : A) {{option A}} B) {{option B}} ...\nPlease reason step by step, and you should write the correct option alphabet within \\boxed{}.\nFigure 5: Prompt used for evaluating EXAONE Deep models on multiple-choice questions. We apply the prompt to the CSAT 2025, GPQA Diamond, MMLU, and MMLU-Pro benchmarks. The number of options is adjusted for each test case.\nWe find that the EXAONE Deep 32B model exhibits competitive performance, rivaling leading open-weight reasoning models such as DeepSeek-R1 and QwQ-32B. Notably, it outperforms the distilled versions of DeepSeek-R1, including DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B.\nFurthermore, the EXAONE Deep 7.8B model demonstrates superior performance compared to models of similar scale such as DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B. It also outperforms the proprietary reasoning model: OpenAI o1-mini.\nRegarding the EXAONE Deep 2.4B, it outperforms the DeepSeek-R1-Distill-Qwen-1.5B. Our experimental results highlight the EXAONE Deep models demonstrate enhanced reasoning capabilities across different model sizes.\nModel MATH-500 (pass@1) AIME 2024 (pass@1) AIME 2024 (cons@64) AIME 2025 (pass@1) AIME 2025 (cons@64) CSAT 2025 (pass@1) EXAONE Deep 32B 95.7 72.1 90.0 65.8 80.0 94.5 DeepSeek-R1-Distill-Qwen-32B 94.3* 72.6* 83.3* 55.2 73.3 84.1 QwQ-32B 95.5 79.5* 86.7 67.1 76.7 94.4 DeepSeek-R1-Distill-Llama-70B 94.5* 70.0* 86.7* 53.9 66.7 88.8 DeepSeek-R1 (671B) 97.3* 79.8* 86.7 66.8 80.0 89.9 EXAONE Deep 7.8B 94.8 70.0 83.3 59.6 76.7 89.9 DeepSeek-R1-Distill-Qwen-7B 92.8* 55.5* 83.3* 38.5 56.7 79.7 DeepSeek-R1-Distill-Llama-8B 89.1* 50.4* 80.0* 33.6 53.3 74.1 OpenAI o1-mini 90.0* 63.6* 80.0* 54.8 66.7 84.4 EXAONE Deep 2.4B 92.3 52.5 76.7 47.9 73.3 79.2 DeepSeek-R1-Distill-Qwen-1.5B 83.9* 28.9* 52.7* 23.9 36.7 65.6 Table 2: Comparison between EXAONE Deep and baseline models in the Mathematics category. The asterisk (*) indicates figures that have been officially reported. When calculating pass@1 score, we set k in Equation 1 as 8 for MATH-500, 16 for CSAT 2025, and 64 for AIME 2024 and 2025. For AIME 2024 and 2025, we also report cons@64.\nFor CSAT 2025, the individual scores for the elective subjects can be found in Table 4 within Appendix C. Bold scores indicate the best performance, and underlined scores mean the second best.\n5 Model GPQA Diamond (pass@1) LiveCodeBench (pass@1) MMLU (accuracy) MMLU-Pro (accuracy) EXAONE Deep 32B 66.1 59.5 83.0 74.0 DeepSeek-R1-Distill-Qwen-32B 62.1* 57.2* 83.6 77.2 QwQ-32B 63.3 63.4* 87.4 79.1 DeepSeek-R1-Distill-Llama-70B 65.2* 57.5* 89.1 79.4 DeepSeek-R1 (671B) 71.5* 65.9* 90.8* 84.0 EXAONE Deep 7.8B 62.6 55.2 75.0 65.7 DeepSeek-R1-Distill-Qwen-7B 49.1* 37.6* 57.7 59.3 DeepSeek-R1-Distill-Llama-8B 49.0* 39.6* 74.4 60.6 OpenAI o1-mini 60.0* 53.8* 85.2* 80.3 EXAONE Deep 2.4B 54.3 46.6 65.8 56.4 DeepSeek-R1-Distill-Qwen-1.5B 33.8* 16.9* 33.8 39.3 Table 3: Comparison between EXAONE Deep and baseline models in the Science (GPQA Diamond), Coding (LiveCodeBench), and General (MMLU and MMLU-Pro) categories. The asterisk (*) indicates figures that have been officially reported. When calculating pass@1 score, we set k in Equation 1 as 6 for LiveCodeBench and 16 for GPQA Diamond. Bold scores indicate the best performance, and underlined scores mean the second best.\n4 Limitations The EXAONE Deep models introduced in this document are specifically fine-tuned to excel at reasoning tasks. Though their base models are instruction-fine-tuned and generally capable of following instructions, for addressing a wider range of real-world use cases, we strongly recommend utilizing the EXAONE 3.5 Instruct models [8, 9, 10], which are optimized for practical application scenarios.\n5 Deployment Section B in the Appendix provides license information for using the EXAONE Deep models. Understanding the license information is essential for the legal utilization of the language model.\n6 Conclusion In this document, we presented three specialized reasoning models: EXAONE Deep 2.4B, 7.8B, and 32B. Despite the emergence of various methodologies aimed at improving reasoning capabilities, we have chosen to rely on well-established approaches such as SFT, DPO, and Online RL, achieving superior or competitive performance relative to models of comparable scale. Our results highlight the effectiveness and practicality of these proven techniques in advancing reasoning performance. At present, these models are primarily engaged in problem-solving in domains where clear answers are available, such as mathematics, science, and coding. Looking ahead, we aim to extend their capabilities into areas where answers are less clear or yet to be discovered, thereby broadening their impact and utility.\nOur models are available to everyone for research purposes, and we welcome your feedback to help us improve the models. If you have any feedback or are interested in exploring commercial opportunities with our models, please reach out to contact_us@lgresearch.ai.\n6 A Contributors All authors are listed in alphabetical order by last name.\nCore Contributors Eunbi Choi, Kibong Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Hyunjik Jo, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Haeju Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Heuiyeen Yeen, Hyeongu Yun Contributors Kyunghoon Bae, Stanley Jungkyu Choi, Yemuk Choi, Kijeong Jeon, Gerrard Jeongwon Jo, Jiyeon Jung, Hyosang Kim, Youchul Kim, Edward Hwayoung Lee, Honglak Lee, Yongmin Park, Sihoon Yang, Sihyuk Yi 7 B Model License EXAONE AI Model License Agreement 1.1 - NC This License Agreement (“Agreement”) is entered into between you (“Licensee”) and LG Management De-velopment Institute Co., Ltd. (“Licensor”), governing the use of the EXAONE AI Model (“Model”). By downloading, installing, copying, or using the Model, you agree to comply with and be bound by the terms of this Agreement. If you do not agree to all the terms, you must not download, install, copy, or use the Model. This Agreement constitutes a binding legal agreement between the Licensee and Licensor.\n1. Definitions 1.1 Model: The artificial intelligence model provided by Licensor, which includes any software, algorithms, machine learning models, or related components supplied by Licensor. This definition extends to encompass all updates, enhancements, improvements, bug fixes, patches, or other modifications that may be provided by Licensor from time to time, whether automatically or manually implemented.\n1.2 Derivatives: Any modifications, alterations, enhancements, improvements, adaptations, or derivative works of the Model created by Licensee or any third party. This includes changes made to the Model’s architecture, parame-ters, data processing methods, or any other aspect of the Model that results in a modification of its functionality or output.\n1.3 Output: Any data, results, content, predictions, analyses, insights, or other materials generated by the Model or Derivatives, regardless of whether they are in their original form or have been further processed or modified by the Licensee. This includes, but is not limited to, textual or numerical produced directly or indirectly through the use of the Model.\n1.4 Licensor: LG Management Development Institute Co., Ltd., the owner, developer, and provider of the EXAONE AI Model. The Licensor holds all rights, title, and interest in the Model and is responsible for granting licenses to use the Model under the terms specified in this Agreement.\n1.5 Licensee: The individual, organization, corporation, academic institution, government agency, or other entity using or intending to use the Model under the terms and conditions of this Agreement. The Licensee is responsible for ensuring compliance with the Agreement by all authorized users who access or utilize the Model on behalf of the Licensee.\n2. License Grant 2.1 Grant of License: Subject to the terms and conditions outlined in this Agreement, the Licensor hereby grants the Licensee a limited, non-exclusive, non-transferable, worldwide, and revocable license to: a. Access, download, install, and use the Model solely for research purposes. This includes evaluation, test-ing, academic research, experimentation, and participation in competitions, provided that such participation is in a non-commercial context. Notwithstanding Section 3.1, the Licensee may only provide the Model or Derivatives for a competition if no commercial license is granted to the competition organizer or any third party.\nb. Publicly disclose research results and findings derived from the use of the Model or Derivatives, including publishing papers or presentations.\nc. Modify the Model and create Derivatives based on the Model, provided that such modifications and Derivatives are used exclusively for research purposes. The Licensee may conduct experiments, perform analyses, and apply custom modifications to the Model to explore its capabilities and performance under various scenarios. If the Model is modified, the modified Model must include “EXAONE” at the beginning of its name.\nd. Distribute the Model and Derivatives in each case with a copy of this Agreement.\n2.2 Scope of License: The license granted herein does not authorize the Licensee to use the Model for any purpose not explicitly permitted under this Agreement. Any use beyond the scope of this license, including any com-mercial application or external distribution, is strictly prohibited unless explicitly agreed upon in writing by the Licensor.\n8 3. Restrictions 3.1 Commercial Use: The Licensee is expressly prohibited from using the Model, Derivatives, or Output for any commercial purposes, including but not limited to, developing or deploying products, services, or applications that generate revenue, whether directly or indirectly. Any commercial exploitation of the Model or its derivatives requires a separate commercial license agreement with the Licensor. Furthermore, the Licensee shall not use the Model, Derivatives or Output to develop or improve other models.\n3.2 Reverse Engineering: The Licensee shall not decompile, disassemble, reverse engineer, or attempt to derive the source code, underlying ideas, algorithms, or structure of the Model, except to the extent that such activities are expressly permitted by applicable law. Any attempt to bypass or circumvent technological protection measures applied to the Model is strictly prohibited.\n3.3 Unlawful Use: The Licensee shall not use the Model and Derivatives for any illegal, fraudulent, or unau-thorized activities, nor for any purpose that violates applicable laws or regulations. This includes but is not limited to the creation, distribution, or dissemination of malicious, deceptive, or unlawful content.\n3.4 Ethical Use: The Licensee shall ensure that the Model or Derivatives is used in an ethical and responsi-ble manner, adhering to the following guidelines: a. The Model and Derivatives shall not be used to generate, propagate, or amplify false, misleading, or harm-ful information, including fake news, misinformation, or disinformation.\nb. The Model and Derivatives shall not be employed to create, distribute, or promote content that is discrimi-natory, harassing, defamatory, abusive, or otherwise offensive to individuals or groups based on race, gender, sexual orientation, religion, nationality, or other protected characteristics.\nc. The Model and Derivatives shall not infringe on the rights of others, including intellectual property rights, privacy rights, or any other rights recognized by law. The Licensee shall obtain all necessary permissions and consents before using the Model and Derivatives in a manner that may impact the rights of third parties.\nd. The Model and Derivatives shall not be used in a way that causes harm, whether physical, mental, emo-tional, or financial, to individuals, organizations, or communities. The Licensee shall take all reasonable measures to prevent misuse or abuse of the Model and Derivatives that could result in harm or injury.\n4. Ownership 4.1 Intellectual Property: All rights, title, and interest in and to the Model, including any modifications, Derivatives, and associated documentation, are and shall remain the exclusive property of the Licensor. The Licensee acknowledges that this Agreement does not transfer any ownership rights to the Licensee. All trademarks, service marks, and logos associated with the Model are the property of the Licensor.\n4.2 Output: All rights, title, and interest in and to the Output generated by the Model and Derivatives whether in its original form or modified, are and shall remain the exclusive property of the Licensor. Licensee may use, modify, and distribute the Output and its derivatives for research purpose. The Licensee shall not claim ownership of the Output except as expressly provided in this Agreement. The Licensee may use the Output solely for the purposes permitted under this Agreement and shall not exploit the Output for unauthorized or commercial purposes.\n4.3 Attribution: In any publication or presentation of results obtained using the Model, the Licensee shall provide appropriate attribution to the Licensor, citing the Model’s name and version, along with any relevant documentation or references specified by the Licensor.\n9 5. No Warranty 5.1 “As-Is” Basis: The Model, Derivatives, and Output are provided on an “as-is” and “as-available” basis, without any warranties or representations of any kind, whether express, implied, or statutory. The Licensor disclaims all warranties, including but not limited to, implied warranties of merchantability, fitness for a partic-ular purpose, accuracy, reliability, non-infringement, or any warranty arising from the course of dealing or usage of trade.\n5.2 Performance and Reliability: The Licensor does not warrant or guarantee that the Model, Derivatives or Output will meet the Licensee’s requirements, that the operation of the Model, Derivatives or Output will be uninterrupted or error-free, or that defects in the Model will be corrected. The Licensee acknowledges that the use of the Model, Derivatives or Output is at its own risk and that the Model, Derivatives or Output may contain bugs, errors, or other limitations.\n5.3 No Endorsement: The Licensor does not endorse, approve, or certify any results, conclusions, or recom-mendations derived from the use of the Model. The Licensee is solely responsible for evaluating the accuracy, reliability, and suitability of the Model for its intended purposes.\n6. Limitation of Liability 6.1 No Liability for Damages: To the fullest extent permitted by applicable law, in no event shall the Licen-sor be liable for any special, incidental, indirect, consequential, exemplary, or punitive damages, including but not limited to, damages for loss of business profits, business interruption, loss of business information, loss of data, or any other pecuniary or non-pecuniary loss arising out of or in connection with the use or inability to use the Model, Derivatives or any Output, even if the Licensor has been advised of the possibility of such damages.\n6.2 Indemnification: The Licensee agrees to indemnify, defend, and hold harmless the Licensor, its affili-ates, officers, directors, employees, and agents from and against any claims, liabilities, damages, losses, costs, or expenses (including reasonable attorneys’ fees) arising out of or related to the Licensee’s use of the Model, any Derivatives, or any Output, including any violation of this Agreement or applicable laws.\n7. Termination 7.1 Termination by Licensor: The Licensor reserves the right to terminate this Agreement and revoke the Licensee’s rights to use the Model at any time, with or without cause, and without prior notice if the Licensee breaches any of the terms or conditions of this Agreement. Termination shall be effective immediately upon notice.\n7.2 Effect of Termination: Upon termination of this Agreement, the Licensee must immediately cease all use of the Model, Derivatives, and Output and destroy all copies of the Model, Derivatives, and Output in its possession or control, including any backup or archival copies. The Licensee shall certify in writing to the Licensor that such destruction has been completed.\n7.3 Survival: The provisions of this Agreement that by their nature should survive termination, including but not limited to, Sections 4 (Ownership), 5 (No Warranty), 6 (Limitation of Liability), and this Section 7 (Termination), shall continue to apply after termination.\n8. Governing Law 8.1 Governing Law: This Agreement shall be governed by and construed in accordance with the laws of the Republic of Korea, without regard to its conflict of laws principles.\n8.2 Arbitration: Any disputes, controversies, or claims arising out of or relating to this Agreement, includ-ing its existence, validity, interpretation, performance, breach, or termination, shall be referred to and finally resolved by arbitration administered by the Korean Commercial Arbitration Board (KCAB) in accordance with the International Arbitration Rules of the Korean Commercial Arbitration Board in force at the time of the commencement of the arbitration. The seat of arbitration shall be Seoul, Republic of Korea. The tribunal shall consist of one arbitrator. The language of the arbitration shall be English.\n10 9. Alterations 9.1 Modifications: The Licensor reserves the right to modify or amend this Agreement at any time, in its sole discretion. Any modifications will be effective upon posting the updated Agreement on the Licensor’s website or through other means of communication. The Licensee is responsible for reviewing the Agreement periodically for changes. Continued use of the Model after any modifications have been made constitutes acceptance of the revised Agreement.\n9.2 Entire Agreement: This Agreement constitutes the entire agreement between the Licensee and Licensor concerning the subject matter hereof and supersedes all prior or contemporaneous oral or written agreements, representations, or understandings. Any terms or conditions of any purchase order or other document submitted by the Licensee in connection with the Model that are in addition to, different from, or inconsistent with the terms and conditions of this Agreement are not binding on the Licensor and are void.\nBy downloading, installing, or using the EXAONE AI Model, the Licensee acknowledges that it has read, understood, and agrees to be bound by the terms and conditions of this Agreement.\n11 C Evaluation Details Model CSAT 2025 Calculus (pass@1) CSAT 2025 Statistics (pass@1) CSAT 2025 Geometry (pass@1) EXAONE Deep 32B 95.1 95.0 93.5 QwQ-32B 94.5 95.5 93.3 DeepSeek-R1 (671B) 89.4 90.8 89.6 DeepSeek-R1-Distill-Llama-70B 88.1 90.3 88.1 DeepSeek-R1-Distill-Qwen-32B 84.3 84.4 83.5 EXAONE Deep 7.8B 89.5 91.8 88.5 OpenAI o1-mini 82.8 85.9 84.6 DeepSeek-R1-Distill-Qwen-7B 75.6 83.8 79.6 DeepSeek-R1-Distill-Llama-8B 70.6 79.0 72.6 EXAONE Deep 2.4B 74.4 82.4 80.8 DeepSeek-R1-Distill-Qwen-1.5B 64.4 67.6 64.6 Table 4: Comparison of EXAONE Deep with baseline models in the individual scores for the elective subjects at the CSAT 2025 benchmark. Bold scores indicate the best performance, and underlined scores mean the second best.\n12 References [1] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating Large Language Models Trained on Code. https://arxiv.org/abs/2107.03374, 2021.\n[2] DeepSeek-AI. DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model. https: //arxiv.org/abs/2405.04434, 2024.\n[3] DeepSeek-AI. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. https: //arxiv.org/abs/2501.12948, 2025.\n[4] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.\nMeasuring Massive Multitask Language Understanding. https://arxiv.org/abs/2009.03300, 2021.\n[5] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code. https://arxiv.org/abs/2403.07974, 2024.\n[6] Korea Institute for Curriculum and Evaluation. College Scholastic Ability Test. https://www.suneung.re.kr, 2025.\n[7] LG AI Research. EXAONE 3.5: Series of Large Language Models for Real-world Use Cases. https://arxiv.\norg/abs/2412.04862, 2024.\n[8] LG AI Research. EXAONE-3.5-2.4B-Instruct. https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.\n4B-Instruct, 2025.\n[9] LG AI Research.\nEXAONE-3.5-32B-Instruct.\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.\n5-32B-Instruct, 2025.\n[10] LG AI Research. EXAONE-3.5-7.8B-Instruct. https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-7.\n8B-Instruct, 2025.\n[11] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s Verify Step by Step. https://arxiv.org/abs/2305.20050, 2023.\n[12] Mathematical Association of America. American Invitational Mathematics Examination. https://maa.org, 2025.\n[13] OpenAI. OpenAI o1 System Card. https://cdn.openai.com/o1-system-card-20241205.pdf, 2024.\n[14] Qwen Team. QwQ-32B: Embracing the Power of Reinforcement Learning. https://qwenlm.github.io/ blog/qwq-32b, 2025.\n[15] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. GPQA: A Graduate-Level Google-Proof Q&A Benchmark. https://arxiv.\norg/abs/2311.12022, 2023.\n[16] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters. https://arxiv.org/abs/2408.03314, 2024.\n[17] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-Consistency Improves Chain of Thought Reasoning in Language Models. https://arxiv.org/ abs/2203.11171, 2023.\n13 [18] Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, and Wenhu Chen. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.\nhttps://arxiv.org/abs/2406.01574, 2024.\n[19] Teng Xiao, Yige Yuan, Zhengyu Chen, Mingxiao Li, Shangsong Liang, Zhaochun Ren, and Vasant G Honavar.\nSimPER: A Minimalist Approach to Preference Alignment without Hyperparameters. https://arxiv.org/ abs/2502.00883, 2025.\n14"
    },
    {
        "url": "https://zdnet.co.kr/view/?no=20250322134718",
        "title": "LG의 새 AI '엑사원 딥', 수능서 94.5% 정답률...수학·코딩 능력 탁월",
        "content": "성능 평가 결과에 따르면, 가장 작은 모델인 EXAONE Deep 2.4B는 DeepSeek-R1-Distill-Qwen-1.5B보다 우수한 성능을 보여주었다. 중간 크기인 7.8B 모델은 DeepSeek-R1-Distill-Qwen-7B와 DeepSeek-R1-Distill-Llama-8B 같은 오픈 웨이트 모델뿐만 아니라 상용 추론 모델인 OpenAI o1-mini보다도 뛰어난 성능을 입증했다. 가장 큰 모델인 32B는 QwQ-32B와 DeepSeek-R1 같은 최첨단 오픈 웨이트 추론 모델과 견줄 만한 성능을 보여주었으며, DeepSeek-R1-Distill-Qwen-32B와 DeepSeek-R1-Distill-Llama-70B를 능가했다.\n\nImage 11\n\n단계별 논리적 사고로 무장한 EXAONE Deep, 120억 토큰 데이터로 학습",
        "score": 0.8029425,
        "raw_content": "Published Time: 2025-03-22T13:47:18+09:00\n\nLG의 새 AI ‘엑사원 딥’, 수능서 94.5% 정답률...수학·코딩 능력 탁월 - ZDNet korea\n\n===============\n[![Image 1](https://menu.mt.co.kr/news/banner/image/2020/20200703160528.jpg)](https://ads.mtgroup.kr/RealMedia/ads/click_lx.ads/zdnet_pc/news/L13/1223256542/x96/moneytoday/Zdnet_PC_PV/Zdnet_PC_PV.html/496d417830576877765077414365384e)\n\nZDNet Korea 뉴스레터 구독신청 \n\n[구독신청](javascript:newsletter();)닫기\n\n[![Image 2](https://zdnet.co.kr/images/zdnet_logo.png?ver=20220830)](https://zdnet.co.kr/ \"ZDNetKore\")\n\n*   [ZDNet USA](https://www.zdnet.com/)\n*   [ZDNet China](https://www.zhiding.cn/)\n*   [ZDNet Japan](https://japan.zdnet.com/)\n\n*   [English](https://www.zdnet.com/topic/korea/)\n*   [지디넷 웨비나](https://itsight.zdnet.co.kr/)\n\n[](javascript:void(0))\n\n[](https://zdnet.co.kr/member/)\n\n뉴스\n\n*   [최신뉴스](https://zdnet.co.kr/news/?lstcode=0000&page=1)\n*   [방송/통신](https://zdnet.co.kr/news/?lstcode=0010&page=1)\n*   [컴퓨팅](https://zdnet.co.kr/news/?lstcode=0020&page=1)\n*   [홈&모바일](https://zdnet.co.kr/news/?lstcode=0030&page=1)\n*   [인터넷](https://zdnet.co.kr/news/?lstcode=0040&page=1)\n*   [반도체/디스플레이](https://zdnet.co.kr/news/?lstcode=0050&page=1)\n\n*   [카테크](https://zdnet.co.kr/news/?lstcode=0057&page=1)\n*   [헬스케어](https://zdnet.co.kr/news/?lstcode=0058&page=1)\n*   [게임](https://zdnet.co.kr/news/?lstcode=0060&page=1)\n*   [중기&스타트업](https://zdnet.co.kr/news/?lstcode=0045&page=1)\n*   [유통](https://zdnet.co.kr/news/?lstcode=0055&page=1)\n*   [금융](https://zdnet.co.kr/news/?lstcode=0073&page=1)\n\n*   [과학](https://zdnet.co.kr/news/?lstcode=0070&page=1)\n*   [디지털경제](https://zdnet.co.kr/news/?lstcode=0075&page=1)\n*   [취업/HR/교육](https://zdnet.co.kr/news/?lstcode=0110&page=1)\n*   [인터뷰](https://zdnet.co.kr/news/?lstcode=0100&page=1)\n*   [인사•부음](https://zdnet.co.kr/news/?lstcode=0090&page=1)\n*   [글로벌뉴스](https://zdnet.co.kr/news/?lstcode=0120&page=1)\n\n[인공지능](https://zdnet.co.kr/newskey/?lstcode=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5)\n\n[배터리](https://zdnet.co.kr/newskey/?lstcode=%EB%B0%B0%ED%84%B0%EB%A6%AC)\n\n[양자컴퓨팅](https://zdnet.co.kr/newskey/?lstcode=%EC%96%91%EC%9E%90%EC%BB%B4%ED%93%A8%ED%8C%85)\n\n[컨퍼런스](https://itsight.zdnet.co.kr/)\n\n[칼럼•연재](https://zdnet.co.kr/column/)\n\n[포토•영상](https://zdnet.co.kr/photo/)\n\nLG의 새 AI ‘엑사원 딥’, 수능서 94.5% 정답률...수학·코딩 능력 탁월\n=============================================\n\n[컴퓨팅](https://zdnet.co.kr/news/?lstcode=0020&page=1)입력 :2025/03/22 13:47\n\n![Image 3](https://zdnet.co.kr/Include2/user/pic/reporter/media1@zdnet.co.kr.jpg)\n\n**AI 에디터**[](mailto:media@zdnet.co.kr)[기자의 다른기사 보기](https://zdnet.co.kr/reporter/?lstcode=media)\n\n*   [![Image 4](https://zdnet.co.kr/images/f_on.png)](https://www.facebook.com/sharer/sharer.php?u=)\n*   [![Image 5](https://zdnet.co.kr/images/x_on.png)](https://twitter.com/intent/tweet?text=LG%EC%9D%98%20%EC%83%88%20AI%20%E2%80%98%EC%97%91%EC%82%AC%EC%9B%90%20%EB%94%A5%E2%80%99,%20%EC%88%98%EB%8A%A5%EC%84%9C%2094.5%%20%EC%A0%95%EB%8B%B5%EB%A5%A0...%EC%88%98%ED%95%99%C2%B7%EC%BD%94%EB%94%A9%20%EB%8A%A5%EB%A0%A5%20%ED%83%81%EC%9B%94&url=)\n*   [![Image 6](https://zdnet.co.kr/images/in_on.png)](https://www.linkedin.com/shareArticle?url=)\n*   [![Image 7](https://zdnet.co.kr/images/txt_bt1.gif)](javascript:increaseFontsize('20250322134718');)\n*   [![Image 8](https://zdnet.co.kr/images/txt_bt2.gif)](javascript:decreaseFontsize('20250322134718');)\n*   [![Image 9](https://zdnet.co.kr/images/print_bt.gif)](javascript:article_print('20250322134718'))\n\n![Image 10](https://image.zdnet.co.kr/2025/03/21/aic9b6deee93716d1058502b69c8c25eb6.jpg)\n\n**동급 최강 성능의 EXAONE Deep, 작은 모델도 오픈AI 추월**\n\nLG AI 연구소가 개발한 EXAONE Deep 시리즈가 수학과 코딩 등 다양한 추론 과제에서 뛰어난 성능을 보여주고 있다. EXAONE Deep 시리즈는 2.4B, 7.8B, 32B 세 가지 크기로 출시되었으며, 이 모델들은 기존 EXAONE 3.5 시리즈를 기반으로 추론 능력을 강화하기 위해 특별히 최적화된 버전이다.\n\nEXAONE Deep 모델은 단계적 사고 과정을 포함하는 특화된 데이터셋으로 학습되었다. 연구팀은 지도 학습(Supervised Fine-Tuning, SFT), 직접 선호도 최적화(Direct Preference Optimization, DPO), 온라인 강화학습(Online Reinforcement Learning, Online RL)과 같은 세 가지 주요 기법을 활용해 모델을 훈련시켰다.\n\n성능 평가 결과에 따르면, 가장 작은 모델인 EXAONE Deep 2.4B는 DeepSeek-R1-Distill-Qwen-1.5B보다 우수한 성능을 보여주었다. 중간 크기인 7.8B 모델은 DeepSeek-R1-Distill-Qwen-7B와 DeepSeek-R1-Distill-Llama-8B 같은 오픈 웨이트 모델뿐만 아니라 상용 추론 모델인 OpenAI o1-mini보다도 뛰어난 성능을 입증했다. 가장 큰 모델인 32B는 QwQ-32B와 DeepSeek-R1 같은 최첨단 오픈 웨이트 추론 모델과 견줄 만한 성능을 보여주었으며, DeepSeek-R1-Distill-Qwen-32B와 DeepSeek-R1-Distill-Llama-70B를 능가했다.\n\n![Image 11](https://image.zdnet.co.kr/2025/03/21/ai5014b6b4db3008aaec59f3a1581258d1.jpg)\n\n**단계별 논리적 사고로 무장한 EXAONE Deep, 120억 토큰 데이터로 학습**\n\nEXAONE Deep 모델의 추론 능력을 강화하기 위해 연구팀은 약 160만 건의 SFT 데이터, 2만 건의 선호도 데이터(DPO용), 그리고 1만 건의 온라인 RL 데이터를 활용했다. SFT 데이터셋은 약 120억 개의 토큰을 포함하며, 확장된 사고 연쇄(chain-of-thought) 과정을 통해 모델이 추론을 수행하도록 설계되었다.\n\n특히 눈에 띄는 점은 이 데이터셋의 구조이다. 각 학습 인스턴스는 구조화된 사고 과정과 최종 답변으로 구성되어 있다. EXAONE 3.5 모델은 &lt;thought> 태그 내에서 논리적 진행, 자기 반성, 자체 검사, 수정 등의 단계별 추론을 수행하도록 훈련되었다. 이렇게 추론 후 생성된 최종 답변은 자기 완결적이며, 사고 과정에서 도출된 핵심 통찰력을 명확하고 간결하게 요약한다.\n\n![Image 12](https://idm.skplanet.com/pixel?nid=29&uid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 13](https://cm.mman.kr/cm.mezzo?partnerkey=digitalcamp&buyerid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 14](https://idm.skplanet.com/pixel?nid=29&uid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)![Image 15](https://cm.mman.kr/cm.mezzo?partnerkey=digitalcamp&buyerid=1e3f611063dbc354da595ddfe51e8de71e35c6056f10a57071f29e83396f3d9c)\n\n훈련 계산 리소스 면에서, EXAONE Deep 모델은 Google Cloud Platform과 NVIDIA NeMo FRAMEwork에서 제공하는 NVIDIA H100 GPU 클러스터를 사용하여 훈련되었다. 기본 모델의 사전 훈련과 추론 능력 향상을 위한 미세 조정에 사용된 계산량은 정밀하게 측정되어, 32B 모델의 경우 총 1.26 × 10^24 FLOP가 사용되었다.\n\n**수학 시험에서 빛난 EXAONE Deep, 한국 수능 수학 94.5% 정답률 달성**\n\nEXAONE Deep 모델은 MATH-500, 미국 수학 초청 시험(AIME) 2024/2025, 한국 대학수학능력시험(CSAT) 2025의 수학 영역, GPQA Diamond, LiveCodeBench, MMLU, MMLU-Pro 등 다양한 벤치마크에서 평가되었다.\n\n수학 분야에서 EXAONE Deep 32B 모델은 MATH-500에서 95.7%, AIME 2024에서 72.1%, AIME 2025에서 65.8%, CSAT 2025에서 94.5%의 놀라운 정확도를 보여주었다. 특히 한국 수능 수학 영역의 세 가지 선택 과목인 미적분, 통계, 기하에서 각각 95.1%, 95.0%, 93.5%의 높은 성능을 보여 전체 평균 94.5%라는 인상적인 결과를 달성했다.\n\n과학 및 코딩 분야에서도 EXAONE Deep 32B는 GPQA Diamond에서 66.1%, LiveCodeBench에서 59.5%의 성능을 보여주었다. 일반 지식을 평가하는 MMLU와 MMLU-Pro에서는 각각 83.0%와 74.0%의 정확도를 달성했다.\n\n7.8B 모델 역시 동급의 모델들과 비교해 모든 분야에서 우수한 성능을 보여주었으며, 특히 수학 분야에서는 MATH-500 94.8%, AIME 2024 70.0%, CSAT 2025 89.9%의 높은 정확도를 기록했다.\n\n**무료로 사용 가능한 EXAONE Deep, 상업용은 별도 라이선스 필요**\n\nEXAONE Deep 모델은 연구 목적으로 모든 사람이 사용할 수 있도록 공개되어 있다. 이 모델들은 허깅페이스(Hugging Face)를 통해 다운로드할 수 있다. 그러나 이 모델은 추론 작업에 특화되어 있으므로, 넓은 범위의 실제 사용 사례에 적용하려면 EXAONE 3.5 Instruct 모델 사용을 권장한다. 또한, EXAONE AI 모델 라이선스 계약에 따르면, 이 모델은 상업적 용도로 사용할 수 없으며, 별도의 상업용 라이선스 계약이 필요하다.\n\n**FAQ**\n\n**Q: EXAONE Deep 모델은 어떤 특징이 있나요?**\n\nA: EXAONE Deep은 추론 능력에 특화된 AI 모델로, 단계적 사고 과정을 포함하는 특별한 데이터셋으로 학습되었습니다. 수학, 코딩 등 논리적 추론이 필요한 과제에서 뛰어난 성능을 보이며, 2.4B, 7.8B, 32B 세 가지 크기로 제공됩니다.\n\n**Q: 이 모델은 어떻게 사용할 수 있나요?**\n\nA: EXAONE Deep 모델은 연구 목적으로 누구나 무료로 사용할 수 있으며, 허깅페이스를 통해 다운로드할 수 있습니다. 상업적 목적으로 사용하려면 별도의 라이선스가 필요합니다.\n\n**Q: EXAONE Deep과 다른 AI 모델과의 차이점은 무엇인가요?**\n\n관련기사\n----\n\n*   [\"챗GPT, 노벨상 연구는 불가\"… 생성형 AI의 과학적 한계, 뭐길래?](https://zdnet.co.kr/view/?no=20250322103343)2025.03.22\n*   [[Q&AI] '고공행진' 한화에어로, 주가 15% 폭락…왜?](https://zdnet.co.kr/view/?no=20250321173726)2025.03.21\n*   [[AI연구소] AI로 작성한 이력서, 채용 담당자들은 알아 차릴까](https://zdnet.co.kr/view/?no=20250320094753)2025.03.20\n*   [스테이블코인 대신 카드결제?…금융은 기회 포착했다](https://zdnet.co.kr/view/?no=20250709092316)2025.07.11\n\nA: EXAONE Deep은 추론에 특화된 모델로, 같은 크기의 다른 모델들보다 수학, 과학, 코딩 분야에서 우수한 성능을 보입니다. 특히 7.8B 모델은 상용 추론 모델인 OpenAI o1-mini보다도 더 나은 성능을 입증했습니다.\n\n■ 이 기사는 AI 전문 매체 ‘[AI 매터스](https://aimatters.co.kr/)’와 제휴를 통해 제공됩니다. 기사는 클로드 3.5 소네트와 챗GPT를 활용해 작성되었습니다. (☞ [기사 원문 바로가기](https://aimatters.co.kr/?p=17497))\n\n**AI 에디터**[media@zdnet.co.kr](mailto:media@zdnet.co.kr)\n\n[기자의 다른 기사 보기](https://zdnet.co.kr/reporter/?lstcode=media)\n\n[![Image 16](https://zdnet.co.kr/images/naver_bt3.gif?ver=20210515)](https://media.naver.com/channel/promotion.nhn?oid=092)\n\n[AI 에디터](https://search.zdnet.co.kr/?kwd=AI%20%EC%97%90%EB%94%94%ED%84%B0&area=4)\n\n지금 뜨는 기사\n--------\n\n### 이시각 헤드라인\n\n[![Image 17](https://image.zdnet.co.kr/2025/07/09/e6ecfd471423f8fceb12e03eb249be48-290x182.jpg)](https://zdnet.co.kr/view/?no=20250709092316)\n\n[#### 스테이블코인 대신 카드결제?…금융은 기회 포착했다](https://zdnet.co.kr/view/?no=20250709092316)\n\n[![Image 18](https://image.zdnet.co.kr/2025/07/10/869372f643f279088b7d331e01514ce0-290x182.jpg)](https://zdnet.co.kr/view/?no=20250710135202)\n\n[#### [타보고서] 고속도로가 도서관보다 적막해…더 정숙해진 볼보 XC90](https://zdnet.co.kr/view/?no=20250710135202)\n\n[![Image 19](https://image.zdnet.co.kr/2025/04/09/a0ddbfeefb9700a251224688b9b994d8-290x182.jpg)](https://zdnet.co.kr/view/?no=20250711104054)\n\n[#### 삼성전기·LG이노텍, 2분기 실적 부진…신성장 동력 확보에 기대](https://zdnet.co.kr/view/?no=20250711104054)\n\n[![Image 20](https://image.zdnet.co.kr/2025/07/11/640f8bc35ab2d5f6992afeb9328e565f-290x182.jpg)](https://zdnet.co.kr/view/?no=20250711142256)\n\n[#### 문체 최휘영·국토 김윤덕...이재명 정부 초대내각 인선 완료](https://zdnet.co.kr/view/?no=20250711142256)\n\n### ZDNet Power Center\n\n![Image 21](https://zdnet.co.kr/images/power_center_320x50.jpg)\n\n[![Image 22: TOP](https://zdnet.co.kr/images/top_button.png)](https://zdnet.co.kr/view/?no=20250322134718#)\n\n![Image 23](https://zdnet.co.kr/images/footer_logo2.png?ver=20220830)\n\nConnect with us\n\n[](https://www.facebook.com/zdnetkor)[](https://twitter.com/zdnetkorea)[](https://www.youtube.com/@techverse.)[](https://feeds.feedburner.com/zdkorea)\n\n ZDNET Korea is operated by Money Today Group under license from Ziff Davis. Global family site >>[CNET.com](https://www.cnet.com/) | [ZDNet.com](https://www.zdnet.com/)\n\nZDNet Korea Newsletter 구독 신청 [구독신청](javascript:newsletter();)\n\n*   [회사소개](https://zdnet.co.kr/corporation/)\n*   [광고문의](https://zdnet.co.kr/corporation/sub2_1.html)\n*   [DB마케팅문의](https://zdnet.co.kr/corporation/sub2_2.html)\n*   [제휴문의](https://zdnet.co.kr/corporation/sub3.html)\n*   [개인정보처리방침](https://zdnet.co.kr/member/privacy.php)\n*   [이용약관](https://zdnet.co.kr/member/teamservice.php)\n*   [청소년 보호정책](https://zdnet.co.kr/member/teenager.php)\n\n*   회사명 : (주)메가뉴스\n*   제호 : 지디넷코리아\n*   등록번호 : 서울아00665\n\n*   등록연월일 : 2008년 9월 23일\n*   사업자 등록번호 : 220-87-44355\n\n*   주소 : 서울시 마포구 양화로111 지은빌딩 3층\n*   대표전화 : (02)330-0100\n\n*   발행인 : 김경묵\n*   편집국장 : 김태진\n*   개인정보보호 책임자·청소년보호책임자 : 김익현\n\n*   COPYRIGHT © ZDNETKOREA ALL RIGHTS RESERVED.\n\n![Image 24](https://cm.g.doubleclick.net/pixel?google_nid=dable&google_cm)![Image 25](https://cm-exchange.toast.com/pixel?cm_mid=1440080439&cm_muid=30646173.1752218880285&toast_push)![Image 26](https://cs.gssprt.jp/yie/ld/cs?dspid=dable&uid=30646173.1752218880285)![Image 27](https://analytics.ad.daum.net/match?d=111&uid=30646173.1752218880285)![Image 28](https://dable-api.scupio.com/dable/v1/exc/?did=30646173.1752218880285)![Image 29](https://ib.adnxs.com/setuid?entity=563&code=30646173.1752218880285)\n"
    },
    {
        "url": "https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/",
        "title": "EXAONE Deep vs. Qwen Comparison - SourceForge",
        "content": "EXAONE Deep is a series of reasoning-enhanced language models developed by LG AI Research, featuring parameter sizes of 2.4 billion, 7.8 billion, and 32 billion. These models demonstrate superior capabilities in various reasoning tasks, including math and coding benchmarks. Notably, EXAONE Deep 2.4B outperforms other models of comparable size, EXAONE Deep 7.8B surpasses both open-weight models of similar scale and the proprietary reasoning model OpenAI o1-mini, and EXAONE Deep 32B shows [...] needs and performance levels. Open source: Some versions of Qwen are open-source, which means their code is publicly available for anyone to use and modify. Multilingual support: Qwen can understand and translate multiple languages, including English, Chinese, and French. Diverse capabilities: Besides generation and translation, Qwen models can be used for tasks like question answering, text summarization, and code generation. [...] processed, we bring lasting value to millions worldwide. Our all-in-one platform combines advanced technology with a client-first approach, offering high-yield flexible and fixed-term savings, crypto-backed loans, sophisticated trading tools, and liquidity solutions, including the first crypto debit/credit card. Built on deep industry expertise, a sustainable business model, robust infrastructure, stringent security, and global licensing, Nexo champions innovation and long-lasting prosperity.",
        "score": 0.7872945,
        "raw_content": "EXAONE Deep vs. Qwen Comparison\n\n===============\n![Image 1](https://ipv4.d.adroll.com/px4/3QEU55AVURGVNFYKGPRLHU/EPGGWMNOENDCJMRYE2IIFV?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&cookie=&adroll_s_ref=&keyw=&p0=1907&xa4=1)![Image 2](https://ipv4.d.adroll.com/px4/3QEU55AVURGVNFYKGPRLHU/EPGGWMNOENDCJMRYE2IIFV?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&cookie=&adroll_s_ref=&keyw=&p0=1907&xa4=1)![Image 3](https://x.adroll.com/attribution/trigger?fpc=b785b50ea9096d8ff8c15e48f941daf1&advertisable_eid=3QEU55AVURGVNFYKGPRLHU&conversion_type=PageView&conversion_value=0.00&currency=USC&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F)![Image 4](https://x.adroll.com/attribution/trigger?fpc=b785b50ea9096d8ff8c15e48f941daf1&advertisable_eid=3QEU55AVURGVNFYKGPRLHU&conversion_type=PageView&conversion_value=0.00&currency=USC&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F)\n\n![Image 5](https://d.adroll.com/cm/b/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 6](https://d.adroll.com/cm/bombora/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 7](https://d.adroll.com/cm/experian/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 8](https://d.adroll.com/cm/g/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 9](https://d.adroll.com/cm/index/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 10](https://d.adroll.com/cm/n/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 11](https://d.adroll.com/cm/o/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 12](https://d.adroll.com/cm/outbrain/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 13](https://d.adroll.com/cm/pubmatic/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 14](https://d.adroll.com/cm/taboola/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 15](https://d.adroll.com/cm/triplelift/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 16](https://d.adroll.com/cm/x/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)\n\n![Image 17](https://d.adroll.com/cm/b/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 18](https://d.adroll.com/cm/bombora/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 19](https://d.adroll.com/cm/experian/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 20](https://d.adroll.com/cm/g/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 21](https://d.adroll.com/cm/index/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 22](https://d.adroll.com/cm/n/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 23](https://d.adroll.com/cm/o/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 24](https://d.adroll.com/cm/outbrain/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 25](https://d.adroll.com/cm/pubmatic/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 26](https://d.adroll.com/cm/taboola/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 27](https://d.adroll.com/cm/triplelift/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)![Image 28](https://d.adroll.com/cm/x/out?adroll_fpc=b785b50ea9096d8ff8c15e48f941daf1-1752218895324&flg=1&pv=82321794605.02486&arrfrr=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&advertisable=3QEU55AVURGVNFYKGPRLHU)\n\n*   [Join/Login](https://sourceforge.net/auth/)\n*   [Business Software](https://sourceforge.net/software/)\n*   [Open Source Software](https://sourceforge.net/directory/)\n*   [For Vendors](https://sourceforge.net/software/vendors/ \"For Vendors\")\n*   [Blog](https://sourceforge.net/blog/ \"Blog\")\n*   [About](https://sourceforge.net/about)\n*   More\n*       *   [Articles](https://sourceforge.net/articles/)\n    *   [SourceForge Podcast](https://sourceforge.net/articles/category/sourceforge-podcast/)\n    *   [Support / Documentation](https://docs.sourceforge.net/ \"Support / Documentation Section\")\n    *   [Subscribe to our Newsletter](https://sourceforge.net/user/newsletters)\n    *   [Support Request](https://sourceforge.net/support)\n\n[![Image 29: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")[](https://sourceforge.net/user/newsletters \"Subscribe to our newsletter\")[For Vendors](https://sourceforge.net/software/vendors/ \"For Vendors\")[Add a Product](https://sourceforge.net/software/vendors/new \"Add a Commercial Product\")[Join](https://sourceforge.net/user/registration_business \"Join\")[Login](https://sourceforge.net/auth/ \"Login\")\n\n[![Image 30: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n[![Image 31: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n[Business Software](https://sourceforge.net/software/)\n\n[Open Source Software](https://sourceforge.net/directory/ \"Browse\")\n\n[SourceForge Podcast](https://sourceforge.net/articles/category/sourceforge-podcast/)\n\nResources\n*   [Articles](https://sourceforge.net/articles/)\n*   [Case Studies](https://sourceforge.net/software/case-studies/)\n*   [Blog](https://sourceforge.net/blog/)\n\n Menu \n*   [Help](https://sourceforge.net/support)\n*   [Create](https://sourceforge.net/create)\n*   [Join](https://sourceforge.net/user/registration_business/ \"Join\")\n*   [Login](https://sourceforge.net/auth/ \"Login\")\n\n[![Image 32](https://a.fsdn.com/con/assets/maxnav/sourceforge/nav32-347199d0-d5c91966.png)](https://www.avast.com/lp-free-av?full_trSrc=mmm_srf_dlp_008_406_a&utm_medium=referral&utm_source=sourceforge&utm_campaign=srf_dlp_008_406_a:site_banner)\n\nEXAONE Deep vs. Qwen Comparison Chart\n=====================================\n\n[![Image 33: EXAONE Deep](https://a.fsdn.com/allura/s/exaone-deep/icon?863150716bc856082e8821e5e7778494f914f43b5b589d7434f7e7fc8cd916d5?&w=90)](https://sourceforge.net/software/product/EXAONE-Deep/)\n\n[EXAONE Deep](https://sourceforge.net/software/product/EXAONE-Deep/)\n--------------------------------------------------------------------\n\n LG[![Image 34: Qwen](https://a.fsdn.com/allura/s/qwen/icon?c869f29d5126d635ac01fbb7a9e623d14b32dadd3a738f98738db68085ff8e82?&w=90)](https://sourceforge.net/software/product/Qwen/)\n\n[Qwen](https://sourceforge.net/software/product/Qwen/)\n------------------------------------------------------\n\nAlibaba++\n[Learn More](https://sourceforge.net/software/product/EXAONE-Deep/)\n\n[Update Features](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#claim_exaone-deep.s)[Learn More](https://sourceforge.net/software/product/Qwen/)\n\n[Update Features](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#claim_qwen.s)Add To Compare Add To Compare\n\n### Related Products\n\n*   [![Image 35: Vertex AI](https://a.fsdn.com/allura/s/google-cloud-ml-engine/icon?7c9ed3165f15fb567dfd971732c04b698e249f9289fcc8d75e1e44ebd9f98ce5?&w=48)](https://sourceforge.net/software/product/Vertex-AI/ \"Vertex AI\")[Vertex AI](https://sourceforge.net/software/product/Vertex-AI/ \"Learn more about Vertex AI \") Build, deploy, and scale machine learning (ML) models faster, with fully managed ML tools for any use case. Through Vertex AI Workbench, Vertex AI is natively integrated with BigQuery, Dataproc, and Spark. You can use BigQuery ML to create and execute machine learning models in BigQuery using standard SQL queries on existing business intelligence tools and spreadsheets, or you can export datasets from BigQuery directly into Vertex AI Workbench and run your models from there. Use Vertex Data Labeling to generate highly accurate labels for your data collection. Vertex AI Agent Builder enables developers to create and deploy enterprise-grade generative AI applications. It offers both no-code and code-first approaches, allowing users to build AI agents using natural language instructions or by leveraging frameworks like LangChain and LlamaIndex.           713 Ratings  ![Image 36](https://sourceforge.net/software/tp3/?b=67689&z=65061&c=13059&cb=ba4ba318913279ce56db)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=67689__zoneid=65061__cb=678be02e2b4547e522d8__oadest=https%3A%2F%2Fcloud.google.com%2Fvertex-ai%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DVertex_AI \"Visit Vertex AI Website\")    \n*   [![Image 37: Google AI Studio](https://a.fsdn.com/allura/s/google-ai-studio/icon?560e6b21275529b4cf46005ac941cc8d9e6e5db4fe36281f8f5d45b4db10db7a?&w=48)](https://sourceforge.net/software/product/Google-AI-Studio/ \"Google AI Studio\")[Google AI Studio](https://sourceforge.net/software/product/Google-AI-Studio/ \"Learn more about Google AI Studio \") Google AI Studio is a comprehensive, web-based development environment that democratizes access to Google's cutting-edge AI models, notably the Gemini family, enabling a broad spectrum of users to explore and build innovative applications. This platform facilitates rapid prototyping by providing an intuitive interface for prompt engineering, allowing developers to meticulously craft and refine their interactions with AI. Beyond basic experimentation, AI Studio supports the seamless integration of AI capabilities into diverse projects, from simple chatbots to complex data analysis tools. Users can rigorously test different prompts, observe model behaviors, and iteratively refine their AI-driven solutions within a collaborative and user-friendly environment. This empowers developers to push the boundaries of AI application development, fostering creativity and accelerating the realization of AI-powered solutions.           4 Ratings  ![Image 38](https://sourceforge.net/software/tp3/?b=80946&z=78342&c=15627&cb=a2d02170ebe2891c6cfb)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=80946__zoneid=78342__cb=a61cfdf2fc3b158b00a4__oadest=https%3A%2F%2Faistudio.google.com%2Fwelcome%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Daistudio \"Visit Google AI Studio Website\")    \n*   [![Image 39: LM-Kit.NET](https://a.fsdn.com/allura/s/lm-kit-net/icon?b204f29e26a682c5dc80ccd9d8dbfeb0b2e58eacb975518aee36d828897a2951?&w=48)](https://sourceforge.net/software/product/LM-Kit.NET/ \"LM-Kit.NET\")[LM-Kit.NET](https://sourceforge.net/software/product/LM-Kit.NET/ \"Learn more about LM-Kit.NET \") LM-Kit.NET is a cutting-edge, high-level inference SDK designed specifically to bring the advanced capabilities of Large Language Models (LLM) into the C# ecosystem. Tailored for developers working within .NET, LM-Kit.NET provides a comprehensive suite of powerful Generative AI tools, making it easier than ever to integrate AI-driven functionality into your applications. The SDK is versatile, offering specialized AI features that cater to a variety of industries. These include text completion, Natural Language Processing (NLP), content retrieval, text summarization, text enhancement, language translation, and much more. Whether you are looking to enhance user interaction, automate content creation, or build intelligent data retrieval systems, LM-Kit.NET offers the flexibility and performance needed to accelerate your project.           16 Ratings  ![Image 40](https://sourceforge.net/software/tp3/?b=79640&z=77038&c=15392&cb=21d59bc59cef86012eee)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=79640__zoneid=77038__cb=53865f062ffa44b59d68__oadest=https%3A%2F%2Flm-kit.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Dsourceforgelisting \"Visit LM-Kit.NET Website\")    \n*   [![Image 41: Qloo](https://a.fsdn.com/allura/s/qloo/icon?cea84810c00f7e710b3a38b95543f24e0d3cca1f2100ba34f7cf98ce3bd28f60?&w=48)](https://sourceforge.net/software/product/Qloo/ \"Qloo\")[Qloo](https://sourceforge.net/software/product/Qloo/ \"Learn more about Qloo \") Qloo is the “Cultural AI”, decoding and predicting consumer taste across the globe. A privacy-first API that predicts global consumer preferences and catalogs hundreds of millions of cultural entities. Through our API, we provide contextualized personalization and insights based on a deep understanding of consumer behavior and more than 575 million people, places, and things. Our technology empowers you to look beyond trends and uncover the connections behind people’s tastes in the world around them. Look up entities in our vast library spanning categories like brands, music, film, fashion, travel destinations, and notable people. Results are delivered within milliseconds and can be weighted by factors such as regionalization and real-time popularity. Used by companies who want to incorporate best-in-class data in their consumer experiences. Our flagship recommendation API delivers results based on demographics, preferences, cultural entities, metadata, and geolocational factors.           23 Ratings  ![Image 42](https://sourceforge.net/software/tp3/?b=55113&z=52441&c=10713&cb=075ab0a78ce1746452f5)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=55113__zoneid=52441__cb=c2594420c2e04458dbc2__oadest=https%3A%2F%2Fqloo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dsourceforge%26utm_campaign%3Dsourceforge%26utm_id%3Dsf \"Visit Qloo Website\")    \n*   [![Image 43: Nexo](https://a.fsdn.com/allura/s/nexo/icon?628adf0adb50456ae1804a9838dc6cb6908d0f0c19c476fa0904a0829da8a2bd?&w=48)](https://sourceforge.net/software/product/Nexo/ \"Nexo\")[Nexo](https://sourceforge.net/software/product/Nexo/ \"Learn more about Nexo \") Nexo is a premier digital assets wealth platform designed to empower clients to grow, manage, and preserve their crypto holdings. Our mission is to lead the next generation of wealth creation by focusing on customer success and delivering tailored solutions that build enduring value, supported by 24/7 client care. Since 2018, Nexo has provided unmatched opportunities to forward-thinking clients in over 200 jurisdictions. With over $7 billion in AUM and $320 billion processed, we bring lasting value to millions worldwide. Our all-in-one platform combines advanced technology with a client-first approach, offering high-yield flexible and fixed-term savings, crypto-backed loans, sophisticated trading tools, and liquidity solutions, including the first crypto debit/credit card. Built on deep industry expertise, a sustainable business model, robust infrastructure, stringent security, and global licensing, Nexo champions innovation and long-lasting prosperity.           16,077 Ratings  ![Image 44](https://sourceforge.net/software/tp3/?b=41391&z=38686&c=8041&cb=7ae94e6bf4637c13fc13)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=41391__zoneid=38686__cb=276c60887492e3025579__oadest=https%3A%2F%2Fnexo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dfixed%26utm_campaign%3Dsourceforge_mb_generic_q225 \"Visit Nexo Website\")    \n*   [![Image 45: Valant Behavioral Health EHR](https://a.fsdn.com/allura/s/valant-behavioral-health-ehr/icon?1732903952?&w=48)](https://sourceforge.net/software/product/Valant-Behavioral-Health-EHR/ \"Valant Behavioral Health EHR\")[Valant Behavioral Health EHR](https://sourceforge.net/software/product/Valant-Behavioral-Health-EHR/ \"Learn more about Valant Behavioral Health EHR \") Provide exceptional, data-driven care from anywhere with Valant, the all-in-one EHR and practice management software designed exclusively for behavioral health practices of all sizes. - Focus the efforts of your entire workflow in one system built for individual psychotherapy, medication management, group counseling and more, whether delivered in person or virtually. - Speed your documentation process with 100+ clinical templates for evidence-based and specialized therapies, such as DBT, CBT, MFT, TMS, and weight and eating disorders. - Track your progress with 100+ comprehensive reports on patient retention, compliance, productivity, and financial performance. Demonstrate the value of your care to payers with 80+ reportable outcome measures you can schedule send to patients, auto-score, document, and track progress.           321 Ratings  ![Image 46](https://sourceforge.net/software/tp3/?b=36895&z=34198&c=7886&cb=747cd3d4985f191d6c05)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=36895__zoneid=34198__cb=80f40caa84067092986a__oadest=https%3A%2F%2Fwww.valant.io%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlisting%26utm_campaign%3Ddemo \"Visit Valant Behavioral Health EHR Website\")    \n*   [![Image 47: Google Cloud Speech-to-Text](https://a.fsdn.com/allura/s/google-cloud-speech-to-text/icon?615c0556bb44a0e185f9242eb24c328727ac3e0e3f1ddaf3328b249157e95480?&w=48)](https://sourceforge.net/software/product/Google-Cloud-Speech-to-Text/ \"Google Cloud Speech-to-Text\")[Google Cloud Speech-to-Text](https://sourceforge.net/software/product/Google-Cloud-Speech-to-Text/ \"Learn more about Google Cloud Speech-to-Text \") Google Cloud’s Speech API processes more than 1 billion voice minutes per month with close to human levels of understanding for many commonly spoken languages. Powered by the best of Google's AI research and technology, Google Cloud's Speech-to-Text API helps you accurately transcribe speech into text in 73 languages and 137 different local variants. Leverage Google’s most advanced deep learning neural network algorithms for automatic speech recognition (ASR) and deploy ASR wherever you need it, whether in the cloud with the API, on-premises with Speech-to-Text On-Prem, or locally on any device with Speech On-Device.           374 Ratings  ![Image 48](https://sourceforge.net/software/tp3/?b=67733&z=65105&c=13067&cb=0373631495223b3019cf)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=67733__zoneid=65105__cb=2bddc5dbdf0001391f7b__oadest=https%3A%2F%2Fcloud.google.com%2Fspeech-to-text%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DSpeech_To_Text \"Visit Google Cloud Speech-to-Text Website\")    \n*   [![Image 49: Windsurf Editor](https://a.fsdn.com/allura/s/codeium/icon?6ab638dbe26fb8b3b0dd6f3c66956bf5b77d72dc2883263893fa53864c365730?&w=48)](https://sourceforge.net/software/product/The-Windsurf-Editor/ \"Windsurf Editor\")[Windsurf Editor](https://sourceforge.net/software/product/The-Windsurf-Editor/ \"Learn more about Windsurf Editor \") The Windsurf Editor is a free AI-powered IDE and AI coding assistant that accelerates development by providing intelligent code generation and agents in over 70 programming languages and more than 40 IDEs, including VSCode, JetBrains, and Jupyter Notebooks. With Windsurf, developers can write code faster, eliminate repetitive tasks, and stay in the flow state—whether they're working with Python, JavaScript, C++, or any other language. Built on billions of lines of open-source code, Windsurf Editor understands and anticipates your coding needs, offering multiline suggestions, automated unit tests, and even natural language explanations for complex functions. It’s perfect for streamlining code writing, reducing boilerplate, and cutting down the time spent on documentation searches. Trusted by individual developers and Fortune 500 companies alike, Windsurf Editor is your go-to solution for boosting productivity and writing better code. Try Windsurf for free today!           137 Ratings  ![Image 50](https://sourceforge.net/software/tp3/?b=57601&z=54925&c=11107&cb=872cd1b1887c39a41328)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=57601__zoneid=54925__cb=bd0e8bdd4fca8a593f05__oadest=https%3A%2F%2Fwindsurf.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlist%26utm_campaign%3Dsourceforge1 \"Visit Windsurf Editor Website\")    \n*   [![Image 51: RaimaDB](https://a.fsdn.com/allura/s/raima-database-manager/icon?78e5d6a19e94f230710ef8a0a54dbc7b42aa41fa93525195b40963bf23295a91?&w=48)](https://sourceforge.net/software/product/RaimaDB/ \"RaimaDB\")[RaimaDB](https://sourceforge.net/software/product/RaimaDB/ \"Learn more about RaimaDB \") RaimaDB is an embedded time series database for IoT and Edge devices that can run in-memory. It is an extremely powerful, lightweight and secure RDBMS. Field tested by over 20 000 developers worldwide and has more than 25 000 000 deployments. RaimaDB is a high-performance, cross-platform embedded database designed for mission-critical applications, particularly in the Internet of Things (IoT) and edge computing markets. It offers a small footprint, making it suitable for resource-constrained environments, and supports both in-memory and persistent storage configurations. RaimaDB provides developers with multiple data modeling options, including traditional relational models and direct relationships through network model sets. It ensures data integrity with ACID-compliant transactions and supports various indexing methods such as B+Tree, Hash Table, R-Tree, and AVL-Tree.           5 Ratings  ![Image 52](https://sourceforge.net/software/tp3/?b=28971&z=26159&c=5625&cb=3a476a14c5c913548458)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=28971__zoneid=26159__cb=076ac9c2f375dd25759e__oadest=https%3A%2F%2Fraima.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dppc%26utm_campaign%3DSF \"Visit RaimaDB Website\")    \n*   [![Image 53: ONLYOFFICE Docs](https://a.fsdn.com/allura/s/onlyoffice/icon?1750859097?&w=48)](https://sourceforge.net/software/product/ONLYOFFICE/ \"ONLYOFFICE Docs\")[ONLYOFFICE Docs](https://sourceforge.net/software/product/ONLYOFFICE/ \"Learn more about ONLYOFFICE Docs \") ONLYOFFICE is an open-source project that offers cloud-based and self-hosted solutions for business of all sizes. The key product is ONLYOFFICE Docs, a secure office suite that seamlessly integrates into the most popular platforms, e.g. Odoo, Alfresco, Confluence, Pipedrive, Redmine, SuiteCRM and more. When integrated, ONLYOFFICE Docs provides the users of your business app with editors for documents, spreadsheets, presentations, forms, PDFs and diagrams. The ONLYOFFICE suite makes it possible to collaborate on office files in real time. The built-in AI assistant is compatible with ChatGPT, DeepSeek, Mistral and other AI providers to ensure a flawless editing experience. You can use Docs within ONLYOFFICE DocSpace, a room-based document collaboration platform that allows you to create dedicated spaces where you can assign access permissions and collaborate with your teammates. With DocSpace, you can store, share and co-edit office files, and even interact with third parties.           672 Ratings  ![Image 54](https://sourceforge.net/software/tp3/?b=33890&z=31162&c=7102&cb=ee7182c7512574bd0859)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=33890__zoneid=31162__cb=f26d60085cf5a5e9fa8e__oadest=https%3A%2F%2Fwww.onlyoffice.com%3Futm_source%3Dsourceforge%26utm_medium%3Dcpc%26utm_campaign%3Dsourceforge_2025%26utm_id%3D23051%26utm_content%3DVISIT-WEBSITE \"Visit ONLYOFFICE Docs Website\")\n### About\n\n EXAONE Deep is a series of reasoning-enhanced language models developed by LG AI Research, featuring parameter sizes of 2.4 billion, 7.8 billion, and 32 billion. These models demonstrate superior capabilities in various reasoning tasks, including math and coding benchmarks. Notably, EXAONE Deep 2.4B outperforms other models of comparable size, EXAONE Deep 7.8B surpasses both open-weight models of similar scale and the proprietary reasoning model OpenAI o1-mini, and EXAONE Deep 32B shows competitive performance against leading open-weight models. The repository provides comprehensive documentation covering performance evaluations, quickstart guides for using EXAONE Deep models with Transformers, explanations of quantized EXAONE Deep weights in AWQ and GGUF formats, and instructions for running EXAONE Deep models locally using frameworks like llama.cpp and Ollama.### About\n\n Qwen LLM refers to a family of large language models (LLMs) developed by Alibaba Cloud's Damo Academy. These models are trained on a massive dataset of text and code, allowing them to understand and generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way. Here are some key features of Qwen LLMs: Variety of sizes: The Qwen series ranges from 1.8 billion to 72 billion parameters, offering options for different needs and performance levels. Open source: Some versions of Qwen are open-source, which means their code is publicly available for anyone to use and modify. Multilingual support: Qwen can understand and translate multiple languages, including English, Chinese, and French. Diverse capabilities: Besides generation and translation, Qwen models can be used for tasks like question answering, text summarization, and code generation.\n### Platforms Supported\n\n Windows \n\n Mac \n\n Linux \n\n Cloud \n\n On-Premises \n\n iPhone \n\n iPad \n\n Android \n\n Chromebook### Platforms Supported\n\n Windows \n\n Mac \n\n Linux \n\n Cloud \n\n On-Premises \n\n iPhone \n\n iPad \n\n Android \n\n Chromebook\n### Audience\n\n Researchers and developers requiring a tool offering advanced language models for enhanced reasoning tasks in mathematics and coding### Audience\n\n Developers that want a powerful LLM\n### Support\n\n Phone Support \n\n 24/7 Live Support \n\n Online### Support\n\n Phone Support \n\n 24/7 Live Support \n\n Online\n### API\n\n Offers API### API\n\n Offers API\n### Screenshots and Videos\n\n[![Image 55: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/max/max/1)[![Image 56: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/max/max/1)[View more images or videos](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#)### Screenshots and Videos\n\nNo images available\n### Pricing\n\n**Free**\n\n Free Version \n\n Free Trial### Pricing\n\n**Free**\n\n Free Version \n\n Free Trial\n### Reviews/Ratings\n\nOverall 0.0 / 5 \n\nease 0.0 / 5 \n\nfeatures 0.0 / 5 \n\ndesign 0.0 / 5 \n\nsupport 0.0 / 5 \n\nThis software hasn't been reviewed yet. Be the first to provide a review:\n\n[Review this Software](https://sourceforge.net/software/product/EXAONE-Deep/reviews/new)### Reviews/Ratings\n\nOverall 5.0 / 5 \n\nease 5.0 / 5 \n\nfeatures 5.0 / 5 \n\ndesign 5.0 / 5 \n\nsupport 5.0 / 5 \n\n[Read all reviews](https://sourceforge.net/software/product/Qwen/#reviews)\n### Training\n\n Documentation \n\n Webinars \n\n Live Online \n\n In Person### Training\n\n Documentation \n\n Webinars \n\n Live Online \n\n In Person\n### Company Information\n\n**LG**\n\nFounded: 1947\n\nSouth Korea\n\ngithub.com/LG-AI-EXAONE/EXAONE-Deep### Company Information\n\n**Alibaba**\n\nFounded: 1999\n\nChina\n\ngithub.com/QwenLM/Qwen\n### Alternatives\n\n[![Image 57: Phi-4-reasoning-plus](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-reasoning-plus/)\n#### [Phi-4-reasoning-plus](https://sourceforge.net/software/product/Phi-4-reasoning-plus/)\n\nMicrosoft### Alternatives\n\n[![Image 58: OLMo 2](https://a.fsdn.com/allura/s/olmo-2/icon?db8323a967a99ef3c3ecd2ff377e1a3eb3632cb2493c23ebab9a835be514c0a8?&w=90)](https://sourceforge.net/software/product/OLMo-2/)\n#### [OLMo 2](https://sourceforge.net/software/product/OLMo-2/)\n\nAi2\n[![Image 59: Phi-4-reasoning](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-reasoning/)\n#### [Phi-4-reasoning](https://sourceforge.net/software/product/Phi-4-reasoning/)\n\nMicrosoft[![Image 60: Phi-3](https://a.fsdn.com/allura/s/phi-3/icon?0de9df5cb5db7b395e32f67e1923c18d95a4078ec321df8ea3765cf0460d205f?&w=90)](https://sourceforge.net/software/product/Phi-3/)\n#### [Phi-3](https://sourceforge.net/software/product/Phi-3/)\n\nMicrosoft\n[![Image 61: Phi-4-mini-reasoning](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-mini-reasoning/)\n#### [Phi-4-mini-reasoning](https://sourceforge.net/software/product/Phi-4-mini-reasoning/)\n\nMicrosoft[![Image 62: Qwen2](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f?&w=90)](https://sourceforge.net/software/product/Qwen2/)\n#### [Qwen2](https://sourceforge.net/software/product/Qwen2/)\n\nAlibaba\n[![Image 63: Qwen2](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f?&w=90)](https://sourceforge.net/software/product/Qwen2/)\n#### [Qwen2](https://sourceforge.net/software/product/Qwen2/)\n\nAlibaba[![Image 64: Qwen2-VL](https://a.fsdn.com/allura/s/qwen2-vl/icon?46530744ad9f0efd67308d7d878442fffcdad4babc48357c136fe764710e8f2c?&w=90)](https://sourceforge.net/software/product/Qwen2-VL/)\n#### [Qwen2-VL](https://sourceforge.net/software/product/Qwen2-VL/)\n\nAlibaba\n[![Image 65: DeepSeek R1](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b?&w=90)](https://sourceforge.net/software/product/DeepSeek-R1/)\n#### [DeepSeek R1](https://sourceforge.net/software/product/DeepSeek-R1/)\n\nDeepSeek\n\n[View All](https://sourceforge.net/software/product/EXAONE-Deep/alternatives)[![Image 66: Samsung Gauss](https://a.fsdn.com/allura/s/samsung-gauss/icon?3764bed16136aac7b2547e89f3ed016cd6c1600debbb568ba39d64e6a48ca252?&w=90)](https://sourceforge.net/software/product/Samsung-Gauss/)\n#### [Samsung Gauss](https://sourceforge.net/software/product/Samsung-Gauss/)\n\nSamsung\n\n[View All](https://sourceforge.net/software/product/Qwen/alternatives)\n### Categories\n\n[AI Models](https://sourceforge.net/software/ai-models/)### Categories\n\n[AI Models](https://sourceforge.net/software/ai-models/)\n\n[Large Language Models](https://sourceforge.net/software/large-language-models/)\n\n[LLM API](https://sourceforge.net/software/llm-api/)\n\n### Integrations\n\n Alibaba Cloud \n\n Athene-V2 \n\n Axolotl \n\n C \n\n C# \n\n C++ \n\n CSS \n\n Decompute Blackbird \n\n F# \n\n HTML \n\n Hugging Face \n\n Java \n\n LM-Kit.NET \n\n NativeMind \n\n OpenAI \n\n PHP \n\n Qwen Chat \n\n SambaNova \n\n Symflower \n\n Zemith \n\n[Show More Integrations](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#)\n\n[View All 3 Integrations](https://sourceforge.net/software/product/EXAONE-Deep/integrations/)### Integrations\n\n Alibaba Cloud \n\n Athene-V2 \n\n Axolotl \n\n C \n\n C# \n\n C++ \n\n CSS \n\n Decompute Blackbird \n\n F# \n\n HTML \n\n Hugging Face \n\n Java \n\n LM-Kit.NET \n\n NativeMind \n\n OpenAI \n\n PHP \n\n Qwen Chat \n\n SambaNova \n\n Symflower \n\n Zemith \n\n[Show More Integrations](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#)\n\n[View All 43 Integrations](https://sourceforge.net/software/product/Qwen/integrations/)\nClaim EXAONE Deep and update features and information\n\n[Claim EXAONE Deep and update features and information](https://sourceforge.net/software/product/EXAONE-Deep/claim)Claim Qwen and update features and information\n\n[Claim Qwen and update features and information](https://sourceforge.net/software/product/Qwen/claim)\n\nSourceForge\n\n*   [Open Source Software](https://sourceforge.net/directory/ \"Open Source Software Directory\")\n*   [Business Software](https://sourceforge.net/software/ \"Business Software Directory\")\n*   [Add Your Software](https://sourceforge.net/software/vendors/new)\n*   [Business Software Advertising](https://sourceforge.net/software/vendors/pricing/)\n\nCompany\n\n*   [About](https://sourceforge.net/about)\n*   [Team](https://sourceforge.net/about/leadership \"Open Source Software Directory\")\n*   SourceForge Headquarters\n\n225 Broadway Suite 1600\n\nSan Diego, CA 92101\n\n+1 (858) 422-6466\n\n*   [](https://twitter.com/sourceforge \"SourceForge on X\")[](https://fosstodon.org/@sourceforge \"SourceForge on Mastodon\")[](https://www.facebook.com/sourceforgenet/ \"SourceForge on Facebook\")[](https://www.linkedin.com/company/sourceforge.net \"SourceForge on LinkedIn\")[](https://sourceforge.net/user/newsletters \"Subscribe to our newsletter\")\n\nResources\n\n*   [Support / Documentation](https://docs.sourceforge.net/ \"Support / Documentation Section\")\n*   [Site Status](https://fosstodon.org/@sourceforgestatus \"Site Status\")\n*   [SourceForge Reviews](https://sourceforge.net/reviews \"Reviews\")\n\n[![Image 67: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n © 2025 Slashdot Media. All Rights Reserved. \n\n[Terms](https://slashdotmedia.com/terms-of-use \"Terms\")[Privacy](https://slashdotmedia.com/privacy-statement/ \"Privacy\")[Opt Out](https://slashdotmedia.com/opt-out-choices/ \"Opt Out\")[Advertise](https://slashdotmedia.com/contact/ \"Advertise\")\n\n#### Find software to compare\n\nSuggested Software\n\n*   [![Image 68: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning-plus Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-reasoning-plus)\n*   [![Image 69: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-reasoning)\n*   [![Image 70: Logo](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-mini-reasoning Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-mini-reasoning)\n*   [![Image 71: Logo](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f)Qwen2 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Qwen2)\n*   [![Image 72: Logo](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b)DeepSeek R1 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=DeepSeek-R1)\n*   [![Image 73: Logo](https://a.fsdn.com/allura/s/tulu-3/icon?db8323a967a99ef3c3ecd2ff377e1a3eb3632cb2493c23ebab9a835be514c0a8)Tülu 3 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Tulu-3)\n*   [![Image 74: Logo](https://a.fsdn.com/allura/s/pixtral-12b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Pixtral Large Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Pixtral-Large)\n*   [![Image 75: Logo](https://a.fsdn.com/allura/s/mixtral-8x7b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Mixtral 8x7B Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Mixtral-8x7B)\n*   [![Image 76: Logo](https://a.fsdn.com/allura/s/deepseek-coder-v2/icon?30a90148f6c74cbd4b4fb1c601a0e926d150c83ede9b065732ffa2d9fd056781)DeepSeek-Coder-V2 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=DeepSeek-Coder-V2)\n*   [![Image 77: Logo](https://a.fsdn.com/allura/s/llama-4-behemoth/icon?ea72543a1b0a7dec15408328f9ec9dea7a408593f0b38c32b69bee9d8061d302)Llama 4 Behemoth Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/add-software/?software_name=Llama-4-Behemoth)\n\n×\n\n![Image 79](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=5113&dimension2=pg_commercial_compare&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&action_name=EXAONE+Deep+vs.+Qwen+Comparison)![Image 80](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=32292&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&action_name=EXAONE+Deep+vs.+Qwen+Comparison&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=EXAONE-Deep)![Image 81](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=43736&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&action_name=EXAONE+Deep+vs.+Qwen+Comparison&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=Qwen)\n\nThanks for helping keep SourceForge clean.\n\n[X](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#)\n\nYou seem to have CSS turned off. Please don't fill out this field.\n\nYou seem to have CSS turned off. Please don't fill out this field.\n\n Briefly describe the problem (required): \n\nUpload screenshot of ad (required):\n\n[Select a file](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen/#), or drag & drop file here. \n\n![Image 82](blob:http://localhost/48f76619a5bd00ce057f2024dcf38bc1)\n\n✔\n\n✘\n\nScreenshot instructions:[Mac](https://support.apple.com/en-us/HT201361)\n\nClick URL instructions:\n\n Right-click on the ad, choose \"Copy Link\", then paste here →\n\n (This may not be possible with some types of ads)\n\n[More information about our ad policies](https://sourceforge.net/p/forge/documentation/Report%20a%20problem%20with%20Ad%20content/)\n\nAd destination/click URL:\n\n![Image 83](https://io.narrative.io/?companyId=2440&id=first_party%3Ae503cf87-e1b6-4fb4-934c-3d4d367d9e34&id=site_name%3Asourceforge.net&id=url%3A%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen%2F&id=pagetitle%3AEXAONE+Deep+vs.+Qwen+Comparison&id=vertical%3AB2B+Software&id=product%3AEXAONE+Deep%2CQwen&id=topics%3AAI+Models%2CAI+Models%2CLLM+API%2CLarge+Language+Models&rand=1752218894102)\n"
    },
    {
        "url": "https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/",
        "title": "Compare EXAONE Deep vs. Qwen in 2025 - Slashdot",
        "content": "diverse performance requirements and applications. Open source availability: Certain versions of Qwen are open-source, allowing users to access and modify the underlying code as needed. Multilingual capabilities: Qwen is equipped to comprehend and translate several languages, including English, Chinese, and French. Versatile functionalities: In addition to language generation and translation, Qwen models excel in tasks such as answering questions, summarizing texts, and generating code, making [...] EXAONE Deep represents a collection of advanced language models that are enhanced for reasoning, created by LG AI Research, and come in sizes of 2.4 billion, 7.8 billion, and 32 billion parameters. These models excel in a variety of reasoning challenges, particularly in areas such as mathematics and coding assessments. Significantly, the EXAONE Deep 2.4B model outshines other models of its size, while the 7.8B variant outperforms both open-weight models of similar dimensions and the [...] performance. This comprehensive platform unlocks the full potential of AI, facilitating innovation and improving efficiency in various fields by lowering the barriers to AI development. By removing complexities, it helps users focus on building impactful solutions faster.           4 Ratings  Learn More",
        "score": 0.77548623,
        "raw_content": "Compare EXAONE Deep vs. Qwen in 2025\n\n===============\n\n*   [News](https://slashdot.org/)\n*   [Compare Business Software](https://slashdot.org/software/ \"Compare Business Software\")\n*   [Thought Leadership](https://slashdot.org/content/)\n*   Connect[](http://twitter.com/slashdot \"Slashdot on X\")[](http://www.facebook.com/slashdot \"Slashdot on Facebook\")[](https://www.linkedin.com/company/slashdot \"Slashdot on LinkedIn\")\n*   [Privacy](https://slashdotmedia.com/privacy-statement/)\n*   More\n*       *   [Add Your Software](https://slashdot.org/software/transfer_site/sf/?url_path=/software/vendors/new&origin=sd \"Add Your Software\")\n    *   [@slashdot](https://twitter.com/slashdot \"@slashdot\")\n    *   [Feedback](mailto:feedback@slashdot.org \"Feedback\")\n    *   [Opt Out](https://slashdotmedia.com/opt-out-choices/)\n    *   [Terms](https://slashdotmedia.com/terms-of-use/)\n    *   [Software Advertising Options](https://slashdot.org/software/transfer_site/sf/?url_path=/software/vendors/pricing/&origin=sd \"Software Advertising Options\")\n\n[](https://slashdot.org/ \"Home\")\n\n[](https://slashdot.org/ \"Home\")[News](https://slashdot.org/)[Business Software](https://slashdot.org/software/)[Thought Leadership](https://slashdot.org/content/)\n\n[](http://twitter.com/slashdot \"Slashdot on X\")[](http://www.facebook.com/slashdot \"Slashdot on Facebook\")[](https://www.linkedin.com/company/slashdot \"Slashdot on LinkedIn\")\n\n*   [Software](https://slashdot.org/software/)\n*   [AI Models](https://slashdot.org/software/ai-models/)\n*   EXAONE Deep vs. Qwen\n\nCompare EXAONE Deep vs. Qwen\n============================\n\nWhat’s the difference between EXAONE Deep and Qwen? Compare EXAONE Deep vs. Qwen in 2025 by cost, reviews, features, integrations, deployment, target market, support options, trial offers, training options, years in business, region, and more using the chart below.\n\n[![Image 1: EXAONE Deep Reviews](https://a.fsdn.com/allura/s/exaone-deep/icon?863150716bc856082e8821e5e7778494f914f43b5b589d7434f7e7fc8cd916d5?&w=90)](https://slashdot.org/software/p/EXAONE-Deep/)\n\n[EXAONE Deep](https://slashdot.org/software/p/EXAONE-Deep/)\n-----------------------------------------------------------\n\n[View Product](https://slashdot.org/software/p/EXAONE-Deep/)\n\n[![Image 2: Qwen Reviews](https://a.fsdn.com/allura/s/qwen/icon?c869f29d5126d635ac01fbb7a9e623d14b32dadd3a738f98738db68085ff8e82?&w=90)](https://slashdot.org/software/p/Qwen/)\n\n[Qwen](https://slashdot.org/software/p/Qwen/)\n---------------------------------------------\n\n[View Product](https://slashdot.org/software/p/Qwen/)\n\nAdd To Compare\n\nAdd To Compare\n\n### Average Ratings [0 Ratings](https://slashdot.org/software/p/EXAONE-Deep/#reviews)\n\nTotal\n\nease\n\nfeatures\n\ndesign\n\nsupport\n\nNo User Reviews. Be the first to provide a review:\n\n[Write a Review](https://slashdot.org/software/p/EXAONE-Deep/reviews/new)\n\n### Average Ratings [1 Rating](https://slashdot.org/software/p/Qwen/#reviews)\n\nTotal\n\nease\n\nfeatures\n\ndesign\n\nsupport\n\n[Read all reviews](https://slashdot.org/software/p/Qwen/#reviews)\n\n### Similar Products\n\n*   [![Image 3: Vertex AI Reviews](https://a.fsdn.com/allura/s/google-cloud-ml-engine/icon?7c9ed3165f15fb567dfd971732c04b698e249f9289fcc8d75e1e44ebd9f98ce5?&w=48)](https://slashdot.org/software/p/Vertex-AI/ \"Vertex AI\")[Vertex AI](https://slashdot.org/software/p/Vertex-AI/ \"Learn more about Vertex AI \") Fully managed ML tools allow you to build, deploy and scale machine-learning (ML) models quickly, for any use case. Vertex AI Workbench is natively integrated with BigQuery Dataproc and Spark. You can use BigQuery to create and execute machine-learning models in BigQuery by using standard SQL queries and spreadsheets or you can export datasets directly from BigQuery into Vertex AI Workbench to run your models there. Vertex Data Labeling can be used to create highly accurate labels for data collection. Vertex AI Agent Builder empowers developers to design and deploy advanced generative AI applications for enterprise use. It supports both no-code and code-driven development, enabling users to create AI agents through natural language prompts or by integrating with frameworks like LangChain and LlamaIndex.           713 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=67695__zoneid=65067__cb=efdd0a3c092ba36d5621__oadest=https%3A%2F%2Fcloud.google.com%2Fvertex-ai%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DVertex_AI \"Visit Vertex AI Website\")    \n*   [![Image 4: Google AI Studio Reviews](https://a.fsdn.com/allura/s/google-ai-studio/icon?560e6b21275529b4cf46005ac941cc8d9e6e5db4fe36281f8f5d45b4db10db7a?&w=48)](https://slashdot.org/software/p/Google-AI-Studio/ \"Google AI Studio\")[Google AI Studio](https://slashdot.org/software/p/Google-AI-Studio/ \"Learn more about Google AI Studio \") Google AI Studio is a user-friendly, web-based workspace that offers a streamlined environment for exploring and applying cutting-edge AI technology. It acts as a powerful launchpad for diving into the latest developments in AI, making complex processes more accessible to developers of all levels. The platform provides seamless access to Google's advanced Gemini AI models, creating an ideal space for collaboration and experimentation in building next-gen applications. With tools designed for efficient prompt crafting and model interaction, developers can quickly iterate and incorporate complex AI capabilities into their projects. The flexibility of the platform allows developers to explore a wide range of use cases and AI solutions without being constrained by technical limitations. Google AI Studio goes beyond basic testing by enabling a deeper understanding of model behavior, allowing users to fine-tune and enhance AI performance. This comprehensive platform unlocks the full potential of AI, facilitating innovation and improving efficiency in various fields by lowering the barriers to AI development. By removing complexities, it helps users focus on building impactful solutions faster.           4 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=80947__zoneid=78343__cb=90d7dec35ae8a9577bac__oadest=https%3A%2F%2Faistudio.google.com%2Fwelcome%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Daistudio \"Visit Google AI Studio Website\")    \n*   [![Image 5: LM-Kit.NET Reviews](https://a.fsdn.com/allura/s/lm-kit-net/icon?b204f29e26a682c5dc80ccd9d8dbfeb0b2e58eacb975518aee36d828897a2951?&w=48)](https://slashdot.org/software/p/LM-Kit.NET/ \"LM-Kit.NET\")[LM-Kit.NET](https://slashdot.org/software/p/LM-Kit.NET/ \"Learn more about LM-Kit.NET \") LM-Kit.NET is an enterprise-grade toolkit designed for seamlessly integrating generative AI into your .NET applications, fully supporting Windows, Linux, and macOS. Empower your C# and VB.NET projects with a flexible platform that simplifies the creation and orchestration of dynamic AI agents. Leverage efficient Small Language Models for on‑device inference, reducing computational load, minimizing latency, and enhancing security by processing data locally. Experience the power of Retrieval‑Augmented Generation (RAG) to boost accuracy and relevance, while advanced AI agents simplify complex workflows and accelerate development. Native SDKs ensure smooth integration and high performance across diverse platforms. With robust support for custom AI agent development and multi‑agent orchestration, LM‑Kit.NET streamlines prototyping, deployment, and scalability—enabling you to build smarter, faster, and more secure solutions trusted by professionals worldwide.           16 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=79643__zoneid=77041__cb=e92339a5754cc7cba5c4__oadest=https%3A%2F%2Flm-kit.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Dsourceforgelisting \"Visit LM-Kit.NET Website\")    \n*   [![Image 6: Qloo Reviews](https://a.fsdn.com/allura/s/qloo/icon?cea84810c00f7e710b3a38b95543f24e0d3cca1f2100ba34f7cf98ce3bd28f60?&w=48)](https://slashdot.org/software/p/Qloo/ \"Qloo\")[Qloo](https://slashdot.org/software/p/Qloo/ \"Learn more about Qloo \") Qloo, the \"Cultural AI\", is capable of decoding and forecasting consumer tastes around the world. Privacy-first API that predicts global consumer preferences, catalogs hundreds of million of cultural entities, and is privacy-first. Our API provides contextualized personalization and insight based on deep understanding of consumer behavior. We have access to more than 575,000,000 people, places, and things. Our technology allows you to see beyond trends and discover the connections that underlie people's tastes in their world. Our vast library includes entities such as brands, music, film and fashion. We also have information about notable people. Results are delivered in milliseconds. They can be weighted with factors like regionalization and real time popularity. Companies who want to use best-in-class data to enhance their customer experiences. Our flagship recommendation API provides results based on demographics and preferences, cultural entities, metadata, geolocational factors, and metadata.           23 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=55119__zoneid=52447__cb=5eb881958210f5099d6f__oadest=https%3A%2F%2Fqloo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dsourceforge%26utm_campaign%3Dsourceforge%26utm_id%3Dsf \"Visit Qloo Website\")    \n*   [![Image 7: Nexo Reviews](https://a.fsdn.com/allura/s/nexo/icon?628adf0adb50456ae1804a9838dc6cb6908d0f0c19c476fa0904a0829da8a2bd?&w=48)](https://slashdot.org/software/p/Nexo/ \"Nexo\")[Nexo](https://slashdot.org/software/p/Nexo/ \"Learn more about Nexo \") Nexo is a premier digital assets wealth platform designed to empower clients to grow, manage, and preserve their crypto holdings. Our mission is to lead the next generation of wealth creation by focusing on customer success and delivering tailored solutions that build enduring value, supported by 24/7 client care. At Nexo, we understand that building wealth isn’t one-size-fits-all. That’s why we give you the power to choose how your assets grow. Whether you value flexibility or want to lock in higher returns, Nexo puts your goals in your hands. Earn daily compounding interest on your crypto and stablecoins with Flexible Savings. Spend, trade or withdraw them anytime, while you enjoy up to 14% annual interest. Go for the long-term and earn as high as 16% annual interest with Fixed-term Savings. Your crypto deserves to grow alongside your ambitions. At Nexo, we also believe in empowering you to make the most of your portfolio. Why sell your digital assets and miss on gains, when you can leverage them? With Nexo’s crypto Credit Line, you can unlock liquidity without selling a single coin. Grow your buying power and enjoy rates as low as 2.9%. Build your wealth, your way with Nexo.           16,077 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=41394__zoneid=38689__cb=2434408deb621d7c1da2__oadest=https%3A%2F%2Fnexo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dfixed%26utm_campaign%3Dsourceforge_mb_generic_q225 \"Visit Nexo Website\")    \n*   [![Image 8: Valant Behavioral Health EHR Reviews](https://a.fsdn.com/allura/s/valant-behavioral-health-ehr/icon?1732903952?&w=48)](https://slashdot.org/software/p/Valant-Behavioral-Health-EHR/ \"Valant Behavioral Health EHR\")[Valant Behavioral Health EHR](https://slashdot.org/software/p/Valant-Behavioral-Health-EHR/ \"Learn more about Valant Behavioral Health EHR \") Focus your efforts on providing exceptional, data-driven care with Valant, the all-in-one EHR and practice management software designed exclusively for behavioral health practices of all sizes. Valant is built to help you spend less time on administrative tasks and more time providing quality care to individuals and groups. Speed your process when you: - Reduce documentation stress with a system that generates clinical narratives - practically completing your notes for you. - Schedule 80+ built-in, reportable outcome measures to automatically send to patients before appointments through the MYIO Patient Portal. - Have the system generate a coded charge when you record appointments. - Automate your patient onboarding process and have intake packets waiting for patients to sign within their portal. - Receive requests for services directly in your EHR, manage new patient inquiries, and get a data-driven match score with new patients.           321 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=36898__zoneid=34201__cb=73971ff38bb915502447__oadest=https%3A%2F%2Fwww.valant.io%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlisting%26utm_campaign%3Ddemo \"Visit Valant Behavioral Health EHR Website\")    \n*   [![Image 9: Google Cloud Speech-to-Text Reviews](https://a.fsdn.com/allura/s/google-cloud-speech-to-text/icon?615c0556bb44a0e185f9242eb24c328727ac3e0e3f1ddaf3328b249157e95480?&w=48)](https://slashdot.org/software/p/Google-Cloud-Speech-to-Text/ \"Google Cloud Speech-to-Text\")[Google Cloud Speech-to-Text](https://slashdot.org/software/p/Google-Cloud-Speech-to-Text/ \"Learn more about Google Cloud Speech-to-Text \") An API powered by Google's AI technology allows you to accurately convert speech into text. You can accurately caption your content, provide a better user experience with products using voice commands, and gain insight from customer interactions to improve your service. Google's deep learning neural network algorithms are the most advanced in automatic speech recognition (ASR). Speech-to-Text allows for experimentation, creation, management, and customization of custom resources. You can deploy speech recognition wherever you need it, whether it's in the cloud using the API or on-premises using Speech-to-Text O-Prem. You can customize speech recognition to translate domain-specific terms or rare words. Automated conversion of spoken numbers into addresses, years and currencies. Our user interface makes it easy to experiment with your speech audio.           374 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=67739__zoneid=65111__cb=b93ec9d3377f7fe49e89__oadest=https%3A%2F%2Fcloud.google.com%2Fspeech-to-text%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DSpeech_To_Text \"Visit Google Cloud Speech-to-Text Website\")    \n*   [![Image 10: Windsurf Editor Reviews](https://a.fsdn.com/allura/s/codeium/icon?6ab638dbe26fb8b3b0dd6f3c66956bf5b77d72dc2883263893fa53864c365730?&w=48)](https://slashdot.org/software/p/The-Windsurf-Editor/ \"Windsurf Editor\")[Windsurf Editor](https://slashdot.org/software/p/The-Windsurf-Editor/ \"Learn more about Windsurf Editor \") Windsurf is a cutting-edge IDE designed for developers to maintain focus and productivity through AI-driven assistance. At the heart of the platform is Cascade, an intelligent agent that not only fixes bugs and errors but also anticipates potential issues before they arise. With built-in features for real-time code previews, automatic linting, and seamless integrations with popular tools like GitHub and Slack, Windsurf streamlines the development process. Developers can also benefit from memory tracking, which helps Cascade recall past work, and smart suggestions that enhance code optimization. Windsurf’s unique capabilities ensure that developers can work faster and smarter, reducing onboarding time and accelerating project delivery.           137 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=57607__zoneid=54931__cb=2fc4cac318670d4ddb1f__oadest=https%3A%2F%2Fwindsurf.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlist%26utm_campaign%3Dsourceforge1 \"Visit Windsurf Editor Website\")    \n*   [![Image 11: RaimaDB Reviews](https://a.fsdn.com/allura/s/raima-database-manager/icon?78e5d6a19e94f230710ef8a0a54dbc7b42aa41fa93525195b40963bf23295a91?&w=48)](https://slashdot.org/software/p/RaimaDB/ \"RaimaDB\")[RaimaDB](https://slashdot.org/software/p/RaimaDB/ \"Learn more about RaimaDB \") RaimaDB, an embedded time series database that can be used for Edge and IoT devices, can run in-memory. It is a lightweight, secure, and extremely powerful RDBMS. It has been field tested by more than 20 000 developers around the world and has been deployed in excess of 25 000 000 times. RaimaDB is a high-performance, cross-platform embedded database optimized for mission-critical applications in industries such as IoT and edge computing. Its lightweight design makes it ideal for resource-constrained environments, supporting both in-memory and persistent storage options. RaimaDB offers flexible data modeling, including traditional relational models and direct relationships through network model sets. With ACID-compliant transactions and advanced indexing methods like B+Tree, Hash Table, R-Tree, and AVL-Tree, it ensures data reliability and efficiency. Built for real-time processing, it incorporates multi-version concurrency control (MVCC) and snapshot isolation, making it a robust solution for applications demanding speed and reliability.           5 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=38666__zoneid=35969__cb=cc7e7faf4276f2b27a56__oadest=https%3A%2F%2Fraima.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dppc%26utm_campaign%3DSF \"Visit RaimaDB Website\")    \n*   [![Image 12: ONLYOFFICE Docs Reviews](https://a.fsdn.com/allura/s/onlyoffice/icon?1750859097?&w=48)](https://slashdot.org/software/p/ONLYOFFICE/ \"ONLYOFFICE Docs\")[ONLYOFFICE Docs](https://slashdot.org/software/p/ONLYOFFICE/ \"Learn more about ONLYOFFICE Docs \") ONLYOFFICE Docs is a secure online office suite for teams and businesses of all sizes. Create and edit docs, sheets, slides, fillable forms and PDFs. Collaborate with your teammates in real time using two co-editing modes, version history and other tools. Enable the AI assistant of your choice — ChatGPT, DeepSeek, Mistral, Groq AI, etc. Generate new content, summarize, translate and do more with your favourite AI tool while working on office files. Integrate ONLYOFFICE Docs into your business platform, whether it be Odoo, Alfresco, Confluence, Pipedrive, Nextcloud, Redmine, SuiteCRM, etc., via an integration app (40+ available integrations). Use Docs within ONLYOFFICE DocSpace, a room-based document collaboration platform equipped with the online office suite. Create dedicated spaces for different purposes, invite your teammates, assign access permissions and collaborate the way you like. With DocSpace, you can store, share and co-edit office files, and even interact with third parties.           672 Ratings  [Learn More](https://slashdot.org/software/link?oaparams=2__bannerid=40398__zoneid=37701__cb=ea118b06eecfd3b34b3b__oadest=https%3A%2F%2Fwww.onlyoffice.com%3Futm_source%3Dsourceforge%26utm_medium%3Dcpc%26utm_campaign%3Dsourceforge_2025%26utm_id%3D23051%26utm_content%3DVISIT-WEBSITE \"Visit ONLYOFFICE Docs Website\")    \n\n### Description\n\n EXAONE Deep represents a collection of advanced language models that are enhanced for reasoning, created by LG AI Research, and come in sizes of 2.4 billion, 7.8 billion, and 32 billion parameters. These models excel in a variety of reasoning challenges, particularly in areas such as mathematics and coding assessments. Significantly, the EXAONE Deep 2.4B model outshines other models of its size, while the 7.8B variant outperforms both open-weight models of similar dimensions and the proprietary reasoning model known as OpenAI o1-mini. Furthermore, the EXAONE Deep 32B model competes effectively with top-tier open-weight models in the field. The accompanying repository offers extensive documentation that includes performance assessments, quick-start guides for leveraging EXAONE Deep models with the Transformers library, detailed explanations of quantized EXAONE Deep weights formatted in AWQ and GGUF, as well as guidance on how to run these models locally through platforms like llama.cpp and Ollama. Additionally, this resource serves to enhance user understanding and accessibility to the capabilities of EXAONE Deep models. \n\n### Description\n\n Qwen LLM represents a collection of advanced large language models created by Alibaba Cloud's Damo Academy. These models leverage an extensive dataset comprising text and code, enabling them to produce human-like text, facilitate language translation, craft various forms of creative content, and provide informative answers to queries. Key attributes of Qwen LLMs include: A range of sizes: The Qwen series features models with parameters varying from 1.8 billion to 72 billion, catering to diverse performance requirements and applications. Open source availability: Certain versions of Qwen are open-source, allowing users to access and modify the underlying code as needed. Multilingual capabilities: Qwen is equipped to comprehend and translate several languages, including English, Chinese, and French. Versatile functionalities: In addition to language generation and translation, Qwen models excel in tasks such as answering questions, summarizing texts, and generating code, making them highly adaptable tools for various applications. Overall, the Qwen LLM family stands out for its extensive capabilities and flexibility in meeting user needs. \n\n### API Access\n\n Has API \n\n### API Access\n\n Has API \n\n### Screenshots [View All](https://slashdot.org/software/p/EXAONE-Deep/)\n\n[![Image 13: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/max/max/1)[![Image 14: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/max/max/1)[See more](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/#)\n\n### Screenshots [View All](https://slashdot.org/software/p/Qwen/)\n\nNo images available\n\n### Integrations\n\n AiAssistWorks \n\n C# \n\n CSS \n\n Clojure \n\n Decompute Blackbird \n\n F# \n\n HTML \n\n Java \n\n JavaScript \n\n Julia \n\n Kotlin \n\n LLaMA-Factory \n\n NativeMind \n\n OpenAI o1-mini \n\n Oumi \n\n RankLLM \n\n Ruby \n\n Scala \n\n TypeThink \n\n Visual Basic \n\n[Show More Integrations](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/#)\n\n[Explore All 3 Integrations](https://slashdot.org/software/p/EXAONE-Deep/integrations/)\n\n### Integrations\n\n AiAssistWorks \n\n C# \n\n CSS \n\n Clojure \n\n Decompute Blackbird \n\n F# \n\n HTML \n\n Java \n\n JavaScript \n\n Julia \n\n Kotlin \n\n LLaMA-Factory \n\n NativeMind \n\n OpenAI o1-mini \n\n Oumi \n\n RankLLM \n\n Ruby \n\n Scala \n\n TypeThink \n\n Visual Basic \n\n[Show More Integrations](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/#)\n\n[Explore All 43 Integrations](https://slashdot.org/software/p/Qwen/integrations/)\n\n### Pricing Details\n\n**Free**\n\n Free Trial \n\n Free Version \n\n### Pricing Details\n\n**Free**\n\n Free Trial \n\n Free Version \n\n### Deployment\n\n Web-Based \n\n On-Premises \n\n iPhone App \n\n iPad App \n\n Android App \n\n Windows \n\n Mac \n\n Linux \n\n Chromebook \n\n### Deployment\n\n Web-Based \n\n On-Premises \n\n iPhone App \n\n iPad App \n\n Android App \n\n Windows \n\n Mac \n\n Linux \n\n Chromebook \n\n### Customer Support\n\n Business Hours \n\n Live Rep (24/7) \n\n Online Support \n\n### Customer Support\n\n Business Hours \n\n Live Rep (24/7) \n\n Online Support \n\n### Types of Training\n\n Training Docs \n\n Webinars \n\n Live Training (Online) \n\n In Person \n\n### Types of Training\n\n Training Docs \n\n Webinars \n\n Live Training (Online) \n\n In Person \n\n### Vendor Details\n\n#### Company Name\n\nLG\n\n#### Founded\n\n1947\n\n#### Country\n\nSouth Korea\n\n#### Website\n\ngithub.com/LG-AI-EXAONE/EXAONE-Deep\n\n### Vendor Details\n\n#### Company Name\n\nAlibaba\n\n#### Founded\n\n1999\n\n#### Country\n\nChina\n\n#### Website\n\ngithub.com/QwenLM/Qwen\n\n### Product Features\n\n#### [AI Models](https://slashdot.org/software/ai-models/)\n\n### Product Features\n\n#### [AI Models](https://slashdot.org/software/ai-models/)\n\n#### [Large Language Models](https://slashdot.org/software/large-language-models/)\n\n#### [LLM API](https://slashdot.org/software/llm-api/)\n\n### Alternatives\n\n[![Image 15: Phi-4-reasoning Reviews](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://slashdot.org/software/p/Phi-4-reasoning/)\n#### [Phi-4-reasoning](https://slashdot.org/software/p/Phi-4-reasoning/)\n\nMicrosoft\n\n### Alternatives\n\n[![Image 16: Phi-3 Reviews](https://a.fsdn.com/allura/s/phi-3/icon?0de9df5cb5db7b395e32f67e1923c18d95a4078ec321df8ea3765cf0460d205f?&w=90)](https://slashdot.org/software/p/Phi-3/)\n#### [Phi-3](https://slashdot.org/software/p/Phi-3/)\n\nMicrosoft\n\n[![Image 17: Phi-4-reasoning-plus Reviews](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://slashdot.org/software/p/Phi-4-reasoning-plus/)\n#### [Phi-4-reasoning-plus](https://slashdot.org/software/p/Phi-4-reasoning-plus/)\n\nMicrosoft\n\n[![Image 18: OLMo 2 Reviews](https://a.fsdn.com/allura/s/olmo-2/icon?db8323a967a99ef3c3ecd2ff377e1a3eb3632cb2493c23ebab9a835be514c0a8?&w=90)](https://slashdot.org/software/p/OLMo-2/)\n#### [OLMo 2](https://slashdot.org/software/p/OLMo-2/)\n\nAi2\n\n[![Image 19: Qwen2 Reviews](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f?&w=90)](https://slashdot.org/software/p/Qwen2/)\n#### [Qwen2](https://slashdot.org/software/p/Qwen2/)\n\nAlibaba\n\n[![Image 20: Qwen2-VL Reviews](https://a.fsdn.com/allura/s/qwen2-vl/icon?46530744ad9f0efd67308d7d878442fffcdad4babc48357c136fe764710e8f2c?&w=90)](https://slashdot.org/software/p/Qwen2-VL/)\n#### [Qwen2-VL](https://slashdot.org/software/p/Qwen2-VL/)\n\nAlibaba\n\n[![Image 21: Phi-4-mini-reasoning Reviews](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://slashdot.org/software/p/Phi-4-mini-reasoning/)\n#### [Phi-4-mini-reasoning](https://slashdot.org/software/p/Phi-4-mini-reasoning/)\n\nMicrosoft\n\n[![Image 22: Qwen2 Reviews](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f?&w=90)](https://slashdot.org/software/p/Qwen2/)\n#### [Qwen2](https://slashdot.org/software/p/Qwen2/)\n\nAlibaba\n\n[![Image 23: DeepSeek R1 Reviews](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b?&w=90)](https://slashdot.org/software/p/DeepSeek-R1/)\n#### [DeepSeek R1](https://slashdot.org/software/p/DeepSeek-R1/)\n\nDeepSeek\n\n[See All Alternatives](https://slashdot.org/software/p/EXAONE-Deep/alternatives)\n\n[![Image 24: Samsung Gauss Reviews](https://a.fsdn.com/allura/s/samsung-gauss/icon?3764bed16136aac7b2547e89f3ed016cd6c1600debbb568ba39d64e6a48ca252?&w=90)](https://slashdot.org/software/p/Samsung-Gauss/)\n#### [Samsung Gauss](https://slashdot.org/software/p/Samsung-Gauss/)\n\nSamsung\n\n[See All Alternatives](https://slashdot.org/software/p/Qwen/alternatives)\n\nClaim/Edit This Page\n\n[Do you represent this company? Claim This Page.](https://slashdot.org/software/transfer_site/sf/?url_path=/software/product/EXAONE-Deep/claim&origin=sd)\n\nClaim/Edit This Page\n\n[Do you represent this company? Claim This Page.](https://slashdot.org/software/transfer_site/sf/?url_path=/software/product/Qwen/claim&origin=sd)\n\n[Compare Business Software](https://slashdot.org/software/ \"Compare Business Software\")[Add Your Software](https://slashdot.org/software/transfer_site/sf/?url_path=/software/vendors/new&origin=sd \"Add Your Software\")[Software Advertising Options](https://slashdot.org/software/transfer_site/sf/?url_path=/software/vendors/pricing/&origin=sd \"Software Advertising Options\")\n\n[Feedback](mailto:feedback@slashdot.org \"Feedback\")[@slashdot](https://x.com/slashdot \"@slashdot\")Telephone: +1 (858) 247-0742\n\n[](https://slashdot.org/software/ \"Compare Business Software\")\n\n[Terms](https://slashdotmedia.com/terms-of-use \"Terms\")[Privacy](https://slashdotmedia.com/privacy-statement/ \"Privacy\")[Privacy Choices](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/# \"Privacy Choices\")\n\n © 2025 [Slashdot Media](https://slashdotmedia.com/). All Rights Reserved. \n\n#### Find software to compare\n\nSuggested Software\n\n*   [![Image 25: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning-plus Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-reasoning-plus)\n*   [![Image 26: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-reasoning)\n*   [![Image 27: Logo](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-mini-reasoning Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Phi-4-mini-reasoning)\n*   [![Image 28: Logo](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f)Qwen2 Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Qwen2)\n*   [![Image 29: Logo](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b)DeepSeek R1 Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=DeepSeek-R1)\n*   [![Image 30: Logo](https://a.fsdn.com/allura/s/tulu-3/icon?db8323a967a99ef3c3ecd2ff377e1a3eb3632cb2493c23ebab9a835be514c0a8)Tülu 3 Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Tulu-3)\n*   [![Image 31: Logo](https://a.fsdn.com/allura/s/pixtral-12b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Pixtral Large Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Pixtral-Large)\n*   [![Image 32: Logo](https://a.fsdn.com/allura/s/mixtral-8x7b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Mixtral 8x7B Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Mixtral-8x7B)\n*   [![Image 33: Logo](https://a.fsdn.com/allura/s/deepseek-coder-v2/icon?30a90148f6c74cbd4b4fb1c601a0e926d150c83ede9b065732ffa2d9fd056781)DeepSeek-Coder-V2 Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=DeepSeek-Coder-V2)\n*   [![Image 34: Logo](https://a.fsdn.com/allura/s/llama-4-behemoth/icon?ea72543a1b0a7dec15408328f9ec9dea7a408593f0b38c32b69bee9d8061d302)Llama 4 Behemoth Compare](https://slashdot.org/software/comparison/EXAONE-Deep-vs-Qwen/add-software/?software_name=Llama-4-Behemoth)\n\n×\n\n![Image 35](https://slashdot.org/software/visit?idsite=3&rec=1&rand=99093&dimension2=pg_commercial_compare&url=https%3A%2F%2Fslashdot.org%2Fsoftware%2Fcomparison%2FEXAONE-Deep-vs-Qwen%2F&action_name=Compare+EXAONE+Deep+vs.+Qwen+in+2025)![Image 36](https://slashdot.org/software/visit?idsite=3&rec=1&rand=23844&url=https%3A%2F%2Fslashdot.org%2Fsoftware%2Fcomparison%2FEXAONE-Deep-vs-Qwen%2F&action_name=Compare+EXAONE+Deep+vs.+Qwen+in+2025&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=EXAONE-Deep)![Image 37](https://slashdot.org/software/visit?idsite=3&rec=1&rand=18292&url=https%3A%2F%2Fslashdot.org%2Fsoftware%2Fcomparison%2FEXAONE-Deep-vs-Qwen%2F&action_name=Compare+EXAONE+Deep+vs.+Qwen+in+2025&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=Qwen)\n"
    },
    {
        "url": "https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/",
        "title": "EXAONE Deep vs. Qwen-7B Comparison - SourceForge",
        "content": "EXAONE Deep is a series of reasoning-enhanced language models developed by LG AI Research, featuring parameter sizes of 2.4 billion, 7.8 billion, and 32 billion. These models demonstrate superior capabilities in various reasoning tasks, including math and coding benchmarks. Notably, EXAONE Deep 2.4B outperforms other models of comparable size, EXAONE Deep 7.8B surpasses both open-weight models of similar scale and the proprietary reasoning model OpenAI o1-mini, and EXAONE Deep 32B shows [...] pretraining data. We have pretrained Qwen-7B on a self-constructed large-scale high-quality dataset of over 2.2 trillion tokens. The dataset includes plain texts and codes, and it covers a wide range of domains, including general domain data and professional domain data. Strong performance. In comparison with the models of the similar model size, we outperform the competitors on a series of benchmark datasets, which evaluates natural language understanding, mathematics, coding, etc. And more.",
        "score": 0.76554126,
        "raw_content": "EXAONE Deep vs. Qwen-7B Comparison\n\n===============\n\n*   [Join/Login](https://sourceforge.net/auth/)\n*   [Business Software](https://sourceforge.net/software/)\n*   [Open Source Software](https://sourceforge.net/directory/)\n*   [For Vendors](https://sourceforge.net/software/vendors/ \"For Vendors\")\n*   [Blog](https://sourceforge.net/blog/ \"Blog\")\n*   [About](https://sourceforge.net/about)\n*   More\n*       *   [Articles](https://sourceforge.net/articles/)\n    *   [SourceForge Podcast](https://sourceforge.net/articles/category/sourceforge-podcast/)\n    *   [Support / Documentation](https://docs.sourceforge.net/ \"Support / Documentation Section\")\n    *   [Subscribe to our Newsletter](https://sourceforge.net/user/newsletters)\n    *   [Support Request](https://sourceforge.net/support)\n\n[![Image 1: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")[](https://sourceforge.net/user/newsletters \"Subscribe to our newsletter\")[For Vendors](https://sourceforge.net/software/vendors/ \"For Vendors\")[Add a Product](https://sourceforge.net/software/vendors/new \"Add a Commercial Product\")[Join](https://sourceforge.net/user/registration_business \"Join\")[Login](https://sourceforge.net/auth/ \"Login\")\n\n[![Image 2: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n[![Image 3: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n[Business Software](https://sourceforge.net/software/)\n\n[Open Source Software](https://sourceforge.net/directory/ \"Browse\")\n\n[SourceForge Podcast](https://sourceforge.net/articles/category/sourceforge-podcast/)\n\nResources\n*   [Articles](https://sourceforge.net/articles/)\n*   [Case Studies](https://sourceforge.net/software/case-studies/)\n*   [Blog](https://sourceforge.net/blog/)\n\n Menu \n*   [Help](https://sourceforge.net/support)\n*   [Create](https://sourceforge.net/create)\n*   [Join](https://sourceforge.net/user/registration_business/ \"Join\")\n*   [Login](https://sourceforge.net/auth/ \"Login\")\n\n[![Image 4](https://a.fsdn.com/con/assets/maxnav/sourceforge/nav32-347199d0-d5c91966.png)](https://www.avast.com/lp-free-av?full_trSrc=mmm_srf_dlp_008_406_a&utm_medium=referral&utm_source=sourceforge&utm_campaign=srf_dlp_008_406_a:site_banner)\n\nEXAONE Deep vs. Qwen-7B Comparison Chart\n========================================\n\n[![Image 5: EXAONE Deep](https://a.fsdn.com/allura/s/exaone-deep/icon?863150716bc856082e8821e5e7778494f914f43b5b589d7434f7e7fc8cd916d5?&w=90)](https://sourceforge.net/software/product/EXAONE-Deep/)\n\n[EXAONE Deep](https://sourceforge.net/software/product/EXAONE-Deep/)\n--------------------------------------------------------------------\n\n LG[![Image 6: Qwen-7B](https://a.fsdn.com/allura/s/qwen-7b/icon?9e0b0a3953387cc2d0c7f2e49e069bb0c8f9db63c06d29700f8f4ed3b09a1e76?&w=90)](https://sourceforge.net/software/product/Qwen-7B/)\n\n[Qwen-7B](https://sourceforge.net/software/product/Qwen-7B/)\n------------------------------------------------------------\n\nAlibaba++\n[Learn More](https://sourceforge.net/software/product/EXAONE-Deep/)\n\n[Update Features](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#claim_exaone-deep.s)[Learn More](https://sourceforge.net/software/product/Qwen-7B/)\n\n[Update Features](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#claim_qwen-7b.s)Add To Compare Add To Compare\n\n### Related Products\n\n*   [![Image 7: Vertex AI](https://a.fsdn.com/allura/s/google-cloud-ml-engine/icon?7c9ed3165f15fb567dfd971732c04b698e249f9289fcc8d75e1e44ebd9f98ce5?&w=48)](https://sourceforge.net/software/product/Vertex-AI/ \"Vertex AI\")[Vertex AI](https://sourceforge.net/software/product/Vertex-AI/ \"Learn more about Vertex AI \") Build, deploy, and scale machine learning (ML) models faster, with fully managed ML tools for any use case. Through Vertex AI Workbench, Vertex AI is natively integrated with BigQuery, Dataproc, and Spark. You can use BigQuery ML to create and execute machine learning models in BigQuery using standard SQL queries on existing business intelligence tools and spreadsheets, or you can export datasets from BigQuery directly into Vertex AI Workbench and run your models from there. Use Vertex Data Labeling to generate highly accurate labels for your data collection. Vertex AI Agent Builder enables developers to create and deploy enterprise-grade generative AI applications. It offers both no-code and code-first approaches, allowing users to build AI agents using natural language instructions or by leveraging frameworks like LangChain and LlamaIndex.           713 Ratings  ![Image 8](https://sourceforge.net/software/tp3/?b=67689&z=65061&c=13059&cb=ba4ba318913279ce56db)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=67689__zoneid=65061__cb=678be02e2b4547e522d8__oadest=https%3A%2F%2Fcloud.google.com%2Fvertex-ai%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DVertex_AI \"Visit Vertex AI Website\")    \n*   [![Image 9: Google AI Studio](https://a.fsdn.com/allura/s/google-ai-studio/icon?560e6b21275529b4cf46005ac941cc8d9e6e5db4fe36281f8f5d45b4db10db7a?&w=48)](https://sourceforge.net/software/product/Google-AI-Studio/ \"Google AI Studio\")[Google AI Studio](https://sourceforge.net/software/product/Google-AI-Studio/ \"Learn more about Google AI Studio \") Google AI Studio is a comprehensive, web-based development environment that democratizes access to Google's cutting-edge AI models, notably the Gemini family, enabling a broad spectrum of users to explore and build innovative applications. This platform facilitates rapid prototyping by providing an intuitive interface for prompt engineering, allowing developers to meticulously craft and refine their interactions with AI. Beyond basic experimentation, AI Studio supports the seamless integration of AI capabilities into diverse projects, from simple chatbots to complex data analysis tools. Users can rigorously test different prompts, observe model behaviors, and iteratively refine their AI-driven solutions within a collaborative and user-friendly environment. This empowers developers to push the boundaries of AI application development, fostering creativity and accelerating the realization of AI-powered solutions.           4 Ratings  ![Image 10](https://sourceforge.net/software/tp3/?b=80946&z=78342&c=15627&cb=a2d02170ebe2891c6cfb)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=80946__zoneid=78342__cb=a61cfdf2fc3b158b00a4__oadest=https%3A%2F%2Faistudio.google.com%2Fwelcome%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Daistudio \"Visit Google AI Studio Website\")    \n*   [![Image 11: LM-Kit.NET](https://a.fsdn.com/allura/s/lm-kit-net/icon?b204f29e26a682c5dc80ccd9d8dbfeb0b2e58eacb975518aee36d828897a2951?&w=48)](https://sourceforge.net/software/product/LM-Kit.NET/ \"LM-Kit.NET\")[LM-Kit.NET](https://sourceforge.net/software/product/LM-Kit.NET/ \"Learn more about LM-Kit.NET \") LM-Kit.NET is a cutting-edge, high-level inference SDK designed specifically to bring the advanced capabilities of Large Language Models (LLM) into the C# ecosystem. Tailored for developers working within .NET, LM-Kit.NET provides a comprehensive suite of powerful Generative AI tools, making it easier than ever to integrate AI-driven functionality into your applications. The SDK is versatile, offering specialized AI features that cater to a variety of industries. These include text completion, Natural Language Processing (NLP), content retrieval, text summarization, text enhancement, language translation, and much more. Whether you are looking to enhance user interaction, automate content creation, or build intelligent data retrieval systems, LM-Kit.NET offers the flexibility and performance needed to accelerate your project.           16 Ratings  ![Image 12](https://sourceforge.net/software/tp3/?b=79640&z=77038&c=15392&cb=21d59bc59cef86012eee)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=79640__zoneid=77038__cb=53865f062ffa44b59d68__oadest=https%3A%2F%2Flm-kit.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3Dsourceforgelisting \"Visit LM-Kit.NET Website\")    \n*   [![Image 13: Qloo](https://a.fsdn.com/allura/s/qloo/icon?cea84810c00f7e710b3a38b95543f24e0d3cca1f2100ba34f7cf98ce3bd28f60?&w=48)](https://sourceforge.net/software/product/Qloo/ \"Qloo\")[Qloo](https://sourceforge.net/software/product/Qloo/ \"Learn more about Qloo \") Qloo is the “Cultural AI”, decoding and predicting consumer taste across the globe. A privacy-first API that predicts global consumer preferences and catalogs hundreds of millions of cultural entities. Through our API, we provide contextualized personalization and insights based on a deep understanding of consumer behavior and more than 575 million people, places, and things. Our technology empowers you to look beyond trends and uncover the connections behind people’s tastes in the world around them. Look up entities in our vast library spanning categories like brands, music, film, fashion, travel destinations, and notable people. Results are delivered within milliseconds and can be weighted by factors such as regionalization and real-time popularity. Used by companies who want to incorporate best-in-class data in their consumer experiences. Our flagship recommendation API delivers results based on demographics, preferences, cultural entities, metadata, and geolocational factors.           23 Ratings  ![Image 14](https://sourceforge.net/software/tp3/?b=55113&z=52441&c=10713&cb=075ab0a78ce1746452f5)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=55113__zoneid=52441__cb=c2594420c2e04458dbc2__oadest=https%3A%2F%2Fqloo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dsourceforge%26utm_campaign%3Dsourceforge%26utm_id%3Dsf \"Visit Qloo Website\")    \n*   [![Image 15: Nexo](https://a.fsdn.com/allura/s/nexo/icon?628adf0adb50456ae1804a9838dc6cb6908d0f0c19c476fa0904a0829da8a2bd?&w=48)](https://sourceforge.net/software/product/Nexo/ \"Nexo\")[Nexo](https://sourceforge.net/software/product/Nexo/ \"Learn more about Nexo \") Nexo is a premier digital assets wealth platform designed to empower clients to grow, manage, and preserve their crypto holdings. Our mission is to lead the next generation of wealth creation by focusing on customer success and delivering tailored solutions that build enduring value, supported by 24/7 client care. Since 2018, Nexo has provided unmatched opportunities to forward-thinking clients in over 200 jurisdictions. With over $7 billion in AUM and $320 billion processed, we bring lasting value to millions worldwide. Our all-in-one platform combines advanced technology with a client-first approach, offering high-yield flexible and fixed-term savings, crypto-backed loans, sophisticated trading tools, and liquidity solutions, including the first crypto debit/credit card. Built on deep industry expertise, a sustainable business model, robust infrastructure, stringent security, and global licensing, Nexo champions innovation and long-lasting prosperity.           16,077 Ratings  ![Image 16](https://sourceforge.net/software/tp3/?b=41391&z=38686&c=8041&cb=7ae94e6bf4637c13fc13)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=41391__zoneid=38686__cb=276c60887492e3025579__oadest=https%3A%2F%2Fnexo.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dfixed%26utm_campaign%3Dsourceforge_mb_generic_q225 \"Visit Nexo Website\")    \n*   [![Image 17: Valant Behavioral Health EHR](https://a.fsdn.com/allura/s/valant-behavioral-health-ehr/icon?1732903952?&w=48)](https://sourceforge.net/software/product/Valant-Behavioral-Health-EHR/ \"Valant Behavioral Health EHR\")[Valant Behavioral Health EHR](https://sourceforge.net/software/product/Valant-Behavioral-Health-EHR/ \"Learn more about Valant Behavioral Health EHR \") Provide exceptional, data-driven care from anywhere with Valant, the all-in-one EHR and practice management software designed exclusively for behavioral health practices of all sizes. - Focus the efforts of your entire workflow in one system built for individual psychotherapy, medication management, group counseling and more, whether delivered in person or virtually. - Speed your documentation process with 100+ clinical templates for evidence-based and specialized therapies, such as DBT, CBT, MFT, TMS, and weight and eating disorders. - Track your progress with 100+ comprehensive reports on patient retention, compliance, productivity, and financial performance. Demonstrate the value of your care to payers with 80+ reportable outcome measures you can schedule send to patients, auto-score, document, and track progress.           321 Ratings  ![Image 18](https://sourceforge.net/software/tp3/?b=36895&z=34198&c=7886&cb=747cd3d4985f191d6c05)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=36895__zoneid=34198__cb=80f40caa84067092986a__oadest=https%3A%2F%2Fwww.valant.io%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlisting%26utm_campaign%3Ddemo \"Visit Valant Behavioral Health EHR Website\")    \n*   [![Image 19: Google Cloud Speech-to-Text](https://a.fsdn.com/allura/s/google-cloud-speech-to-text/icon?615c0556bb44a0e185f9242eb24c328727ac3e0e3f1ddaf3328b249157e95480?&w=48)](https://sourceforge.net/software/product/Google-Cloud-Speech-to-Text/ \"Google Cloud Speech-to-Text\")[Google Cloud Speech-to-Text](https://sourceforge.net/software/product/Google-Cloud-Speech-to-Text/ \"Learn more about Google Cloud Speech-to-Text \") Google Cloud’s Speech API processes more than 1 billion voice minutes per month with close to human levels of understanding for many commonly spoken languages. Powered by the best of Google's AI research and technology, Google Cloud's Speech-to-Text API helps you accurately transcribe speech into text in 73 languages and 137 different local variants. Leverage Google’s most advanced deep learning neural network algorithms for automatic speech recognition (ASR) and deploy ASR wherever you need it, whether in the cloud with the API, on-premises with Speech-to-Text On-Prem, or locally on any device with Speech On-Device.           374 Ratings  ![Image 20](https://sourceforge.net/software/tp3/?b=67733&z=65105&c=13067&cb=0373631495223b3019cf)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=67733__zoneid=65105__cb=2bddc5dbdf0001391f7b__oadest=https%3A%2F%2Fcloud.google.com%2Fspeech-to-text%3Futm_source%3Dsourceforge%26utm_medium%3Dreferral%26utm_campaign%3DSpeech_To_Text \"Visit Google Cloud Speech-to-Text Website\")    \n*   [![Image 21: Windsurf Editor](https://a.fsdn.com/allura/s/codeium/icon?6ab638dbe26fb8b3b0dd6f3c66956bf5b77d72dc2883263893fa53864c365730?&w=48)](https://sourceforge.net/software/product/The-Windsurf-Editor/ \"Windsurf Editor\")[Windsurf Editor](https://sourceforge.net/software/product/The-Windsurf-Editor/ \"Learn more about Windsurf Editor \") The Windsurf Editor is a free AI-powered IDE and AI coding assistant that accelerates development by providing intelligent code generation and agents in over 70 programming languages and more than 40 IDEs, including VSCode, JetBrains, and Jupyter Notebooks. With Windsurf, developers can write code faster, eliminate repetitive tasks, and stay in the flow state—whether they're working with Python, JavaScript, C++, or any other language. Built on billions of lines of open-source code, Windsurf Editor understands and anticipates your coding needs, offering multiline suggestions, automated unit tests, and even natural language explanations for complex functions. It’s perfect for streamlining code writing, reducing boilerplate, and cutting down the time spent on documentation searches. Trusted by individual developers and Fortune 500 companies alike, Windsurf Editor is your go-to solution for boosting productivity and writing better code. Try Windsurf for free today!           137 Ratings  ![Image 22](https://sourceforge.net/software/tp3/?b=57601&z=54925&c=11107&cb=872cd1b1887c39a41328)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=57601__zoneid=54925__cb=bd0e8bdd4fca8a593f05__oadest=https%3A%2F%2Fwindsurf.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dlist%26utm_campaign%3Dsourceforge1 \"Visit Windsurf Editor Website\")    \n*   [![Image 23: RaimaDB](https://a.fsdn.com/allura/s/raima-database-manager/icon?78e5d6a19e94f230710ef8a0a54dbc7b42aa41fa93525195b40963bf23295a91?&w=48)](https://sourceforge.net/software/product/RaimaDB/ \"RaimaDB\")[RaimaDB](https://sourceforge.net/software/product/RaimaDB/ \"Learn more about RaimaDB \") RaimaDB is an embedded time series database for IoT and Edge devices that can run in-memory. It is an extremely powerful, lightweight and secure RDBMS. Field tested by over 20 000 developers worldwide and has more than 25 000 000 deployments. RaimaDB is a high-performance, cross-platform embedded database designed for mission-critical applications, particularly in the Internet of Things (IoT) and edge computing markets. It offers a small footprint, making it suitable for resource-constrained environments, and supports both in-memory and persistent storage configurations. RaimaDB provides developers with multiple data modeling options, including traditional relational models and direct relationships through network model sets. It ensures data integrity with ACID-compliant transactions and supports various indexing methods such as B+Tree, Hash Table, R-Tree, and AVL-Tree.           5 Ratings  ![Image 24](https://sourceforge.net/software/tp3/?b=28971&z=26159&c=5625&cb=3a476a14c5c913548458)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=28971__zoneid=26159__cb=076ac9c2f375dd25759e__oadest=https%3A%2F%2Fraima.com%2F%3Futm_source%3Dsourceforge%26utm_medium%3Dppc%26utm_campaign%3DSF \"Visit RaimaDB Website\")    \n*   [![Image 25: ONLYOFFICE Docs](https://a.fsdn.com/allura/s/onlyoffice/icon?1750859097?&w=48)](https://sourceforge.net/software/product/ONLYOFFICE/ \"ONLYOFFICE Docs\")[ONLYOFFICE Docs](https://sourceforge.net/software/product/ONLYOFFICE/ \"Learn more about ONLYOFFICE Docs \") ONLYOFFICE is an open-source project that offers cloud-based and self-hosted solutions for business of all sizes. The key product is ONLYOFFICE Docs, a secure office suite that seamlessly integrates into the most popular platforms, e.g. Odoo, Alfresco, Confluence, Pipedrive, Redmine, SuiteCRM and more. When integrated, ONLYOFFICE Docs provides the users of your business app with editors for documents, spreadsheets, presentations, forms, PDFs and diagrams. The ONLYOFFICE suite makes it possible to collaborate on office files in real time. The built-in AI assistant is compatible with ChatGPT, DeepSeek, Mistral and other AI providers to ensure a flawless editing experience. You can use Docs within ONLYOFFICE DocSpace, a room-based document collaboration platform that allows you to create dedicated spaces where you can assign access permissions and collaborate with your teammates. With DocSpace, you can store, share and co-edit office files, and even interact with third parties.           672 Ratings  ![Image 26](https://sourceforge.net/software/tp3/?b=33890&z=31162&c=7102&cb=ee7182c7512574bd0859)[Visit Website](https://sourceforge.net/software/link?oaparams=2__bannerid=33890__zoneid=31162__cb=f26d60085cf5a5e9fa8e__oadest=https%3A%2F%2Fwww.onlyoffice.com%3Futm_source%3Dsourceforge%26utm_medium%3Dcpc%26utm_campaign%3Dsourceforge_2025%26utm_id%3D23051%26utm_content%3DVISIT-WEBSITE \"Visit ONLYOFFICE Docs Website\")\n### About\n\n EXAONE Deep is a series of reasoning-enhanced language models developed by LG AI Research, featuring parameter sizes of 2.4 billion, 7.8 billion, and 32 billion. These models demonstrate superior capabilities in various reasoning tasks, including math and coding benchmarks. Notably, EXAONE Deep 2.4B outperforms other models of comparable size, EXAONE Deep 7.8B surpasses both open-weight models of similar scale and the proprietary reasoning model OpenAI o1-mini, and EXAONE Deep 32B shows competitive performance against leading open-weight models. The repository provides comprehensive documentation covering performance evaluations, quickstart guides for using EXAONE Deep models with Transformers, explanations of quantized EXAONE Deep weights in AWQ and GGUF formats, and instructions for running EXAONE Deep models locally using frameworks like llama.cpp and Ollama.### About\n\n Qwen-7B is the 7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Alibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc. Additionally, based on the pretrained Qwen-7B, we release Qwen-7B-Chat, a large-model-based AI assistant, which is trained with alignment techniques. The features of the Qwen-7B series include: Trained with high-quality pretraining data. We have pretrained Qwen-7B on a self-constructed large-scale high-quality dataset of over 2.2 trillion tokens. The dataset includes plain texts and codes, and it covers a wide range of domains, including general domain data and professional domain data. Strong performance. In comparison with the models of the similar model size, we outperform the competitors on a series of benchmark datasets, which evaluates natural language understanding, mathematics, coding, etc. And more.\n### Platforms Supported\n\n Windows \n\n Mac \n\n Linux \n\n Cloud \n\n On-Premises \n\n iPhone \n\n iPad \n\n Android \n\n Chromebook### Platforms Supported\n\n Windows \n\n Mac \n\n Linux \n\n Cloud \n\n On-Premises \n\n iPhone \n\n iPad \n\n Android \n\n Chromebook\n### Audience\n\n Researchers and developers requiring a tool offering advanced language models for enhanced reasoning tasks in mathematics and coding### Audience\n\n Large language model developers\n### Support\n\n Phone Support \n\n 24/7 Live Support \n\n Online### Support\n\n Phone Support \n\n 24/7 Live Support \n\n Online\n### API\n\n Offers API### API\n\n Offers API\n### Screenshots and Videos\n\n[![Image 27: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/1-baeaffb0.PNG/max/max/1)[![Image 28: EXAONE Deep Screenshot 1](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/245/183/1)](https://a.fsdn.com/con/app/proj/exaone-deep.s/screenshots/2-bf942fdc.PNG/max/max/1)[View more images or videos](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#)### Screenshots and Videos\n\n[![Image 29: Qwen-7B Screenshot 1](https://a.fsdn.com/con/app/proj/qwen-7b.s/screenshots/Screenshot%202023-08-04%20at%2011.03.19%20AM-4b1f96e0.png/245/183/1)](https://a.fsdn.com/con/app/proj/qwen-7b.s/screenshots/Screenshot%202023-08-04%20at%2011.03.19%20AM-4b1f96e0.png/max/max/1)[View more images or videos](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#)\n### Pricing\n\n**Free**\n\n Free Version \n\n Free Trial### Pricing\n\n**Free**\n\n Free Version \n\n Free Trial\n### Reviews/Ratings\n\nOverall 0.0 / 5 \n\nease 0.0 / 5 \n\nfeatures 0.0 / 5 \n\ndesign 0.0 / 5 \n\nsupport 0.0 / 5 \n\nThis software hasn't been reviewed yet. Be the first to provide a review:\n\n[Review this Software](https://sourceforge.net/software/product/EXAONE-Deep/reviews/new)### Reviews/Ratings\n\nOverall 0.0 / 5 \n\nease 0.0 / 5 \n\nfeatures 0.0 / 5 \n\ndesign 0.0 / 5 \n\nsupport 0.0 / 5 \n\nThis software hasn't been reviewed yet. Be the first to provide a review:\n\n[Review this Software](https://sourceforge.net/software/product/Qwen-7B/reviews/new)\n### Training\n\n Documentation \n\n Webinars \n\n Live Online \n\n In Person### Training\n\n Documentation \n\n Webinars \n\n Live Online \n\n In Person\n### Company Information\n\n**LG**\n\nFounded: 1947\n\nSouth Korea\n\ngithub.com/LG-AI-EXAONE/EXAONE-Deep### Company Information\n\n**Alibaba**\n\nFounded: 1999\n\nChina\n\ngithub.com/QwenLM/Qwen-7B\n### Alternatives\n\n[![Image 30: Phi-4-reasoning-plus](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-reasoning-plus/)\n#### [Phi-4-reasoning-plus](https://sourceforge.net/software/product/Phi-4-reasoning-plus/)\n\nMicrosoft### Alternatives\n\n[![Image 31: Athene-V2](https://a.fsdn.com/allura/s/athene-v2/icon?efdfd23c8eae889fe15667c766a69e2f65fa1842c97303aa6f159ec18196919c?&w=90)](https://sourceforge.net/software/product/Athene-V2/)\n#### [Athene-V2](https://sourceforge.net/software/product/Athene-V2/)\n\nNexusflow\n[![Image 32: Phi-4-reasoning](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-reasoning/)\n#### [Phi-4-reasoning](https://sourceforge.net/software/product/Phi-4-reasoning/)\n\nMicrosoft[![Image 33: ChatGLM](https://a.fsdn.com/allura/s/chatglm-6b/icon?d15057c63350d197d96b7907d42e67e452f1e58d68fae82c39c9cdd48fa2048a?&w=90)](https://sourceforge.net/software/product/ChatGLM/)\n#### [ChatGLM](https://sourceforge.net/software/product/ChatGLM/)\n\nZhipu AI\n[![Image 34: Phi-4-mini-reasoning](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef?&w=90)](https://sourceforge.net/software/product/Phi-4-mini-reasoning/)\n#### [Phi-4-mini-reasoning](https://sourceforge.net/software/product/Phi-4-mini-reasoning/)\n\nMicrosoft[![Image 35: Mistral 7B](https://a.fsdn.com/allura/s/mistral-7b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954?&w=90)](https://sourceforge.net/software/product/Mistral-7B/)\n#### [Mistral 7B](https://sourceforge.net/software/product/Mistral-7B/)\n\nMistral AI\n[![Image 36: Qwen2](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f?&w=90)](https://sourceforge.net/software/product/Qwen2/)\n#### [Qwen2](https://sourceforge.net/software/product/Qwen2/)\n\nAlibaba[![Image 37: CodeQwen](https://a.fsdn.com/allura/s/codeqwen/icon?70ec4bb4cd1e350afbb62690b2fdccf46ce454b1d46cd48b5e22a70214e96360?&w=90)](https://sourceforge.net/software/product/CodeQwen/)\n#### [CodeQwen](https://sourceforge.net/software/product/CodeQwen/)\n\nAlibaba\n[![Image 38: DeepSeek R1](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b?&w=90)](https://sourceforge.net/software/product/DeepSeek-R1/)\n#### [DeepSeek R1](https://sourceforge.net/software/product/DeepSeek-R1/)\n\nDeepSeek\n\n[View All](https://sourceforge.net/software/product/EXAONE-Deep/alternatives)[![Image 39: Qwen](https://a.fsdn.com/allura/s/qwen/icon?c869f29d5126d635ac01fbb7a9e623d14b32dadd3a738f98738db68085ff8e82?&w=90)](https://sourceforge.net/software/product/Qwen/)\n#### [Qwen](https://sourceforge.net/software/product/Qwen/)\n\nAlibaba\n\n[View All](https://sourceforge.net/software/product/Qwen-7B/alternatives)\n### Categories\n\n[AI Models](https://sourceforge.net/software/ai-models/)### Categories\n\n[AI Models](https://sourceforge.net/software/ai-models/)\n\n[Large Language Models](https://sourceforge.net/software/large-language-models/)\n\n### Integrations\n\n Alibaba Cloud \n\n C \n\n C++ \n\n Clojure \n\n Elixir \n\n Go \n\n HTML \n\n Horay.ai \n\n Java \n\n JavaScript \n\n Julia \n\n Kotlin \n\n LM-Kit.NET \n\n Ollama \n\n Python \n\n Qwen Chat \n\n Ruby \n\n Rust \n\n Sesterce \n\n Visual Basic \n\n[Show More Integrations](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#)\n\n[View All 3 Integrations](https://sourceforge.net/software/product/EXAONE-Deep/integrations/)### Integrations\n\n Alibaba Cloud \n\n C \n\n C++ \n\n Clojure \n\n Elixir \n\n Go \n\n HTML \n\n Horay.ai \n\n Java \n\n JavaScript \n\n Julia \n\n Kotlin \n\n LM-Kit.NET \n\n Ollama \n\n Python \n\n Qwen Chat \n\n Ruby \n\n Rust \n\n Sesterce \n\n Visual Basic \n\n[Show More Integrations](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#)\n\n[View All 31 Integrations](https://sourceforge.net/software/product/Qwen-7B/integrations/)\nClaim EXAONE Deep and update features and information\n\n[Claim EXAONE Deep and update features and information](https://sourceforge.net/software/product/EXAONE-Deep/claim)Claim Qwen-7B and update features and information\n\n[Claim Qwen-7B and update features and information](https://sourceforge.net/software/product/Qwen-7B/claim)\n\nSourceForge\n\n*   [Open Source Software](https://sourceforge.net/directory/ \"Open Source Software Directory\")\n*   [Business Software](https://sourceforge.net/software/ \"Business Software Directory\")\n*   [Add Your Software](https://sourceforge.net/software/vendors/new)\n*   [Business Software Advertising](https://sourceforge.net/software/vendors/pricing/)\n\nCompany\n\n*   [About](https://sourceforge.net/about)\n*   [Team](https://sourceforge.net/about/leadership \"Open Source Software Directory\")\n*   SourceForge Headquarters\n\n225 Broadway Suite 1600\n\nSan Diego, CA 92101\n\n+1 (858) 422-6466\n\n*   [](https://twitter.com/sourceforge \"SourceForge on X\")[](https://fosstodon.org/@sourceforge \"SourceForge on Mastodon\")[](https://www.facebook.com/sourceforgenet/ \"SourceForge on Facebook\")[](https://www.linkedin.com/company/sourceforge.net \"SourceForge on LinkedIn\")[](https://sourceforge.net/user/newsletters \"Subscribe to our newsletter\")\n\nResources\n\n*   [Support / Documentation](https://docs.sourceforge.net/ \"Support / Documentation Section\")\n*   [Site Status](https://fosstodon.org/@sourceforgestatus \"Site Status\")\n*   [SourceForge Reviews](https://sourceforge.net/reviews \"Reviews\")\n\n[![Image 40: SourceForge logo](https://a.fsdn.com/con/images/sandiego/sf-logo-full.svg)](https://sourceforge.net/ \"Home\")\n\n © 2025 Slashdot Media. All Rights Reserved. \n\n[Terms](https://slashdotmedia.com/terms-of-use \"Terms\")[Privacy](https://slashdotmedia.com/privacy-statement/ \"Privacy\")[Opt Out](https://slashdotmedia.com/opt-out-choices/ \"Opt Out\")[Advertise](https://slashdotmedia.com/contact/ \"Advertise\")\n\n#### Find software to compare\n\nSuggested Software\n\n*   [![Image 41: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning-plus/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning-plus Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Phi-4-reasoning-plus)\n*   [![Image 42: Logo](https://a.fsdn.com/allura/s/phi-4-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-reasoning Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Phi-4-reasoning)\n*   [![Image 43: Logo](https://a.fsdn.com/allura/s/phi-4-mini-reasoning/icon?0edd25b3b2bfeb46ec8bc4cc87443153de239eb6c98b4dadb9bab4c19abca7ef)Phi-4-mini-reasoning Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Phi-4-mini-reasoning)\n*   [![Image 44: Logo](https://a.fsdn.com/allura/s/qwen2/icon?713deb695ec7c523e6c11f861f78649b1ddfec671ffb5520a3b29ae62047619f)Qwen2 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Qwen2)\n*   [![Image 45: Logo](https://a.fsdn.com/allura/s/deepseek-r1/icon?04956749f955fc196f98047e3c7300e05b0f337dd7dae03ef625a73053f16d5b)DeepSeek R1 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=DeepSeek-R1)\n*   [![Image 46: Logo](https://a.fsdn.com/allura/s/tulu-3/icon?db8323a967a99ef3c3ecd2ff377e1a3eb3632cb2493c23ebab9a835be514c0a8)Tülu 3 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Tulu-3)\n*   [![Image 47: Logo](https://a.fsdn.com/allura/s/pixtral-12b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Pixtral Large Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Pixtral-Large)\n*   [![Image 48: Logo](https://a.fsdn.com/allura/s/mixtral-8x7b/icon?f2513b0ddc822cc79b8cf3c819aa031322c3486bf9fb5fa04df753700262b954)Mixtral 8x7B Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Mixtral-8x7B)\n*   [![Image 49: Logo](https://a.fsdn.com/allura/s/deepseek-coder-v2/icon?30a90148f6c74cbd4b4fb1c601a0e926d150c83ede9b065732ffa2d9fd056781)DeepSeek-Coder-V2 Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=DeepSeek-Coder-V2)\n*   [![Image 50: Logo](https://a.fsdn.com/allura/s/llama-4-behemoth/icon?ea72543a1b0a7dec15408328f9ec9dea7a408593f0b38c32b69bee9d8061d302)Llama 4 Behemoth Compare](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/add-software/?software_name=Llama-4-Behemoth)\n\n×\n\n![Image 52](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=24045&dimension2=pg_commercial_compare&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen-7B%2F&action_name=EXAONE+Deep+vs.+Qwen-7B+Comparison)![Image 53](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=203&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen-7B%2F&action_name=EXAONE+Deep+vs.+Qwen-7B+Comparison&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=EXAONE-Deep)![Image 54](https://sourceforge.net/software/visit?idsite=1&rec=1&rand=39153&url=https%3A%2F%2Fsourceforge.net%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen-7B%2F&action_name=EXAONE+Deep+vs.+Qwen-7B+Comparison&e_c=Impressions&e_a=Impressions+%7C+Project+%7C+Compare&e_n=Qwen-7B)\n\nThanks for helping keep SourceForge clean.\n\n[X](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#)\n\nYou seem to have CSS turned off. Please don't fill out this field.\n\nYou seem to have CSS turned off. Please don't fill out this field.\n\n Briefly describe the problem (required): \n\nUpload screenshot of ad (required):\n\n[Select a file](https://sourceforge.net/software/compare/EXAONE-Deep-vs-Qwen-7B/#), or drag & drop file here. \n\n![Image 55](blob:http://localhost/48f76619a5bd00ce057f2024dcf38bc1)\n\n✔\n\n✘\n\nScreenshot instructions:[Mac](https://support.apple.com/en-us/HT201361)\n\nClick URL instructions:\n\n Right-click on the ad, choose \"Copy Link\", then paste here →\n\n (This may not be possible with some types of ads)\n\n[More information about our ad policies](https://sourceforge.net/p/forge/documentation/Report%20a%20problem%20with%20Ad%20content/)\n\nAd destination/click URL:\n\n![Image 56](https://io.narrative.io/?companyId=2440&id=first_party%3A2348cd22-3376-48ba-a3ae-578620f7e08a&id=site_name%3Asourceforge.net&id=url%3A%2Fsoftware%2Fcompare%2FEXAONE-Deep-vs-Qwen-7B%2F&id=pagetitle%3AEXAONE+Deep+vs.+Qwen-7B+Comparison&id=vertical%3AB2B+Software&id=product%3AEXAONE+Deep%2CQwen-7B&id=topics%3AAI+Models%2CAI+Models%2CLarge+Language+Models&rand=1752218894570)\n"
    }
]